---
title: Redis 的内存管理和优化策略
tags:
  - 内存管理
  - 缓存
status: robot
class: 缓存
slug: redis-memory-management-optimization
ref:
---

## 核心要点

Redis 内存管理包括内存分配器(jemalloc)、内存淘汰策略(8种)、内存碎片处理和过期键删除机制。优化策略包括:合理设置 maxmemory、选择合适的淘汰策略、使用压缩数据结构、避免大 key、监控内存使用和定期清理过期数据。

## 详细回答

### Redis 内存组成

#### 内存使用分析

```bash
# 查看内存使用情况
INFO memory
```

**内存组成**:

| 组成部分 | 占比 | 说明 |
|---------|------|------|
| **数据** | 60-80% | 实际存储的 key-value 数据 |
| **内存碎片** | 5-20% | 分配但未使用的内存 |
| **缓冲区** | 5-10% | 客户端缓冲区、复制缓冲区、AOF 缓冲区 |
| **内部数据结构** | 5-10% | dict、ziplist、intset 等元数据 |

```
used_memory: 1024MB          # Redis 分配的总内存
used_memory_rss: 1200MB      # 操作系统分配的物理内存
used_memory_peak: 1500MB     # 历史最大内存
used_memory_dataset: 800MB   # 数据集占用内存
mem_fragmentation_ratio: 1.17  # 内存碎片率 (rss/used)
```

**内存碎片率判断**:
- **< 1**: Redis 使用了 swap,性能严重下降
- **1-1.5**: 正常范围
- **> 1.5**: 内存碎片严重,需要优化

### 内存分配器

#### jemalloc

Redis 默认使用 **jemalloc** 作为内存分配器。

**优点**:
- 减少内存碎片
- 提高内存分配效率
- 支持多线程并发分配

**内存分配策略**:
```
jemalloc 按固定大小分配内存块:
8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192 bytes

示例:
- 存储 7 字节数据 → 分配 8 字节
- 存储 100 字节数据 → 分配 128 字节
- 存储 1000 字节数据 → 分配 1024 字节

浪费的空间 = 内存碎片
```

### 内存淘汰策略

#### 8 种淘汰策略

| 策略 | 作用范围 | 淘汰算法 | 适用场景 |
|------|---------|---------|---------|
| **noeviction** | - | 不淘汰 | 默认,内存满时写入失败 |
| **allkeys-lru** | 所有 key | LRU | 通用缓存,优先淘汰最久未使用 |
| **allkeys-lfu** | 所有 key | LFU | 优先淘汰访问频率最低 (Redis 4.0+) |
| **allkeys-random** | 所有 key | 随机 | 所有 key 同等重要 |
| **volatile-lru** | 设置过期时间的 key | LRU | 部分数据需要持久化 |
| **volatile-lfu** | 设置过期时间的 key | LFU | 部分数据需要持久化 (Redis 4.0+) |
| **volatile-random** | 设置过期时间的 key | 随机 | - |
| **volatile-ttl** | 设置过期时间的 key | TTL | 优先淘汰即将过期的 key |

#### 配置淘汰策略

```bash
# redis.conf
maxmemory 2gb                  # 最大内存限制
maxmemory-policy allkeys-lru   # 淘汰策略

# 运行时修改
CONFIG SET maxmemory 2gb
CONFIG SET maxmemory-policy allkeys-lru
```

#### LRU vs LFU

**LRU (Least Recently Used)**:
- 淘汰最久未访问的数据
- 适合热点数据变化频繁的场景

```
访问序列: A B C D E A B C
LRU 排序: D E A B C (D 和 E 最久未访问)
```

**LFU (Least Frequently Used)**:
- 淘汰访问频率最低的数据
- 适合热点数据相对固定的场景

```
访问频率: A(100) B(80) C(60) D(10) E(5)
LFU 排序: E D C B A (E 和 D 访问次数最少)
```

**Redis LRU 实现**:
```
Redis 使用近似 LRU 算法:
- 每个 key 维护一个 24bit 的时间戳
- 随机采样 maxmemory-samples 个 key (默认 5 个)
- 淘汰其中最久未访问的 key

优点: 时间和空间复杂度 O(1)
缺点: 不是精确 LRU
```

### 过期键删除策略

#### 三种删除策略

**1. 定时删除**:
- 设置定时器,到期自动删除
- 优点: 内存友好,及时释放
- 缺点: CPU 不友好,大量定时器消耗 CPU

**2. 惰性删除**:
- 访问 key 时检查是否过期,过期则删除
- 优点: CPU 友好,按需删除
- 缺点: 内存不友好,过期 key 可能长期占用内存

**3. 定期删除**:
- 每隔一段时间随机检查一批 key
- 折中方案,兼顾 CPU 和内存

**Redis 采用: 惰性删除 + 定期删除**

#### 定期删除流程

```
每 100ms 执行一次:
1. 随机检查 20 个设置过期时间的 key
2. 删除其中过期的 key
3. 如果过期 key 超过 25%, 重复步骤 1
4. 最多执行 25ms (避免阻塞)
```

**Go 代码示例**:
```go
// 设置过期时间
rdb.Set(ctx, "session:1000", "data", 1*time.Hour)

// 惰性删除: 访问时检查
val, err := rdb.Get(ctx, "session:1000").Result()
// 如果已过期, 返回 redis.Nil 错误

// 主动删除
rdb.Del(ctx, "session:1000")
```

### 内存碎片处理

#### 查看内存碎片

```bash
INFO memory
# mem_fragmentation_ratio:1.5

# 内存碎片率 = used_memory_rss / used_memory
# > 1.5 表示碎片严重
```

#### 自动碎片整理 (Redis 4.0+)

```bash
# redis.conf
activedefrag yes                    # 启用自动碎片整理

# 触发条件
active-defrag-ignore-bytes 100mb    # 碎片至少 100MB
active-defrag-threshold-lower 10    # 碎片率 > 10%
active-defrag-threshold-upper 100   # 碎片率 > 100% 时最大努力整理

# CPU 限制
active-defrag-cycle-min 1           # 最少占用 1% CPU
active-defrag-cycle-max 25          # 最多占用 25% CPU
```

**手动触发**:
```bash
# 手动整理碎片
MEMORY PURGE

# 重启 Redis (会重新分配内存)
```

### 内存优化策略

#### 1. 选择合适的数据结构

**String vs Hash**:
```bash
# 坏例子: 每个字段单独存储 (大量元数据)
SET user:1000:name "Alice"
SET user:1000:age "25"
SET user:1000:city "Beijing"
# 每个 key 有额外开销 (dictEntry + redisObject + SDS)

# 好例子: 使用 Hash (节省内存)
HSET user:1000 name "Alice" age "25" city "Beijing"
# 只有一个 key 的开销
```

**内存对比**:
```
1000 个用户,每人 3 个字段:
- String: ~300KB (3000 个 key)
- Hash: ~100KB (1000 个 key)
节省 66% 内存!
```

#### 2. 使用压缩数据结构

**ziplist 优化**:
```bash
# Hash 使用 ziplist 条件
hash-max-ziplist-entries 512   # 元素数量 < 512
hash-max-ziplist-value 64      # 每个值 < 64 字节

# List 使用 ziplist 条件
list-max-ziplist-size -2       # 每个节点 8KB

# ZSet 使用 ziplist 条件
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
```

**示例**:
```go
// 优化前: 大 Hash (转为 hashtable)
for i := 0; i < 1000; i++ {
    rdb.HSet(ctx, "big_hash", fmt.Sprintf("field%d", i), "value")
}
// 内存: ~100KB

// 优化后: 拆分为多个小 Hash (使用 ziplist)
for i := 0; i < 1000; i++ {
    bucket := i / 100
    rdb.HSet(ctx, fmt.Sprintf("hash:%d", bucket), fmt.Sprintf("field%d", i), "value")
}
// 内存: ~30KB (节省 70%!)
```

#### 3. 避免大 key

**大 key 问题**:
- 占用大量内存
- 删除/过期时阻塞主线程
- 网络传输慢

**查找大 key**:
```bash
# 使用 redis-cli
redis-cli --bigkeys

# 使用 MEMORY USAGE 查看单个 key 内存
MEMORY USAGE key_name

# 扫描大 key
redis-cli --bigkeys -i 0.1
```

**Go 代码扫描大 key**:
```go
func FindBigKeys(ctx context.Context, rdb *redis.Client) {
    var cursor uint64
    for {
        keys, cursor, err := rdb.Scan(ctx, cursor, "*", 100).Result()
        if err != nil {
            break
        }

        for _, key := range keys {
            size, _ := rdb.MemoryUsage(ctx, key).Result()
            if size > 10*1024*1024 { // > 10MB
                log.Printf("Big key: %s, size: %d MB", key, size/1024/1024)
            }
        }

        if cursor == 0 {
            break
        }
    }
}
```

**优化大 key**:
```bash
# 坏例子: 单个大 List
LPUSH big_list item1 item2 ... item100000
# 内存: 10MB, 删除时阻塞 100ms

# 好例子: 拆分为多个小 List
LPUSH list:0 item1 item2 ... item1000  # 1000 个元素
LPUSH list:1 item1001 ... item2000
...
LPUSH list:99 item99001 ... item100000
# 每个 List 100KB, 删除时阻塞 1ms
```

#### 4. 设置合理的过期时间

```go
// 永不过期 (占用内存)
rdb.Set(ctx, "permanent_key", "value", 0)

// 设置过期时间
rdb.Set(ctx, "temp_key", "value", 1*time.Hour)

// 批量设置过期
pipe := rdb.Pipeline()
for i := 0; i < 1000; i++ {
    key := fmt.Sprintf("key:%d", i)
    pipe.Set(ctx, key, "value", 1*time.Hour)
}
pipe.Exec(ctx)
```

**过期时间分散**:
```go
// 坏例子: 同时过期,导致 CPU 峰值
for i := 0; i < 10000; i++ {
    rdb.Set(ctx, fmt.Sprintf("key:%d", i), "value", 1*time.Hour)
}

// 好例子: 过期时间加随机数
for i := 0; i < 10000; i++ {
    // 1 小时 ± 5 分钟
    ttl := time.Hour + time.Duration(rand.Intn(600))*time.Second
    rdb.Set(ctx, fmt.Sprintf("key:%d", i), "value", ttl)
}
```

#### 5. 使用对象池

```go
import "sync"

// 对象池减少内存分配
var bufferPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 4096)
    },
}

func ProcessData(data []byte) {
    // 从池中获取 buffer
    buffer := bufferPool.Get().([]byte)
    defer bufferPool.Put(buffer)

    // 使用 buffer...
}
```

### 内存监控

#### INFO 命令

```bash
INFO memory

# 关键指标:
# used_memory: 分配的内存
# used_memory_rss: 实际占用的物理内存
# mem_fragmentation_ratio: 碎片率
# evicted_keys: 淘汰的 key 数量
# expired_keys: 过期的 key 数量
```

#### Go 监控代码

```go
func MonitorMemory(ctx context.Context, rdb *redis.Client) {
    info, err := rdb.Info(ctx, "memory").Result()
    if err != nil {
        return
    }

    // 解析 INFO 输出
    lines := strings.Split(info, "\r\n")
    for _, line := range lines {
        if strings.HasPrefix(line, "used_memory:") {
            usedMemory := strings.TrimPrefix(line, "used_memory:")
            log.Printf("Used memory: %s", usedMemory)
        }
        if strings.HasPrefix(line, "mem_fragmentation_ratio:") {
            ratio := strings.TrimPrefix(line, "mem_fragmentation_ratio:")
            log.Printf("Fragmentation ratio: %s", ratio)
        }
    }
}
```

#### MEMORY 命令 (Redis 4.0+)

```bash
# 查看 key 占用内存
MEMORY USAGE key_name

# 查看内存统计
MEMORY STATS

# 查看内存分配详情
MEMORY MALLOC-STATS

# 清理内存碎片
MEMORY PURGE
```

### 最佳实践

#### 1. 内存预警

```go
func CheckMemoryUsage(ctx context.Context, rdb *redis.Client) {
    info, _ := rdb.Info(ctx, "memory").Result()

    var usedMemory, maxMemory int64
    // 解析 used_memory 和 maxmemory...

    usage := float64(usedMemory) / float64(maxMemory)
    if usage > 0.8 {
        log.Printf("WARNING: Memory usage: %.2f%%", usage*100)
        // 发送告警
    }
}
```

#### 2. 定期清理

```go
func CleanupExpiredKeys(ctx context.Context, rdb *redis.Client) {
    ticker := time.NewTicker(1 * time.Hour)
    defer ticker.Stop()

    for range ticker.C {
        // 扫描并删除已过期但未被删除的 key
        var cursor uint64
        for {
            keys, cursor, _ := rdb.Scan(ctx, cursor, "*", 100).Result()

            for _, key := range keys {
                ttl, _ := rdb.TTL(ctx, key).Result()
                if ttl == -1 {
                    // 无过期时间,根据业务逻辑处理
                }
            }

            if cursor == 0 {
                break
            }
        }
    }
}
```

#### 3. 合理配置

```bash
# redis.conf 推荐配置

# 最大内存 (根据服务器内存设置,建议预留 20%)
maxmemory 2gb

# 淘汰策略
maxmemory-policy allkeys-lru

# 采样数量 (越大越精确,但性能越差)
maxmemory-samples 5

# 惰性删除大 key (Redis 4.0+)
lazyfree-lazy-eviction yes
lazyfree-lazy-expire yes
lazyfree-lazy-server-del yes

# 自动碎片整理 (Redis 4.0+)
activedefrag yes
```

### 总结

**内存管理核心**:
1. 使用 jemalloc 内存分配器
2. 8 种内存淘汰策略 (推荐 allkeys-lru)
3. 惰性删除 + 定期删除过期 key
4. 自动碎片整理 (Redis 4.0+)

**优化策略**:
1. 选择合适的数据结构 (Hash 优于 String)
2. 使用压缩数据结构 (ziplist)
3. 避免大 key,拆分为多个小 key
4. 设置合理的过期时间,分散过期时刻
5. 监控内存使用,定期清理

**监控指标**:
- used_memory: 内存使用量
- mem_fragmentation_ratio: 碎片率 (正常 1-1.5)
- evicted_keys: 淘汰 key 数量
- expired_keys: 过期 key 数量
