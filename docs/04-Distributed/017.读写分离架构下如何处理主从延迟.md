---
title: 读写分离架构下，如何处理主从延迟？
tags:
  - 分布式系统
status: robot
class: 分布式系统
slug: master-slave-replication-delay-handling
ref:
---

## 核心要点

- **主从延迟根源**：MySQL 主从复制是异步的，从库通过 binlog 重放落后于主库，延迟通常在几毫秒到几秒
- **核心矛盾**：读写分离提升性能，但可能读到过期数据（写后读不一致）
- **解决思路**：强制读主库、延迟读从库、缓存辅助、业务容忍、半同步复制等
- **工程实践**：通过中间件（如 ShardingSphere、Gorm 插件）自动路由，结合业务特性选择策略

## 详细解答

### 1. 问题背景

**读写分离架构**是高并发场景下的标准方案：
- **主库（Master）**：处理所有写操作（INSERT/UPDATE/DELETE）
- **从库（Slave）**：处理读操作（SELECT）

**主从复制流程**：
1. 主库执行 SQL 并写入 binlog
2. 从库 I/O 线程拉取 binlog 到 relay log
3. 从库 SQL 线程重放 relay log

**延迟产生原因**：
- 网络传输延迟
- 从库负载过高（大量慢查询）
- 主库写入过快（从库重放速度跟不上）
- 大事务（如批量导入）导致长时间锁表

**典型问题场景**：
```
1. 用户发布文章（写主库）
2. 立即跳转到详情页（读从库）
3. 从库延迟 500ms，用户看到 404 或旧数据
```

---

### 2. 主流解决方案

#### 2.1 强制读主库（最可靠）

**原理**：对强一致性要求高的场景，直接读主库。

**适用场景**：
- 用户刚写入的数据立即读取（写后读）
- 订单、支付等核心业务

**实现方式**：

**方式一：业务代码显式指定**
```go
package db

import (
    "gorm.io/gorm"
    "gorm.io/plugin/dbresolver"
)

type UserService struct {
    db *gorm.DB
}

// CreatePost 创建文章（写主库）
func (us *UserService) CreatePost(post *Post) error {
    return us.db.Create(post).Error
}

// GetPost 读取文章（从库）
func (us *UserService) GetPost(postID int64) (*Post, error) {
    var post Post
    err := us.db.First(&post, postID).Error
    return &post, err
}

// GetPostFromMaster 强制从主库读取（解决主从延迟）
func (us *UserService) GetPostFromMaster(postID int64) (*Post, error) {
    var post Post
    // 使用 Gorm dbresolver 插件强制读主库
    err := us.db.Clauses(dbresolver.Write).First(&post, postID).Error
    return &post, err
}
```

**方式二：通过请求上下文标记**
```go
// 在写操作后，标记后续请求读主库
func (us *UserService) CreatePostAndGet(ctx context.Context, post *Post) (*Post, error) {
    // 写入主库
    if err := us.db.Create(post).Error; err != nil {
        return nil, err
    }

    // 后续读操作强制走主库（通过 context 传递标记）
    ctx = context.WithValue(ctx, "read_master", true)
    return us.GetPostWithContext(ctx, post.ID)
}

func (us *UserService) GetPostWithContext(ctx context.Context, postID int64) (*Post, error) {
    db := us.db
    if ctx.Value("read_master") == true {
        db = db.Clauses(dbresolver.Write) // 强制读主库
    }

    var post Post
    err := db.First(&post, postID).Error
    return &post, err
}
```

**优点**：100% 一致性
**缺点**：增加主库压力，部分失去读写分离优势

---

#### 2.2 延迟读从库（Sleep 策略）

**原理**：写入后等待一段时间再读从库，确保主从同步完成。

**实现**：
```go
func (us *UserService) CreatePostWithDelay(post *Post) (*Post, error) {
    // 1. 写入主库
    if err := us.db.Create(post).Error; err != nil {
        return nil, err
    }

    // 2. 等待主从同步（根据监控数据调整时间）
    time.Sleep(200 * time.Millisecond)

    // 3. 读取从库
    var result Post
    us.db.First(&result, post.ID)
    return &result, nil
}
```

**优点**：简单易实现
**缺点**：
- 延迟时间难以确定（延迟波动）
- 增加响应时间
- 延迟突然增大时仍可能不一致

---

#### 2.3 检查主从位点（GTID/Binlog Position）

**原理**：写入时记录主库 binlog 位点，读取时检查从库是否已同步到该位点。

**流程**：
1. 写操作后，获取主库当前 binlog 位置（如 GTID）
2. 将位点存入缓存（Redis）
3. 读操作时，检查从库的同步位点
4. 如果从库已同步，读从库；否则读主库

**示例代码**：
```go
import (
    "context"
    "fmt"
    "github.com/redis/go-redis/v9"
)

type ReplicationChecker struct {
    db    *gorm.DB
    redis *redis.Client
}

// GetMasterGTID 获取主库当前 GTID
func (rc *ReplicationChecker) GetMasterGTID() (string, error) {
    var gtid string
    err := rc.db.Raw("SELECT @@GLOBAL.gtid_executed").Scan(&gtid).Error
    return gtid, err
}

// GetSlaveGTID 获取从库已同步的 GTID
func (rc *ReplicationChecker) GetSlaveGTID() (string, error) {
    var gtid string
    err := rc.db.Raw("SELECT @@GLOBAL.gtid_executed").Scan(&gtid).Error
    return gtid, err
}

// WriteWithGTID 写操作时记录 GTID
func (rc *ReplicationChecker) WriteWithGTID(ctx context.Context, post *Post) error {
    // 1. 写入主库
    if err := rc.db.Create(post).Error; err != nil {
        return err
    }

    // 2. 获取当前主库 GTID
    gtid, err := rc.GetMasterGTID()
    if err != nil {
        return err
    }

    // 3. 存入 Redis（key: post_id, value: gtid, ttl: 10s）
    key := fmt.Sprintf("post_gtid:%d", post.ID)
    rc.redis.Set(ctx, key, gtid, 10*time.Second)

    return nil
}

// ReadWithGTIDCheck 读操作时检查 GTID
func (rc *ReplicationChecker) ReadWithGTIDCheck(ctx context.Context, postID int64) (*Post, error) {
    key := fmt.Sprintf("post_gtid:%d", postID)

    // 1. 获取写入时的 GTID
    expectedGTID, err := rc.redis.Get(ctx, key).Result()
    if err == redis.Nil {
        // 没有记录，直接读从库（已同步或数据较旧）
        var post Post
        rc.db.First(&post, postID)
        return &post, nil
    }

    // 2. 检查从库是否已同步
    slaveGTID, _ := rc.GetSlaveGTID()
    if slaveGTID >= expectedGTID {
        // 从库已同步，读从库
        var post Post
        rc.db.First(&post, postID)
        return &post, nil
    }

    // 3. 从库未同步，强制读主库
    var post Post
    rc.db.Clauses(dbresolver.Write).First(&post, postID)
    return &post, nil
}
```

**优点**：精确判断，避免不必要的读主库
**缺点**：实现复杂，需要额外存储 GTID

---

#### 2.4 缓存辅助（最常用）

**原理**：写入数据库后，同时更新缓存；读取时优先读缓存。

**流程**：
```go
type CachedUserService struct {
    db    *gorm.DB
    redis *redis.Client
}

// CreatePost 写入时同时更新缓存
func (cs *CachedUserService) CreatePost(ctx context.Context, post *Post) error {
    // 1. 写入主库
    if err := cs.db.Create(post).Error; err != nil {
        return err
    }

    // 2. 写入缓存
    key := fmt.Sprintf("post:%d", post.ID)
    data, _ := json.Marshal(post)
    cs.redis.Set(ctx, key, data, 5*time.Minute)

    return nil
}

// GetPost 读取时优先缓存
func (cs *CachedUserService) GetPost(ctx context.Context, postID int64) (*Post, error) {
    key := fmt.Sprintf("post:%d", postID)

    // 1. 先查缓存
    val, err := cs.redis.Get(ctx, key).Result()
    if err == nil {
        var post Post
        json.Unmarshal([]byte(val), &post)
        return &post, nil
    }

    // 2. 缓存未命中，读从库
    var post Post
    if err := cs.db.First(&post, postID).Error; err != nil {
        return nil, err
    }

    // 3. 回写缓存
    data, _ := json.Marshal(post)
    cs.redis.Set(ctx, key, data, 5*time.Minute)

    return &post, nil
}
```

**优点**：
- 性能高（缓存命中率高时几乎不受主从延迟影响）
- 降低数据库压力

**缺点**：
- 需要维护缓存一致性
- 缓存失效时仍可能读到旧数据

---

#### 2.5 半同步复制（MySQL 配置）

**原理**：主库写入后，至少等待一个从库确认接收到 binlog 才返回成功。

**配置（MySQL 5.7+）**：
```sql
-- 主库开启半同步复制插件
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
SET GLOBAL rpl_semi_sync_master_enabled = 1;
SET GLOBAL rpl_semi_sync_master_timeout = 1000; -- 超时时间 1 秒

-- 从库开启半同步复制
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';
SET GLOBAL rpl_semi_sync_slave_enabled = 1;
```

**优点**：保证至少一个从库数据一致
**缺点**：
- 增加写入延迟（等待从库确认）
- 超时后退化为异步复制

---

#### 2.6 业务容忍（最灵活）

**原理**：评估业务场景，有些场景可以容忍短暂不一致。

**适用场景**：
- 评论列表（晚几秒看到新评论可接受）
- 点赞数（实时性要求不高）
- 推荐列表（个性化推荐本身就有延迟）

**实现**：
```go
// 对于可容忍延迟的场景，直接读从库
func (us *UserService) GetComments(postID int64) ([]Comment, error) {
    var comments []Comment
    // 直接读从库，不处理延迟
    us.db.Where("post_id = ?", postID).Find(&comments)
    return comments, nil
}
```

**优点**：充分利用读写分离性能
**缺点**：需要业务方明确知晓延迟风险

---

### 3. 中间件方案（工程实践）

#### 3.1 Gorm DBResolver 插件

```go
import (
    "gorm.io/driver/mysql"
    "gorm.io/gorm"
    "gorm.io/plugin/dbresolver"
)

func InitDB() *gorm.DB {
    db, _ := gorm.Open(mysql.Open("root:pwd@tcp(master:3306)/db"), &gorm.Config{})

    db.Use(dbresolver.Register(dbresolver.Config{
        // 从库配置
        Replicas: []gorm.Dialector{
            mysql.Open("root:pwd@tcp(slave1:3306)/db"),
            mysql.Open("root:pwd@tcp(slave2:3306)/db"),
        },
        // 负载均衡策略
        Policy: dbresolver.RandomPolicy{},
    }).SetMaxIdleConns(10).SetMaxOpenConns(100))

    return db
}

// 使用示例
func Example(db *gorm.DB) {
    // 自动路由到从库
    db.Model(&User{}).Find(&users)

    // 强制使用主库
    db.Clauses(dbresolver.Write).Model(&User{}).Find(&users)
}
```

#### 3.2 ShardingSphere-Proxy

**特点**：数据库代理层，自动路由读写请求。

**配置示例（YAML）**：
```yaml
dataSources:
  master:
    url: jdbc:mysql://master:3306/db
    username: root
    password: pwd
  slave0:
    url: jdbc:mysql://slave1:3306/db
    username: root
    password: pwd

rules:
  - !READWRITE_SPLITTING
    dataSources:
      readwrite_ds:
        writeDataSourceName: master
        readDataSourceNames:
          - slave0
        loadBalancerName: round_robin
```

---

### 4. 方案对比与选择

| 方案 | 一致性 | 性能 | 复杂度 | 适用场景 |
|------|--------|------|--------|----------|
| 强制读主库 | 强一致 | 低 | 低 | 核心业务（订单、支付） |
| 延迟读从库 | 基本一致 | 中 | 低 | 延迟可预测的场景 |
| GTID 检查 | 强一致 | 中 | 高 | 需要精确控制的场景 |
| 缓存辅助 | 最终一致 | 高 | 中 | 高并发读场景 |
| 半同步复制 | 强一致 | 低 | 中 | 金融、核心数据 |
| 业务容忍 | 最终一致 | 高 | 低 | 社交、推荐类业务 |

**推荐组合策略**：
```
1. 默认读从库（性能最优）
2. 写后读场景强制读主库（保证一致性）
3. 热点数据使用缓存（降低数据库压力）
4. 核心业务开启半同步复制（数据安全）
```

---

### 5. 监控与优化

#### 5.1 监控主从延迟

```sql
-- 查看从库延迟（Seconds_Behind_Master）
SHOW SLAVE STATUS\G

-- 监控 GTID 差距
SELECT @@GLOBAL.gtid_executed;
```

**Go 监控示例**：
```go
func CheckReplicationLag(db *gorm.DB) (int, error) {
    var result struct {
        SecondsBehindMaster int `gorm:"column:Seconds_Behind_Master"`
    }

    err := db.Raw("SHOW SLAVE STATUS").Scan(&result).Error
    if err != nil {
        return -1, err
    }

    // 告警：延迟超过 5 秒
    if result.SecondsBehindMaster > 5 {
        log.Warnf("Replication lag: %d seconds", result.SecondsBehindMaster)
    }

    return result.SecondsBehindMaster, nil
}
```

#### 5.2 优化主从延迟

**从库侧**：
- 开启并行复制（MySQL 5.7+）
  ```sql
  SET GLOBAL slave_parallel_type = 'LOGICAL_CLOCK';
  SET GLOBAL slave_parallel_workers = 4;
  ```
- 升级从库硬件（SSD、更多 CPU）
- 避免从库运行大查询（影响 SQL 线程）

**主库侧**：
- 避免大事务（拆分批量操作）
- 优化 binlog 格式（ROW vs STATEMENT）
- 使用 MySQL 8.0 WriteSet 并行复制

---

### 6. 常见面试追问

**Q：如何判断应该读主库还是从库？**
A：根据业务特性分类：
- 写后立即读：读主库
- 历史数据查询：读从库
- 实时性要求高：读主库或缓存
- 可容忍延迟：读从库

**Q：主从延迟能彻底消除吗？**
A：不能。异步复制本质决定存在延迟，只能通过半同步复制、并行复制等手段尽量缩小。

**Q：如果从库挂了怎么办？**
A：
- 中间件自动剔除故障从库（健康检查）
- 临时将流量切到主库
- 监控告警，运维介入修复

---

## 总结

读写分离下的主从延迟是**性能与一致性的权衡**：
- **核心业务**：优先保证一致性（强制读主库、半同步复制）
- **一般业务**：平衡性能与一致性（缓存 + GTID 检查）
- **可容忍延迟业务**：追求极致性能（直接读从库）

生产环境建议**分场景组合使用**多种策略，并通过监控及时发现延迟异常。最重要的是明确业务对一致性的真实需求，避免过度设计。
