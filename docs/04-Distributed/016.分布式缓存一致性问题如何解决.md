---
title: 分布式缓存一致性问题如何解决？
tags:
  - 分布式系统
  - 分布式
  - 缓存策略
status: robot
class: 分布式系统
slug: distributed-cache-consistency-solutions
ref:
---

## 核心要点

- **缓存一致性问题本质**：数据库与缓存双写导致的数据不一致，核心矛盾是无法保证原子性
- **主流方案**：Cache-Aside（旁路缓存）、Read/Write-Through、Write-Behind，生产环境多用 Cache-Aside + 延迟双删
- **最佳实践**：删除缓存优于更新缓存，先更新数据库再删除缓存，配合 TTL 和异步补偿机制
- **强一致性场景**：使用分布式锁、订阅 binlog（如 Canal）或直接放弃缓存改用数据库

## 详细解答

### 1. 问题背景

分布式系统中使用缓存（如 Redis）提升性能时，面临的核心问题是：**如何保证缓存与数据库的数据一致性**。

**典型场景**：
- 用户 A 更新数据库
- 用户 B 读取到旧缓存
- 或缓存与数据库永久不一致

**根本原因**：
缓存和数据库是两个独立系统，无法通过单一事务保证原子性操作。

---

### 2. 主流一致性方案

#### 2.1 Cache-Aside（旁路缓存）

**最常用的模式**，业务代码直接操作缓存和数据库。

**读流程**：
1. 先查缓存，命中则返回
2. 未命中查数据库
3. 将数据库结果写入缓存

**写流程（推荐）**：
1. 先更新数据库
2. 再删除缓存

**为什么删除而不是更新缓存？**
- 更新缓存可能浪费（很多写操作后数据未被读取）
- 删除缓存更简单，下次读取时自然加载最新数据

**示例代码（Go + Redis）**：

```go
package cache

import (
    "context"
    "encoding/json"
    "fmt"
    "time"
    "github.com/redis/go-redis/v9"
    "gorm.io/gorm"
)

type User struct {
    ID   int64  `json:"id"`
    Name string `json:"name"`
    Age  int    `json:"age"`
}

type UserCache struct {
    db    *gorm.DB
    redis *redis.Client
}

// GetUser Cache-Aside 读取模式
func (uc *UserCache) GetUser(ctx context.Context, userID int64) (*User, error) {
    cacheKey := fmt.Sprintf("user:%d", userID)

    // 1. 先查缓存
    val, err := uc.redis.Get(ctx, cacheKey).Result()
    if err == nil {
        var user User
        if err := json.Unmarshal([]byte(val), &user); err == nil {
            return &user, nil
        }
    }

    // 2. 缓存未命中，查数据库
    var user User
    if err := uc.db.First(&user, userID).Error; err != nil {
        return nil, err
    }

    // 3. 写入缓存（设置过期时间）
    data, _ := json.Marshal(user)
    uc.redis.Set(ctx, cacheKey, data, 10*time.Minute)

    return &user, nil
}

// UpdateUser Cache-Aside 更新模式（先更新数据库，再删除缓存）
func (uc *UserCache) UpdateUser(ctx context.Context, user *User) error {
    // 1. 先更新数据库
    if err := uc.db.Save(user).Error; err != nil {
        return err
    }

    // 2. 删除缓存
    cacheKey := fmt.Sprintf("user:%d", user.ID)
    uc.redis.Del(ctx, cacheKey)

    return nil
}
```

**存在的问题**：
在极端并发情况下仍可能不一致：
1. 线程 A 更新数据库
2. 线程 A 删除缓存
3. 线程 B 查询缓存未命中
4. 线程 B 查询数据库（可能读到旧数据，如主从延迟）
5. 线程 B 写入旧数据到缓存

**解决方案：延迟双删**

```go
// UpdateUserWithDelayedDelete 延迟双删策略
func (uc *UserCache) UpdateUserWithDelayedDelete(ctx context.Context, user *User) error {
    cacheKey := fmt.Sprintf("user:%d", user.ID)

    // 1. 第一次删除缓存（可选）
    uc.redis.Del(ctx, cacheKey)

    // 2. 更新数据库
    if err := uc.db.Save(user).Error; err != nil {
        return err
    }

    // 3. 立即删除缓存
    uc.redis.Del(ctx, cacheKey)

    // 4. 延迟一段时间后再次删除（异步）
    go func() {
        time.Sleep(500 * time.Millisecond) // 根据主从延迟调整
        uc.redis.Del(context.Background(), cacheKey)
    }()

    return nil
}
```

---

#### 2.2 Read-Through / Write-Through（读写穿透）

**特点**：业务代码只操作缓存，由缓存层负责与数据库同步。

**Write-Through 写流程**：
1. 业务写入缓存
2. 缓存层同步更新数据库
3. 数据库成功后返回

**优点**：
- 业务逻辑简化
- 缓存层统一管理一致性

**缺点**：
- 每次写操作都要同步写数据库，性能较差
- 需要缓存中间件支持（如自建代理层）

**示例（伪代码）**：
```go
// 需要实现缓存代理层
type CacheProxy struct {
    cache redis.Client
    db    *gorm.DB
}

func (cp *CacheProxy) Set(ctx context.Context, key string, value interface{}) error {
    // 1. 写入缓存
    if err := cp.cache.Set(ctx, key, value, 0).Err(); err != nil {
        return err
    }

    // 2. 同步写入数据库
    return cp.db.Save(value).Error
}
```

---

#### 2.3 Write-Behind（异步写回）

**特点**：先写缓存，异步批量更新数据库。

**优点**：
- 写入性能极高
- 可批量合并写操作

**缺点**：
- 数据可能丢失（缓存崩溃）
- 实现复杂，需要消息队列

**适用场景**：
- 写多读少（如计数器、点赞数）
- 可容忍短暂不一致

**示例（基于 Canal 订阅 binlog）**：
```go
// 使用 Canal 监听 MySQL binlog，异步更新缓存
type BinlogListener struct {
    redis *redis.Client
}

func (bl *BinlogListener) OnUpdate(event *canal.RowsEvent) {
    for _, row := range event.Rows {
        userID := row["id"].(int64)
        cacheKey := fmt.Sprintf("user:%d", userID)

        // 删除缓存，下次读取时重新加载
        bl.redis.Del(context.Background(), cacheKey)
    }
}
```

---

### 3. 强一致性方案

#### 3.1 分布式锁

在更新期间加锁，阻止并发读写：

```go
import "github.com/go-redsync/redsync/v4"

func (uc *UserCache) UpdateUserWithLock(ctx context.Context, user *User) error {
    mutexName := fmt.Sprintf("lock:user:%d", user.ID)
    mutex := uc.redsync.NewMutex(mutexName)

    // 获取分布式锁
    if err := mutex.Lock(); err != nil {
        return err
    }
    defer mutex.Unlock()

    // 删除缓存
    cacheKey := fmt.Sprintf("user:%d", user.ID)
    uc.redis.Del(ctx, cacheKey)

    // 更新数据库
    return uc.db.Save(user).Error
}
```

**缺点**：性能下降，可能出现死锁。

---

#### 3.2 订阅数据库 Binlog

**原理**：通过 Canal、Maxwell 等工具订阅 MySQL binlog，实时同步更新缓存。

**优点**：
- 解耦业务代码
- 保证最终一致性

**缺点**：
- 引入额外组件
- 有一定延迟

---

### 4. 生产实践建议

| 场景 | 推荐方案 |
|------|----------|
| 一般业务 | Cache-Aside + 延迟双删 + TTL |
| 高并发写 | Write-Behind + 消息队列 |
| 强一致性 | 分布式锁 或 订阅 binlog |
| 只读数据 | 直接缓存，不考虑一致性 |

**关键配置**：
- **设置合理的 TTL**：即使不一致，过期后自动修复
- **监控缓存命中率**：低于 80% 考虑优化策略
- **降级方案**：缓存故障时直接访问数据库

---

### 5. 常见面试追问

**Q：为什么不先删除缓存，再更新数据库？**
A：可能导致更严重的不一致：
1. 线程 A 删除缓存
2. 线程 B 读取缓存未命中
3. 线程 B 查询数据库（旧数据）
4. 线程 B 写入旧数据到缓存
5. 线程 A 更新数据库（缓存仍是旧数据）

**Q：延迟双删的延迟时间如何确定？**
A：根据主从延迟 + 业务查询时间，一般 500ms-1s。

**Q：如何处理缓存穿透、击穿、雪崩？**
A：
- **穿透**：布隆过滤器 + 空值缓存
- **击穿**：分布式锁 + 永不过期热点数据
- **雪崩**：随机 TTL + 多级缓存

---

## 总结

缓存一致性是分布式系统的经典难题，**没有银弹方案**。生产环境应根据业务特点选择：
- 可接受最终一致性：Cache-Aside + 延迟双删
- 要求强一致性：分布式锁或 binlog 订阅
- 极致性能：Write-Behind + 容忍数据丢失

核心思想是**通过 TTL 兜底 + 异步补偿机制**，将不一致窗口缩到最小。
