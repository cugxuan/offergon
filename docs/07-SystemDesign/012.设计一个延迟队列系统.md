---
title: 设计一个延迟队列系统
tags:
  - 系统设计
status: robot
class: 系统设计
slug: delay-queue-system-design
ref:
---

## 核心要点速览

**业务场景**:订单超时取消、定时推送、延迟重试等需要"在未来某个时间点执行任务"的场景

**关键特性**:高精度延迟(秒级)、高可用(无单点故障)、高吞吐(百万级消息)、可靠投递(不丢不重)

**核心方案**:时间轮算法+Redis有序集合+消息队列,实现分层延迟+分布式协调

**技术难点**:时间精度保证、故障转移、消息幂等、性能优化

---

## 一、问题分析与业务场景

### 1.1 什么是延迟队列

延迟队列是一种特殊的消息队列,消息不会立即被消费,而是在指定的延迟时间后才能被消费者获取。这是一种**时间驱动**的任务调度机制。

### 1.2 典型业务场景

**电商订单场景**
- 用户下单后30分钟未支付,自动取消订单并释放库存
- 订单完成后7天自动确认收货
- 商家48小时未发货,自动赔付用户

**消息推送场景**
- 用户注册后24小时推送新手引导消息
- 会员到期前3天提醒续费
- 定时发送营销活动通知

**分布式系统场景**
- 接口调用失败后延迟重试(指数退避)
- 缓存预热任务延迟执行
- 定期清理过期数据

### 1.3 核心需求

**功能需求**
- 支持任意延迟时间(1秒到数天)
- 精确的时间触发(秒级精度)
- 消息持久化,不丢失
- 消息只被消费一次(幂等性)

**非功能需求**
- **高可用**:无单点故障,服务宕机任务不丢失
- **高性能**:支持百万级消息吞吐,毫秒级延迟
- **可扩展**:支持水平扩展,弹性伸缩
- **可观测**:任务状态可查询,延迟可监控

---

## 二、技术方案设计

### 2.1 整体架构设计

```
[生产者]
   ↓ 提交延迟任务
[任务接入层] (负载均衡)
   ↓ 写入延迟存储
[Redis 时间轮 + 有序集合] (延迟存储)
   ↓ 扫描到期任务
[调度服务集群] (分布式协调)
   ↓ 推送到期任务
[消息队列 Kafka/RabbitMQ]
   ↓ 消费任务
[消费者集群] (业务处理)
```

**分层设计思想**

1. **接入层**:快速接收任务,返回任务ID,异步写入存储
2. **存储层**:使用Redis ZSET按到期时间排序,实现高效查询
3. **调度层**:多节点竞争扫描,避免单点故障
4. **执行层**:解耦延迟和执行,利用消息队列保证可靠性

### 2.2 核心数据结构

**任务元数据**
```
DelayTask {
    TaskID      string    // 唯一任务ID (雪花ID)
    Topic       string    // 任务类型/队列名
    Payload     string    // 业务数据 (JSON)
    DelayTime   int64     // 延迟秒数
    ExecuteTime int64     // 执行时间戳 (毫秒)
    RetryCount  int       // 当前重试次数
    MaxRetry    int       // 最大重试次数
    Status      string    // 状态: pending/ready/success/failed
    CreateTime  int64     // 创建时间
}
```

**Redis 存储结构**

使用 **ZSET (有序集合)** 存储延迟任务:
- **Key**: `delay_queue:{topic}` (按topic分桶)
- **Score**: 执行时间戳 (毫秒)
- **Member**: TaskID

使用 **Hash** 存储任务详情:
- **Key**: `task:{task_id}`
- **Fields**: 任务所有字段

```
Redis 示例:
ZADD delay_queue:order 1699999999000 "task_123"
HSET task:task_123 payload "{order_id:1001}" status "pending"
```

### 2.3 时间轮算法优化

当延迟时间跨度很大时(1秒到7天),统一管理效率低。采用**分层时间轮**方案:

**时间轮分层**
- **秒级轮** (0-60秒): 每秒一个槽,60个槽
- **分钟级轮** (1-60分钟): 每分钟一个槽
- **小时级轮** (1-24小时): 每小时一个槽
- **天级轮** (1-30天): 每天一个槽

**工作原理**
1. 任务提交时根据延迟时间放入对应时间轮
2. 时间轮每秒推进指针,检查当前槽
3. 跨层级任务自动降级到下一层(天→小时→分钟→秒)

**优势**
- 减少扫描开销:只扫描当前秒的任务,而不是全部任务
- 内存友好:按时间分片,可以冷热分离
- 支持海量任务:即使有千万任务,每秒只处理该秒到期的

### 2.4 分布式扫描方案

**问题**:多个调度节点如何协同工作,避免重复消费?

**方案一:分段锁 (推荐)**

将时间分片,每个调度节点竞争不同的时间片锁:

1. 将每秒分为10个段 (0-9)
2. 节点启动时随机选择段号
3. 使用Redis分布式锁竞争该段

```
当前时间: 1699999999000
节点A竞争: lock:delay_scan:1699999999:0
节点B竞争: lock:delay_scan:1699999999:5

ZRANGEBYSCORE delay_queue:order
  1699999999000 1699999999099  // 节点A扫描段0
```

**优势**:多节点并行扫描,吞吐量高

**方案二:哈希槽分配**

根据 topic 做一致性哈希,每个节点负责固定范围的 topic:

```
节点数量: 3
节点A负责: hash(topic) % 3 == 0 的任务
节点B负责: hash(topic) % 3 == 1 的任务
节点C负责: hash(topic) % 3 == 2 的任务
```

**优势**:无锁,性能最高;**劣势**:节点变更需要重新分配

---

## 三、核心流程实现

### 3.1 任务提交流程

```
1. 客户端调用 SubmitTask(topic, payload, delaySeconds)

2. 任务接入层:
   - 生成 TaskID (雪花算法保证全局唯一)
   - 计算 ExecuteTime = CurrentTime + delaySeconds * 1000
   - 快速返回 TaskID (异步写入)

3. 异步写入 Redis:
   - ZADD delay_queue:{topic} {ExecuteTime} {TaskID}
   - HSET task:{TaskID} ... (存储任务详情)

4. 返回 TaskID 给客户端
```

**关键点**
- 快速返回:先返回TaskID,再异步持久化(降低延迟)
- 原子性:使用Redis事务或Lua脚本保证ZADD和HSET原子性
- 容错:如果Redis写入失败,需要重试机制

### 3.2 任务扫描与触发流程

```
调度服务(定时器每秒触发):

1. 获取当前时间戳 now = CurrentTimeMillis()

2. 尝试获取分布式锁:
   SET lock:delay_scan:{now}:{segment} "node_id" EX 2 NX
   (如果获取失败,说明其他节点已处理)

3. 扫描到期任务:
   taskIDs = ZRANGEBYSCORE delay_queue:{topic} 0 {now}
   (获取score在[0, now]之间的所有任务)

4. 批量推送到消息队列:
   for taskID in taskIDs:
       - 从 HGET task:{taskID} 获取任务详情
       - 发送到 Kafka topic: ready_{topic}
       - 更新任务状态为 "ready"

5. 从延迟队列删除:
   ZREM delay_queue:{topic} {taskIDs...}
   (批量删除,使用pipeline提升性能)

6. 释放锁
```

**关键点**
- **锁超时时间**:设为2秒,避免节点宕机导致锁永久占用
- **批量操作**:使用 ZRANGEBYSCORE + pipeline 批量处理,提升吞吐量
- **限流保护**:单次最多扫描1000条,避免Redis阻塞

### 3.3 任务执行与回调流程

```
消费者从 Kafka 消费任务:

1. 拉取消息: task = consumer.Poll()

2. 执行业务逻辑:
   result = ExecuteBusinessLogic(task.Payload)

3. 处理结果:
   - 成功: 更新任务状态为 "success"
   - 失败且未超过重试次数:
     * RetryCount++
     * 计算退避时间 (指数退避: 2^RetryCount 秒)
     * 重新提交到延迟队列
   - 失败且已超过最大重试次数:
     * 更新任务状态为 "failed"
     * 发送到死信队列 (DLQ)

4. 提交 Kafka offset (保证至少一次消费)
```

**幂等性保证**

问题:Kafka消费失败重试,可能导致任务重复执行

方案:在业务层加幂等校验
- 任务执行前检查状态:如果已是 "success",直接跳过
- 使用 Redis SETNX 做分布式锁:`SETNX execute_lock:{task_id} 1 EX 60`
- 业务接口自身实现幂等(如订单取消接口检查订单状态)

---

## 四、高级特性实现

### 4.1 任务持久化与高可用

**Redis持久化**
- 启用 AOF (Append-Only File),每秒刷盘
- 使用 Redis 集群 (主从+哨兵),主节点故障自动切换
- 定期备份 RDB 快照到对象存储

**双写机制 (极端可靠性场景)**
- 任务同时写入 Redis 和 MySQL
- Redis 作为热数据,MySQL 作为兜底
- 调度服务启动时扫描 MySQL 补偿未完成的任务

### 4.2 故障恢复机制

**调度节点宕机**
- 分布式锁自动过期,其他节点接管
- 未推送到消息队列的任务仍在 Redis,下次扫描会触发

**Redis 宕机**
- 主从切换,从库升主(秒级恢复)
- 如果有双写 MySQL,从 MySQL 重新加载任务

**消息队列消费失败**
- 消费者内部重试 3 次
- 重试失败后发送到死信队列
- 告警系统通知人工介入

### 4.3 性能优化策略

**批量操作**
- 扫描任务时使用 `ZRANGEBYSCORE` 一次获取多条
- 使用 Redis Pipeline 批量读取任务详情
- Kafka 批量发送消息 (batch.size = 1000)

**冷热分离**
- 近期到期任务 (< 1小时) 存储在内存
- 长期任务 (> 1小时) 定期归档到 MySQL
- 定时任务从 MySQL 加载回 Redis

**分片策略**
- 按 topic 分桶,不同业务隔离
- 按时间分片,历史数据定期清理
- 按哈希分片,支持水平扩展

---

## 五、监控与运维

### 5.1 关键监控指标

**业务指标**
- 延迟精度:实际执行时间 - 预期执行时间 (P99 < 1秒)
- 任务堆积量:pending 状态任务数量
- 消费速率:每秒处理任务数

**系统指标**
- Redis QPS 和延迟
- Kafka 消费 Lag
- 调度服务 CPU/内存使用率

**告警规则**
- 任务堆积超过 10 万条
- 延迟精度超过 5 秒
- 调度服务连续 1 分钟无心跳

### 5.2 容量评估

**单 Redis 实例容量**
- 假设每个任务 1KB,Redis 16GB 内存可存储约 1600 万任务
- QPS 瓶颈:单实例约 10 万 QPS

**扩容方案**
- 垂直扩容:增加 Redis 内存
- 水平扩容:Redis 集群分片 (按 topic hash)

---

## 六、方案对比与选型

### 6.1 与其他方案对比

| 方案 | 优势 | 劣势 | 适用场景 |
|------|------|------|----------|
| **RabbitMQ 延迟插件** | 开箱即用,简单 | 延迟精度差(秒级),吞吐量低 | 小规模,精度要求不高 |
| **Kafka 时间轮** | 吞吐量高 | 无原生延迟支持,需自研 | 大规模,低延迟场景 |
| **Redis + 时间轮** | 精度高,灵活 | 需自研调度逻辑 | 中大规模,高精度要求 |
| **时序数据库 InfluxDB** | 天然支持时间查询 | 重,资源占用高 | 数据量极大的场景 |
| **数据库轮询** | 实现简单 | 性能差,数据库压力大 | 小规模,非核心业务 |

**推荐方案**: Redis + 时间轮 + 消息队列 (综合性能与可靠性最优)

### 6.2 开源实现参考

- **有赞延迟队列**: 基于 Redis + 时间轮,生产级可用
- **RocketMQ 延迟消息**: 支持固定延迟级别 (1s, 5s, 10s...)
- **Redisson DelayedQueue**: 基于 Redis 的 Java 客户端实现

---

## 七、面试回答要点总结

**第一步:明确需求**
"延迟队列主要解决在未来某个时间点触发任务的需求,比如订单超时取消。核心挑战是高精度、高可用和高吞吐。"

**第二步:给出架构**
"我会采用 Redis ZSET 作为延迟存储,利用 score 存储执行时间戳实现自动排序。调度服务定时扫描到期任务,推送到 Kafka,消费者异步执行。"

**第三步:解决难点**
- **精度保证**: 时间轮算法,每秒扫描一次
- **高可用**: 分布式锁协调多节点,Redis 主从保证存储可靠性
- **幂等性**: 任务状态机 + 业务层去重

**第四步:优化策略**
- 批量操作减少 Redis 交互次数
- 冷热分离,长期任务归档到 MySQL
- 按 topic 分片,支持水平扩展

**第五步:监控运维**
"关注延迟精度、任务堆积量、消费速率等指标,设置告警规则,保证系统稳定性。"

**加分项**
- 提到时间轮算法的分层思想
- 说明分布式场景下的一致性问题
- 给出开源实现的参考 (如有赞延迟队列)
