---
title: 设计一个搜索引擎（全文检索）
tags:
  - 系统设计
  - 索引
status: robot
class: 系统设计
slug: design-full-text-search-engine
ref:
---

## 核心要点

全文检索搜索引擎的核心是**倒排索引**和**分词技术**。关键要素包括：
- 索引构建：爬虫采集 → 文档解析 → 分词 → 构建倒排索引
- 查询处理：用户查询 → 分词 → 索引查找 → 相关性排序 → 返回结果
- 相关性排序：TF-IDF、BM25算法计算文档与查询的相关度
- 性能优化：索引分片、缓存热门查询、查询改写
- 数据更新：增量索引更新、近实时搜索

## 详细回答

### 一、什么是倒排索引

倒排索引是搜索引擎的核心数据结构，理解它是理解全文检索的关键。

**正排索引 vs 倒排索引：**

假设有以下文档：
- 文档1：Go语言编程实战
- 文档2：Java编程入门
- 文档3：Go语言高级特性

**正排索引**（文档 → 内容）：
```
文档1 → [Go, 语言, 编程, 实战]
文档2 → [Java, 编程, 入门]
文档3 → [Go, 语言, 高级, 特性]
```
正排索引适合"给定文档，查找包含的词"，但不适合"给定词，查找包含它的文档"。

**倒排索引**（词 → 文档列表）：
```
Go      → [文档1, 文档3]
语言    → [文档1, 文档3]
编程    → [文档1, 文档2]
实战    → [文档1]
Java    → [文档2]
入门    → [文档2]
高级    → [文档3]
特性    → [文档3]
```

当用户搜索"Go 编程"时：
1. 查找"Go"的倒排列表：[文档1, 文档3]
2. 查找"编程"的倒排列表：[文档1, 文档2]
3. 求交集：[文档1]（同时包含两个词的文档）

倒排索引让查询速度从 O(n) 降到 O(1)（理想情况）。

**完整的倒排索引结构：**

实际的倒排索引不只存文档ID，还包含：
```
词条: Go
  - 文档频率(DF): 2  (出现在2个文档中)
  - 倒排列表:
    - 文档1: 词频=1, 位置=[0]
    - 文档3: 词频=1, 位置=[0]
```

这些额外信息用于：
- **词频(TF)**：计算相关性（词出现越多，相关性越高）
- **位置信息**：支持短语搜索（如"Go语言"需要两个词相邻）
- **文档频率(DF)**：计算IDF（词越稀有，区分度越高）

### 二、系统架构设计

全文检索系统分为**离线索引构建**和**在线查询处理**两大部分。

#### 1. 离线索引构建流程

**步骤1：数据采集（爬虫）**

如果是互联网搜索引擎，需要爬虫抓取网页：
- 广度优先爬取（BFS）
- 去重（URL哈希）
- 遵守robots.txt协议
- 分布式爬取（多机并行）

如果是站内搜索（如电商商品搜索），直接从数据库读取：
- 定期全量导出
- 监听数据库binlog实现增量更新

**步骤2：文档解析**

将原始内容转换为结构化数据：
- HTML解析：提取正文、过滤标签
- PDF/Word解析：提取文本内容
- 字段提取：标题、正文、作者、时间等
- 去除噪音：广告、导航栏、脚注等

**步骤3：分词**

将文本切分成词条（Token），这是中文搜索的难点：

中文分词挑战：
- "南京市长江大桥" → "南京市/长江大桥" 还是 "南京/市长/江大桥"？
- 需要结合词典和统计模型

常用分词算法：
- **基于词典**：最大正向/逆向匹配（简单但不准确）
- **基于统计**：HMM、CRF（准确但需要训练）
- **基于深度学习**：BERT分词（效果最好但慢）

工程实践：
- 使用成熟分词库（如jieba、IK Analyzer）
- 自定义词典（行业术语、新词）
- 同义词扩展（如"手机" → "手机, 移动电话"）

英文分词相对简单：
- 按空格分割
- 转小写（"Go" → "go"）
- 词干提取（"running" → "run"）
- 停用词过滤（"the", "is", "a"等无意义词）

**步骤4：构建倒排索引**

使用Elasticsearch等搜索引擎框架，底层流程：

1. **建立倒排表**：
   - 遍历所有分词结果
   - 为每个词条建立倒排列表
   - 记录词频、位置等信息

2. **索引存储**：
   - 倒排索引存储在磁盘（Lucene格式）
   - 使用压缩算法减少存储（如变长整数编码）
   - 热点索引加载到内存（通过mmap）

3. **分片（Sharding）**：
   - 索引按文档ID范围分片（如0-100万、100万-200万）
   - 每个分片独立索引和查询
   - 分片可分布在多台机器（分布式）

**步骤5：索引优化**

- **索引合并**：小索引段定期合并成大段（减少碎片）
- **字段权重**：标题权重 > 正文权重（标题命中相关性更高）
- **索引预热**：启动时加载常用索引到内存

#### 2. 在线查询处理流程

**步骤1：查询解析**

用户输入："Go语言 教程"

1. **分词**：使用与索引相同的分词器
   - "Go语言 教程" → ["Go", "语言", "教程"]

2. **查询改写**：
   - 同义词扩展："教程" → ["教程", "入门", "指南"]
   - 拼写纠错："Goo" → "Go"（编辑距离计算）
   - 查询建议："你是不是要搜索：Go语言编程"

3. **构建查询语法树**：
   - AND查询：必须包含所有词
   - OR查询：包含任一词即可
   - NOT查询：排除某些词
   - 短语查询："Go语言"（两个词必须相邻）

**步骤2：索引查找**

分布式查询流程（以Elasticsearch为例）：

1. **协调节点**接收查询请求
2. **广播查询**到所有相关分片
3. 每个分片**并行查询**：
   - 查找每个词的倒排列表
   - 计算交集/并集
   - 计算每个文档的相关性得分
4. **汇总结果**：
   - 收集各分片的Top N结果
   - 全局排序（合并多个有序列表）
   - 返回最终Top N

**步骤3：相关性排序**

如何衡量文档与查询的相关性？核心算法：

**TF-IDF算法：**
```
得分 = TF(词频) × IDF(逆文档频率)
```

- **TF(Term Frequency)**：词在文档中出现的频率
  - 出现越多 → 相关性越高
  - 公式：TF = 词在文档中的次数 / 文档总词数

- **IDF(Inverse Document Frequency)**：词的稀有程度
  - 越稀有的词区分度越高（如"Go"比"的"更有区分度）
  - 公式：IDF = log(文档总数 / 包含该词的文档数)

例如：
- "Go"在文档中出现5次，文档共100词 → TF = 0.05
- "Go"在1000个文档中出现，总文档10万 → IDF = log(100000/1000) = 2
- TF-IDF = 0.05 × 2 = 0.1

**BM25算法（更先进）：**

TF-IDF的改进版本，考虑了：
- **文档长度归一化**：长文档不因词频高而占优势
- **饱和度**：词频从5到6的提升，不如从1到2的提升大

Elasticsearch默认使用BM25。

**其他排序因子：**
- **字段权重**：标题命中 > 正文命中
- **时效性**：新文档加权（新闻搜索）
- **热度**：点击量、点赞数（社交搜索）
- **个性化**：用户历史行为、地理位置
- **机器学习排序（LTR）**：训练模型综合多个特征

**步骤4：结果返回**

1. **高亮**：标记查询词在结果中的位置
   - "Go语言编程实战" → "**Go**语言编程实战"

2. **摘要生成**：提取包含查询词的片段
   - 不是完整正文，而是相关片段（snippet）

3. **分页**：每页10-20条结果
   - 深度分页优化（避免查询太后面的页）

### 三、关键技术问题

#### 问题1：如何实现近实时搜索（NRT）？

用户刚发布内容，立即搜索能找到吗？

**挑战：**
- 构建索引需要时间（分词、写磁盘）
- 索引合并更慢

**解决方案：**

1. **内存Buffer + 定时刷新**：
   - 新文档先写入内存Buffer
   - 每1秒将Buffer刷新到磁盘（生成新的索引段）
   - 用户查询会搜索所有索引段（包括新段）

2. **增量索引**：
   - 不重建全量索引，只索引变更数据
   - 监听数据库binlog，捕获INSERT/UPDATE/DELETE
   - 实时更新对应的倒排索引

3. **延迟合并**：
   - 小索引段先不合并，保证数据可见
   - 后台异步合并（不影响查询）

Elasticsearch的refresh_interval默认1秒，即1秒内可见。

#### 问题2：如何处理海量数据？

亿级文档如何存储和查询？

**解决方案：**

1. **分片（Sharding）**：
   - 按文档ID哈希分片（如文档ID % 10）
   - 每个分片独立存储和查询
   - 10个分片 → 单机10亿文档变成每分片1亿文档

2. **副本（Replication）**：
   - 每个分片有多个副本（通常3副本）
   - 提高查询吞吐量（副本并行处理查询）
   - 提高可用性（主分片挂了副本顶上）

3. **分层存储**：
   - 热数据（近期文档）：SSD + 大内存
   - 冷数据（历史文档）：HDD + 小内存
   - 按时间自动降冷

4. **索引压缩**：
   - 倒排列表用变长整数编码（VByte）
   - 文档ID差值编码（相邻文档ID差值小，压缩比高）

#### 问题3：如何提高查询速度？

**解决方案：**

1. **缓存热门查询**：
   - Query Cache：缓存查询结果（如"Go教程"的Top 10）
   - Field Data Cache：缓存字段值（排序/聚合用）
   - 缓存失效：索引更新时清除相关缓存

2. **索引预加载**：
   - 常用字段的倒排索引加载到内存（mmap）
   - OS页缓存加速磁盘读取

3. **查询优化**：
   - 提前终止（Early Termination）：已找到Top 10，不再扫描后续分片
   - 跳表（Skip List）：快速跳过不相关的文档
   - 布隆过滤器：快速判断词条是否存在

4. **硬件优化**：
   - SSD替代HDD（随机读性能10倍+）
   - 增加内存（更多索引加载到内存）

#### 问题4：如何支持复杂查询？

**常见查询类型：**

1. **布尔查询**：
   - "Go AND 教程"（必须同时包含）
   - "Go OR Java"（包含任一即可）
   - "Go NOT 入门"（包含Go但不包含入门）

2. **短语查询**：
   - "Go语言"（两个词必须相邻）
   - 查找倒排列表中位置连续的文档

3. **通配符查询**：
   - "Jav*"（匹配Java、JavaScript）
   - 需要Term Index（前缀树）支持

4. **模糊查询**：
   - "Goo~"（允许拼写错误）
   - 基于编辑距离（Levenshtein Distance）

5. **范围查询**：
   - 价格：100-500元
   - 时间：最近7天
   - 使用范围索引（如BKD Tree）

6. **聚合查询**：
   - 分类统计：电子产品（100个）、图书（50个）
   - 类似SQL的GROUP BY
   - 使用Doc Values（列式存储）

### 四、开源方案选型

**Elasticsearch（推荐）：**
- 优点：功能完善、社区活跃、易用性好
- 缺点：JVM内存占用大、配置复杂
- 适用场景：日志分析、站内搜索、电商搜索

**Solr：**
- 优点：传统搜索引擎、稳定性好
- 缺点：分布式支持不如ES
- 适用场景：企业搜索、文档检索

**Meilisearch：**
- 优点：轻量级、开箱即用、Rust编写性能好
- 缺点：功能相对简单
- 适用场景：小型项目、个人网站

**自研（基于Lucene）：**
- 优点：完全可控、深度定制
- 缺点：开发成本高、维护困难
- 适用场景：特殊需求、超大规模

### 五、实际应用案例

**电商商品搜索：**
- 索引字段：商品名、分类、品牌、描述、价格、销量
- 排序：相关性 + 销量 + 价格
- 过滤：价格区间、品牌、分类
- 聚合：分类统计、价格区间分布

**新闻搜索：**
- 索引字段：标题、正文、作者、时间、来源
- 排序：相关性 + 时效性（新文章优先）
- 高亮：标题和摘要中的查询词
- 去重：相似新闻合并

**日志搜索（ELK）：**
- 索引字段：时间、服务、级别、消息、堆栈
- 时间范围查询：最近1小时
- 聚合：错误统计、服务分布
- 实时监控：错误率告警

### 六、总结

设计全文检索搜索引擎的核心要点：

1. **倒排索引**：从"文档→词"转为"词→文档"，实现快速查找
2. **分词技术**：中文分词是难点，需要词典+统计模型
3. **相关性排序**：TF-IDF/BM25算法，综合词频、稀有度、文档长度
4. **分布式架构**：分片+副本，支撑海量数据和高并发查询
5. **近实时搜索**：内存Buffer + 定时刷新，实现秒级可见
6. **多级缓存**：Query Cache + Field Data Cache，提升查询速度

工程实践建议：
- 优先使用Elasticsearch等成熟方案，不要重复造轮子
- 根据业务特点调优：电商重排序、日志重实时性、新闻重时效性
- 监控关键指标：查询QPS、P99延迟、缓存命中率、索引刷新延迟
- 定期评估相关性：人工标注样本，A/B测试排序算法
