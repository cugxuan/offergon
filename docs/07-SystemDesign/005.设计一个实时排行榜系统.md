---
title: 设计一个实时排行榜系统
tags:
  - 系统设计
status: robot
class: 系统设计
slug: real-time-ranking-system-design
ref:
---

## 核心要点

**Redis Sorted Set + 多级缓存 + 异步更新 + 分片策略**,支持亿级用户实时排名查询和更新,延迟控制在毫秒级。

---

## 详细回答

### 一、系统需求分析

#### 1.1 功能需求
- **实时更新**:用户分数变化后,排行榜需要在毫秒级响应
- **排名查询**:
  - Top N 排行榜(如前100名)
  - 用户个人排名查询(我的排名)
  - 区间排名查询(第100-200名)
- **多维度排行**:游戏积分榜、财富榜、粉丝榜等
- **时间维度**:日榜、周榜、月榜、总榜

#### 1.2 非功能需求
- **高并发**:支持10万+ QPS的查询和更新
- **低延迟**:查询响应<50ms,更新延迟<100ms
- **高可用**:99.99%可用性
- **数据一致性**:最终一致性即可,允许短暂延迟

### 二、核心架构设计

#### 2.1 整体架构图

```
┌─────────────┐
│  客户端请求   │
└──────┬──────┘
       │
┌──────▼──────────────────────────────┐
│        接入层 (API Gateway)          │
│  - 流量控制                          │
│  - 请求路由                          │
└──────┬──────────────────────────────┘
       │
┌──────▼──────────────────────────────┐
│      应用层 (Ranking Service)        │
│  - 业务逻辑处理                      │
│  - 缓存查询                          │
└──────┬──────────────────────────────┘
       │
┌──────▼──────────────────────────────┐
│       缓存层 (Redis Cluster)         │
│  - L1: 热点排行榜 (Top 100)          │
│  - L2: 完整 Sorted Set               │
│  - 分片存储                          │
└──────┬──────────────────────────────┘
       │
┌──────▼──────────────────────────────┐
│    消息队列 (Kafka/RocketMQ)         │
│  - 分数变化事件                      │
│  - 异步更新任务                      │
└──────┬──────────────────────────────┘
       │
┌──────▼──────────────────────────────┐
│      存储层 (MySQL + HBase)          │
│  - MySQL: 用户基础信息               │
│  - HBase: 历史排行数据               │
└─────────────────────────────────────┘
```

#### 2.2 数据结构设计

**Redis Sorted Set 核心设计**:
```
排行榜维度设计:
- ranking:game:daily:20250108        # 日榜
- ranking:game:weekly:2025W01        # 周榜
- ranking:game:monthly:202501        # 月榜
- ranking:game:total                 # 总榜

Sorted Set 结构:
KEY: ranking:game:daily:20250108
MEMBER: user_id (用户ID)
SCORE: points (分数,支持浮点数)

辅助缓存:
- ranking:top100:game:daily:20250108  # Top 100快照 (String/Hash)
- user:rank:123456                    # 用户排名缓存 (ttl=30s)
```

**MySQL 用户表**:
```sql
CREATE TABLE user_score (
  id BIGINT PRIMARY KEY,
  user_id BIGINT NOT NULL,
  ranking_type VARCHAR(32),  -- 排行榜类型
  score DECIMAL(20,2),
  rank INT,
  update_time TIMESTAMP,
  INDEX idx_type_score (ranking_type, score DESC)
);
```

**HBase 历史表**(用于历史数据查询):
```
RowKey: ranking_type:date:user_id
Column Family: info
  - score
  - rank
  - snapshot_time
```

### 三、核心功能实现

#### 3.1 分数更新流程

```
用户行为 → 业务系统
              ↓
        发送更新事件到 Kafka
              ↓
    Ranking Service 消费消息
              ↓
    ┌─────────┴─────────┐
    ↓                   ↓
Redis ZINCRBY      异步写入 MySQL
(实时更新)         (持久化存储)
    ↓
清除相关缓存
(Top100缓存、用户排名缓存)
```

**Go 代码实现**:
```go
// 更新用户分数
func (s *RankingService) UpdateScore(ctx context.Context,
    userID int64, rankingType string, scoreDelta float64) error {

    // 1. 构建 Redis Key
    key := fmt.Sprintf("ranking:%s:%s", rankingType, time.Now().Format("20060102"))

    // 2. 原子性增加分数 (Redis Sorted Set)
    newScore, err := s.redis.ZIncrBy(ctx, key, scoreDelta,
        fmt.Sprintf("%d", userID)).Result()
    if err != nil {
        return err
    }

    // 3. 清除相关缓存
    s.clearCache(ctx, key, userID)

    // 4. 异步持久化到 MySQL (发送到 Kafka)
    event := ScoreUpdateEvent{
        UserID:      userID,
        RankingType: rankingType,
        NewScore:    newScore,
        Timestamp:   time.Now(),
    }
    return s.kafka.Publish(ctx, "ranking.update", event)
}

// 清除缓存
func (s *RankingService) clearCache(ctx context.Context, key string, userID int64) {
    // 清除 Top100 缓存
    s.redis.Del(ctx, fmt.Sprintf("%s:top100", key))
    // 清除用户排名缓存
    s.redis.Del(ctx, fmt.Sprintf("user:rank:%d", userID))
}
```

#### 3.2 Top N 排行榜查询

```go
// 查询 Top N 排行榜
func (s *RankingService) GetTopN(ctx context.Context,
    rankingType string, n int) ([]RankItem, error) {

    key := fmt.Sprintf("ranking:%s:%s", rankingType, time.Now().Format("20060102"))
    cacheKey := fmt.Sprintf("%s:top%d", key, n)

    // 1. 尝试从缓存获取
    cached, err := s.redis.Get(ctx, cacheKey).Result()
    if err == nil {
        var items []RankItem
        json.Unmarshal([]byte(cached), &items)
        return items, nil
    }

    // 2. 从 Sorted Set 查询 (降序,获取前 N 名)
    result, err := s.redis.ZRevRangeWithScores(ctx, key, 0, int64(n-1)).Result()
    if err != nil {
        return nil, err
    }

    // 3. 构建排行榜数据
    items := make([]RankItem, 0, len(result))
    for i, z := range result {
        userID, _ := strconv.ParseInt(z.Member.(string), 10, 64)
        items = append(items, RankItem{
            Rank:   i + 1,
            UserID: userID,
            Score:  z.Score,
        })
    }

    // 4. 缓存结果 (TTL=60s)
    data, _ := json.Marshal(items)
    s.redis.Set(ctx, cacheKey, data, 60*time.Second)

    return items, nil
}
```

#### 3.3 用户排名查询

```go
// 查询用户排名
func (s *RankingService) GetUserRank(ctx context.Context,
    userID int64, rankingType string) (*UserRankInfo, error) {

    key := fmt.Sprintf("ranking:%s:%s", rankingType, time.Now().Format("20060102"))
    userKey := fmt.Sprintf("%d", userID)

    // 1. 并行查询排名和分数
    pipe := s.redis.Pipeline()
    rankCmd := pipe.ZRevRank(ctx, key, userKey)    // 获取排名 (0-based)
    scoreCmd := pipe.ZScore(ctx, key, userKey)     // 获取分数
    _, err := pipe.Exec(ctx)

    if err != nil {
        return nil, err
    }

    rank, _ := rankCmd.Result()
    score, _ := scoreCmd.Result()

    return &UserRankInfo{
        UserID: userID,
        Rank:   rank + 1,  // 转为 1-based
        Score:  score,
    }, nil
}
```

### 四、性能优化方案

#### 4.1 多级缓存架构

```
L1 缓存 (本地内存)
  ↓ Miss
L2 缓存 (Redis - Top100)
  ↓ Miss
L3 缓存 (Redis - Sorted Set)
  ↓ Miss
L4 存储 (MySQL)
```

**本地缓存实现**:
```go
type LocalCache struct {
    cache *bigcache.BigCache
}

func (s *RankingService) GetTopNWithLocalCache(ctx context.Context,
    rankingType string, n int) ([]RankItem, error) {

    // L1: 本地缓存 (TTL=10s)
    cacheKey := fmt.Sprintf("local:top%d:%s", n, rankingType)
    if data, err := s.localCache.Get(cacheKey); err == nil {
        var items []RankItem
        json.Unmarshal(data, &items)
        return items, nil
    }

    // L2/L3: Redis 查询
    items, err := s.GetTopN(ctx, rankingType, n)
    if err != nil {
        return nil, err
    }

    // 回写本地缓存
    data, _ := json.Marshal(items)
    s.localCache.Set(cacheKey, data)

    return items, nil
}
```

#### 4.2 分片策略

**按排行榜类型分片**:
```
Redis Cluster 分片方案:
- 游戏排行榜 → Shard 1
- 财富排行榜 → Shard 2
- 粉丝排行榜 → Shard 3

每个 Shard 使用一致性哈希 + 虚拟节点
```

**按时间维度分片**:
```go
func (s *RankingService) getRedisClient(rankingType string) *redis.Client {
    shardKey := fmt.Sprintf("%s:%s", rankingType, time.Now().Format("20060102"))
    shardID := crc32.ChecksumIEEE([]byte(shardKey)) % uint32(len(s.redisClients))
    return s.redisClients[shardID]
}
```

#### 4.3 数据预加载

```go
// 定时任务:凌晨预加载当日排行榜
func (s *RankingService) PreloadDailyRanking(ctx context.Context) {
    rankingTypes := []string{"game", "wealth", "fans"}

    for _, rt := range rankingTypes {
        // 预热 Top 100
        items, _ := s.GetTopN(ctx, rt, 100)

        // 预热热门用户排名 (VIP用户、活跃用户)
        hotUsers := s.getHotUsers(ctx, rt)
        for _, userID := range hotUsers {
            s.GetUserRank(ctx, userID, rt)
        }
    }
}
```

### 五、高级特性

#### 5.1 实时榜单变化推送

```go
// WebSocket 推送排行榜变化
func (s *RankingService) WatchRankingChange(ctx context.Context,
    rankingType string) <-chan RankChangeEvent {

    ch := make(chan RankChangeEvent, 100)

    // 订阅 Redis Pub/Sub
    pubsub := s.redis.Subscribe(ctx, fmt.Sprintf("ranking:change:%s", rankingType))

    go func() {
        defer pubsub.Close()
        for msg := range pubsub.Channel() {
            var event RankChangeEvent
            json.Unmarshal([]byte(msg.Payload), &event)
            ch <- event
        }
    }()

    return ch
}

// 分数更新时发布变化事件
func (s *RankingService) publishRankChange(ctx context.Context,
    rankingType string, event RankChangeEvent) {

    data, _ := json.Marshal(event)
    s.redis.Publish(ctx, fmt.Sprintf("ranking:change:%s", rankingType), data)
}
```

#### 5.2 防刷机制

```go
// 分数变化限流
func (s *RankingService) checkRateLimit(ctx context.Context, userID int64) error {
    key := fmt.Sprintf("ratelimit:score:%d", userID)

    // 令牌桶算法:每分钟最多更新 60 次
    count, err := s.redis.Incr(ctx, key).Result()
    if err != nil {
        return err
    }

    if count == 1 {
        s.redis.Expire(ctx, key, time.Minute)
    }

    if count > 60 {
        return errors.New("rate limit exceeded")
    }

    return nil
}

// 异常分数检测
func (s *RankingService) detectAbnormalScore(ctx context.Context,
    userID int64, scoreDelta float64) error {

    // 获取历史分数变化
    history := s.getScoreHistory(ctx, userID, time.Hour)

    // 检测异常:1小时内分数增长超过 10000
    if sumDelta(history) + scoreDelta > 10000 {
        s.logger.Warnf("Abnormal score detected: user=%d, delta=%f", userID, scoreDelta)
        s.sendAlert(ctx, userID, scoreDelta)
        return errors.New("abnormal score detected")
    }

    return nil
}
```

#### 5.3 历史数据归档

```go
// 定时任务:每日凌晨归档昨日数据
func (s *RankingService) ArchiveDailyRanking(ctx context.Context) error {
    yesterday := time.Now().AddDate(0, 0, -1).Format("20060102")
    rankingTypes := []string{"game", "wealth", "fans"}

    for _, rt := range rankingTypes {
        key := fmt.Sprintf("ranking:%s:%s", rt, yesterday)

        // 1. 从 Redis 导出完整排行榜
        allRanks, err := s.redis.ZRevRangeWithScores(ctx, key, 0, -1).Result()
        if err != nil {
            return err
        }

        // 2. 批量写入 HBase (历史查询)
        batch := make([]*HBaseRow, 0, len(allRanks))
        for i, z := range allRanks {
            userID, _ := strconv.ParseInt(z.Member.(string), 10, 64)
            batch = append(batch, &HBaseRow{
                RowKey: fmt.Sprintf("%s:%s:%d", rt, yesterday, userID),
                Score:  z.Score,
                Rank:   i + 1,
            })
        }
        s.hbase.BatchPut(ctx, "ranking_history", batch)

        // 3. 写入 Top 1000 到 MySQL (快速查询)
        top1000 := allRanks[:min(1000, len(allRanks))]
        s.mysql.BatchInsertHistory(ctx, rt, yesterday, top1000)

        // 4. 删除 Redis 数据 (保留 7 天)
        if time.Since(time.Parse("20060102", yesterday)) > 7*24*time.Hour {
            s.redis.Del(ctx, key)
        }
    }

    return nil
}
```

### 六、容灾与降级

#### 6.1 服务降级策略

```go
func (s *RankingService) GetTopNWithFallback(ctx context.Context,
    rankingType string, n int) ([]RankItem, error) {

    // 1. 尝试从 Redis 查询
    items, err := s.GetTopN(ctx, rankingType, n)
    if err == nil {
        return items, nil
    }

    // 2. Redis 故障,降级到 MySQL
    s.logger.Warn("Redis failed, fallback to MySQL")
    items, err = s.mysql.GetTopN(ctx, rankingType, n)
    if err == nil {
        return items, nil
    }

    // 3. MySQL 也故障,返回兜底数据
    s.logger.Error("All backends failed, return cached snapshot")
    return s.getStaticSnapshot(rankingType, n), nil
}
```

#### 6.2 双写一致性

```go
// 双写模式:同时写 Redis 和 MySQL
func (s *RankingService) UpdateScoreWithDoubleWrite(ctx context.Context,
    userID int64, rankingType string, scoreDelta float64) error {

    key := fmt.Sprintf("ranking:%s:%s", rankingType, time.Now().Format("20060102"))

    // 开启事务
    tx := s.mysql.Begin()
    defer tx.Rollback()

    // 1. 更新 MySQL
    if err := tx.UpdateScore(userID, rankingType, scoreDelta); err != nil {
        return err
    }

    // 2. 更新 Redis
    if err := s.redis.ZIncrBy(ctx, key, scoreDelta, fmt.Sprintf("%d", userID)).Err(); err != nil {
        return err
    }

    // 3. 提交事务
    return tx.Commit()
}
```

### 七、监控与告警

```go
// 核心监控指标
type RankingMetrics struct {
    // 性能指标
    QueryLatency     prometheus.Histogram  // 查询延迟
    UpdateLatency    prometheus.Histogram  // 更新延迟
    CacheHitRate     prometheus.Gauge      // 缓存命中率

    // 业务指标
    TotalUsers       prometheus.Gauge      // 排行榜总用户数
    UpdateQPS        prometheus.Counter    // 更新 QPS
    QueryQPS         prometheus.Counter    // 查询 QPS

    // 异常指标
    RedisErrors      prometheus.Counter    // Redis 错误数
    AbnormalScores   prometheus.Counter    // 异常分数次数
}

// Prometheus 埋点
func (s *RankingService) recordQueryMetrics(start time.Time, err error) {
    duration := time.Since(start).Seconds()
    s.metrics.QueryLatency.Observe(duration)
    s.metrics.QueryQPS.Inc()

    if err != nil {
        s.metrics.RedisErrors.Inc()
    }
}
```

### 八、扩展思考

#### 8.1 千万级用户排名查询优化

**问题**:Sorted Set 中有 1000 万用户时,`ZRANK` 命令时间复杂度 O(log N),性能下降。

**解决方案 - 分段索引**:
```
将排行榜按分数段分桶:
- bucket:0-1000        → Redis Sorted Set 1
- bucket:1000-5000     → Redis Sorted Set 2
- bucket:5000-10000    → Redis Sorted Set 3
- bucket:10000+        → Redis Sorted Set 4

查询时:
1. 先根据分数定位桶
2. 在桶内查询排名
3. 加上前面桶的用户总数
```

#### 8.2 跨地域部署

```
多地域架构:
- 华东区 Redis Cluster (主)
- 华北区 Redis Cluster (从)
- 华南区 Redis Cluster (从)

同步策略:
- 写请求路由到主集群
- 通过 Redis Replication 同步到从集群
- 读请求就近访问本地集群
```

#### 8.3 实时计算场景

```
实时榜单需求:基于最近 1 小时的行为数据
技术方案:
- Flink 实时计算用户分数
- 写入 Redis Sorted Set
- 定时清理过期数据

Flink SQL 示例:
SELECT user_id, SUM(score) as total_score
FROM user_behavior
WHERE event_time > NOW() - INTERVAL '1' HOUR
GROUP BY user_id, TUMBLE(event_time, INTERVAL '1' MINUTE)
```

### 九、总结

**核心技术选型**:
- **Redis Sorted Set**:天然支持排序,时间复杂度 O(log N)
- **多级缓存**:本地缓存 + Redis 缓存,降低 Redis 压力
- **异步更新**:Kafka 解耦,保证系统高可用
- **分片策略**:按类型和时间分片,水平扩展

**性能指标**:
- 查询延迟:P99 < 50ms
- 更新延迟:P99 < 100ms
- 支持 QPS:10万+ (通过分片扩展)
- 缓存命中率:>95%

**关键设计点**:
1. Redis Sorted Set 是核心,但需配合多级缓存
2. 热点数据(Top100)单独缓存,避免重复计算
3. 异步更新保证实时性和系统解耦
4. 降级策略保证系统高可用
5. 分片和归档策略支持海量数据
