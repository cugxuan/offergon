---
title: 设计一个消息推送系统（push notification）
tags:
  - 系统设计
status: robot
class: 系统设计
slug: push-notification-system-design
ref:
---

## 核心要点提炼

**系统定位**: 面向百万/千万级用户的消息推送平台,支持多端(iOS/Android/Web)实时推送

**技术核心**:
- **长连接管理**: WebSocket/TCP 维持海量持久连接,连接池+心跳保活
- **分层架构**: 接入层(Connection Server)、逻辑层(Logic Server)、存储层解耦
- **推送策略**: 在线推送(长连接)、离线推送(APNs/FCM)、降级推送(短信/邮件)
- **高可用保障**: 消息队列削峰、Redis 缓存、消息持久化、幂等去重

**关键指标**: 推送到达率 >99%、推送延迟 <3s、单机支持 10 万+长连接

---

## 详细设计方案

### 一、需求分析

#### 1.1 功能需求
- **单播推送**: 针对特定用户 ID 推送(如订单状态更新)
- **组播推送**: 向特定用户群推送(如地域性促销活动)
- **广播推送**: 全员推送(如系统公告)
- **定时推送**: 支持延迟推送和定时触发
- **多端同步**: 消息在用户多设备间同步
- **优先级管理**: 紧急消息优先推送

#### 1.2 非功能需求
- **高并发**: 支持千万级在线用户、每秒百万级推送
- **高可用**: 99.99% 可用性,单点故障自动切换
- **实时性**: P99 推送延迟 < 3 秒
- **可靠性**: 推送到达率 > 99%(含离线重推)
- **可扩展**: 水平扩展支持业务增长

---

### 二、核心架构设计

#### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────┐
│                        业务系统层                            │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │订单服务  │  │社交服务  │  │营销服务  │  │运营平台  │   │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘   │
│       │             │              │             │          │
│       └─────────────┴──────────────┴─────────────┘          │
└───────────────────────────┬─────────────────────────────────┘
                            │ HTTP/gRPC API
┌───────────────────────────▼─────────────────────────────────┐
│                      推送网关层(API Gateway)                 │
│  ┌────────────────────────────────────────────────────────┐ │
│  │ 请求校验 | 限流控制 | 消息封装 | 路由分发 | 统计上报   │ │
│  └────────────────────┬───────────────────────────────────┘ │
└───────────────────────┼─────────────────────────────────────┘
                        │
            ┌───────────┴───────────┐
            │  消息队列(Kafka/RabbitMQ)│
            └───────────┬───────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
┌───────▼──────┐ ┌─────▼──────┐ ┌─────▼──────┐
│推送调度服务1 │ │推送调度服务2│ │推送调度服务N│
│(Logic Server)│ │(Logic Server)│ │(Logic Server)│
└──────┬───────┘ └──────┬──────┘ └──────┬─────┘
       │                │               │
       │   ┌────────────┴────────┐      │
       │   │   用户连接路由表     │      │
       │   │   (Redis Cluster)   │      │
       │   └─────────────────────┘      │
       │                                │
┌──────┴────────────────────────────────┴──────┐
│          长连接服务集群(Connection Server)     │
│  ┌─────────┐  ┌─────────┐      ┌─────────┐  │
│  │ 连接池1  │  │ 连接池2  │ ...  │ 连接池N  │  │
│  │10万连接 │  │10万连接 │      │10万连接 │  │
│  └────┬────┘  └────┬────┘      └────┬────┘  │
└───────┼────────────┼─────────────────┼───────┘
        │            │                 │
┌───────▼────────────▼─────────────────▼───────┐
│           客户端设备(Mobile/Web/Desktop)       │
│  ┌──────┐  ┌──────┐  ┌──────┐  ┌──────┐    │
│  │iOS App│ │Android│ │Web端 │ │PC端  │    │
│  └──────┘  └──────┘  └──────┘  └──────┘    │
└──────────────────────────────────────────────┘

              ┌─────────────────┐
              │  第三方推送通道  │
              ├─────────────────┤
              │ APNs (iOS)      │
              │ FCM (Android)   │
              │ 各厂商推送(华为/小米)│
              └─────────────────┘
```

#### 2.2 分层职责

##### **1. API 网关层(Push Gateway)**
```go
// 核心职责
type PushGateway interface {
    // 接收推送请求并初步校验
    ReceivePushRequest(req *PushRequest) error

    // 限流保护(令牌桶/漏桶算法)
    RateLimitCheck(appID string) bool

    // 消息格式化和封装
    BuildMessage(req *PushRequest) *Message

    // 路由到消息队列
    RouteToQueue(msg *Message) error
}

// 推送请求结构
type PushRequest struct {
    AppID       string            // 应用标识
    MessageID   string            // 消息唯一ID(幂等控制)
    TargetType  string            // single/group/broadcast
    TargetIDs   []string          // 目标用户ID列表
    Content     MessageContent    // 消息内容
    Priority    int               // 优先级 1-高 2-中 3-低
    ExpireTime  int64             // 过期时间戳
    PushTime    int64             // 定时推送时间(0=立即)
    Options     map[string]string // 扩展选项
}

type MessageContent struct {
    Title    string            // 通知标题
    Body     string            // 通知内容
    Data     map[string]string // 透传数据
    Sound    string            // 声音
    Badge    int               // 角标
    ImageURL string            // 图片URL
}
```

**功能细节**:
- **认证鉴权**: API Key + 签名验证,防止非法调用
- **限流策略**: 按 AppID 限流(QPS 限制),防止单个业务方占用过多资源
- **消息优先级队列**: 高优先级消息走独立队列优先处理
- **幂等设计**: 基于 MessageID 去重,防止重复推送

##### **2. 推送调度层(Logic Server)**
```go
// 核心职责
type LogicServer struct {
    messageQueue   *Kafka            // 消息队列
    userRouter     *RedisCluster     // 用户连接路由
    messageStore   *MySQL            // 消息持久化
    offlinePusher  *OfflinePusher    // 离线推送器
}

// 核心流程
func (s *LogicServer) ProcessMessage(msg *Message) {
    // 1. 查询用户在线状态和所在连接服务器
    onlineUsers := s.userRouter.GetOnlineUsers(msg.TargetIDs)

    // 2. 在线用户推送
    for userID, serverAddr := range onlineUsers {
        s.pushToConnectionServer(serverAddr, userID, msg)
    }

    // 3. 离线用户处理
    offlineUsers := s.getOfflineUsers(msg.TargetIDs, onlineUsers)
    if len(offlineUsers) > 0 {
        s.handleOfflineUsers(offlineUsers, msg)
    }

    // 4. 消息持久化(用于历史查询)
    s.messageStore.SaveMessage(msg)

    // 5. 推送结果回调
    s.reportPushResult(msg.MessageID, len(onlineUsers), len(offlineUsers))
}

// 离线推送处理
func (s *LogicServer) handleOfflineUsers(users []string, msg *Message) {
    for _, userID := range users {
        // 获取用户设备Token
        devices := s.getDeviceTokens(userID)

        for _, device := range devices {
            switch device.Platform {
            case "iOS":
                s.offlinePusher.PushViaAPNs(device.Token, msg)
            case "Android":
                s.offlinePusher.PushViaFCM(device.Token, msg)
            }
        }

        // 消息存入离线队列(用户上线后拉取)
        s.saveToOfflineQueue(userID, msg)
    }
}
```

**用户连接路由表设计**(Redis):
```
Key: user_connection:{userID}
Value: {
    "server_addr": "ws://conn-server-3:8080",
    "conn_id": "conn_uuid_12345",
    "platform": "iOS",
    "online_time": 1699999999,
    "last_heartbeat": 1700000100
}
TTL: 7200 秒(2小时无心跳自动过期)
```

##### **3. 长连接服务层(Connection Server)**
```go
// 核心职责
type ConnectionServer struct {
    connPool      *sync.Map         // 连接池: connID -> WebSocket
    userConnMap   *sync.Map         // 用户映射: userID -> []connID
    heartbeatMgr  *HeartbeatManager // 心跳管理器
}

// 连接管理
func (s *ConnectionServer) HandleConnection(ws *websocket.Conn) {
    conn := &Connection{
        ID:         uuid.New().String(),
        Conn:       ws,
        UserID:     "",                    // 认证后填充
        Platform:   "",
        LastActive: time.Now(),
        SendChan:   make(chan *Message, 100),
    }

    // 1. 连接认证(携带JWT Token)
    if err := s.authenticate(conn); err != nil {
        ws.Close()
        return
    }

    // 2. 注册连接到本地池和全局路由
    s.connPool.Store(conn.ID, conn)
    s.userConnMap.Store(conn.UserID, append(s.getUserConns(conn.UserID), conn.ID))
    s.registerToRouter(conn) // 写入Redis路由表

    // 3. 启动读写协程
    go s.readLoop(conn)
    go s.writeLoop(conn)

    // 4. 心跳管理
    s.heartbeatMgr.AddConnection(conn)
}

// 心跳机制
func (s *ConnectionServer) heartbeatLoop(conn *Connection) {
    ticker := time.NewTicker(30 * time.Second) // 客户端每30秒发送心跳
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            if time.Since(conn.LastActive) > 90*time.Second {
                // 90秒无活动,判定连接死亡
                s.closeConnection(conn)
                return
            }
        }
    }
}

// 消息推送
func (s *ConnectionServer) PushMessage(userID string, msg *Message) error {
    connIDs := s.getUserConns(userID)

    for _, connID := range connIDs {
        if conn, ok := s.connPool.Load(connID); ok {
            c := conn.(*Connection)
            select {
            case c.SendChan <- msg:
                // 投递成功
            default:
                // 通道满,丢弃或记录日志
                log.Warnf("send channel full for conn %s", connID)
            }
        }
    }
    return nil
}
```

**连接优化策略**:
- **连接复用**: 同一用户多设备共享逻辑连接(降低服务端压力)
- **分布式连接**: 使用一致性哈希将用户分散到不同 Connection Server
- **单机连接上限**: 每个服务器限制 10 万连接(通过 ulimit 和内存优化实现)

---

### 三、关键技术实现

#### 3.1 在线推送流程(实时推送)

```
┌────────┐    ① 推送请求      ┌──────────┐
│业务系统│──────────────────>│API网关   │
└────────┘                    └────┬─────┘
                                   │ ② 写入队列
                              ┌────▼─────┐
                              │Kafka队列 │
                              └────┬─────┘
                                   │ ③ 消费消息
                              ┌────▼──────┐
                              │Logic Server│
                              └────┬──────┘
                                   │ ④ 查询路由
                              ┌────▼─────┐
                              │Redis路由 │
                              └────┬─────┘
                                   │ ⑤ 转发消息
                         ┌─────────┴─────────┐
                         │                   │
                    ┌────▼────┐         ┌───▼────┐
                    │ConnSvr-1│         │ConnSvr-2│
                    └────┬────┘         └───┬────┘
                         │ ⑥ WebSocket推送  │
                    ┌────▼────┐         ┌───▼────┐
                    │用户A设备1│        │用户A设备2│
                    └─────────┘         └────────┘
```

**推送时延优化**:
- Kafka 分区优化: 按用户 ID 哈希分区,保证有序性
- Redis 读取优化: Pipeline 批量读取路由信息
- 长连接推送: 通过 channel 异步发送,避免阻塞

#### 3.2 离线推送流程(第三方通道)

```go
// APNs 推送(iOS)
type APNsPusher struct {
    client *apns2.Client
}

func (p *APNsPusher) Push(deviceToken string, msg *Message) error {
    notification := &apns2.Notification{
        DeviceToken: deviceToken,
        Topic:       "com.example.app",
        Payload: map[string]interface{}{
            "aps": map[string]interface{}{
                "alert": map[string]string{
                    "title": msg.Content.Title,
                    "body":  msg.Content.Body,
                },
                "badge": msg.Content.Badge,
                "sound": msg.Content.Sound,
            },
            "custom_data": msg.Content.Data,
        },
        Priority: apns2.PriorityHigh,
        Expiration: time.Now().Add(24 * time.Hour),
    }

    res, err := p.client.Push(notification)
    if err != nil {
        return err
    }

    // 处理推送结果
    if res.StatusCode != 200 {
        if res.Reason == apns2.ReasonBadDeviceToken {
            // Token 失效,从数据库删除
            p.deleteDeviceToken(deviceToken)
        }
        return fmt.Errorf("APNs error: %s", res.Reason)
    }

    return nil
}
```

**厂商推送选择策略**:
```go
func (s *OfflinePusher) SelectChannel(device *Device) PushChannel {
    // 优先级: 官方通道 > 厂商通道 > 降级通道

    switch device.Platform {
    case "iOS":
        return s.apnsPusher
    case "Android":
        // 根据设备品牌选择通道
        if device.Brand == "Huawei" {
            return s.huaweiPusher
        } else if device.Brand == "Xiaomi" {
            return s.xiaomiPusher
        } else {
            return s.fcmPusher
        }
    }
    return s.smsPusher // 最终降级到短信
}
```

#### 3.3 消息可靠性保障

##### **1. 消息持久化**
```sql
CREATE TABLE push_messages (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    message_id VARCHAR(64) UNIQUE NOT NULL,
    app_id VARCHAR(32) NOT NULL,
    target_type ENUM('single','group','broadcast'),
    content JSON NOT NULL,
    priority TINYINT DEFAULT 2,
    status TINYINT DEFAULT 0, -- 0待推送 1推送中 2成功 3失败
    success_count INT DEFAULT 0,
    fail_count INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_app_created (app_id, created_at),
    INDEX idx_status (status)
) ENGINE=InnoDB;
```

##### **2. 推送状态追踪**
```sql
CREATE TABLE push_records (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    message_id VARCHAR(64) NOT NULL,
    user_id VARCHAR(64) NOT NULL,
    device_id VARCHAR(128),
    push_channel ENUM('websocket','apns','fcm','vendor','sms'),
    status TINYINT, -- 0待推送 1成功 2失败 3过期
    error_msg VARCHAR(255),
    pushed_at TIMESTAMP,
    INDEX idx_message (message_id),
    INDEX idx_user (user_id, pushed_at)
) ENGINE=InnoDB;
```

##### **3. 失败重试机制**
```go
type RetryPolicy struct {
    MaxRetries    int           // 最大重试次数
    InitialDelay  time.Duration // 初始延迟
    MaxDelay      time.Duration // 最大延迟
    Multiplier    float64       // 延迟倍增因子
}

func (s *LogicServer) retryPush(msg *Message, retryCount int) {
    policy := RetryPolicy{
        MaxRetries:   3,
        InitialDelay: 5 * time.Second,
        MaxDelay:     60 * time.Second,
        Multiplier:   2.0,
    }

    if retryCount >= policy.MaxRetries {
        // 重试耗尽,记录失败并降级推送
        s.fallbackPush(msg)
        return
    }

    // 指数退避
    delay := time.Duration(float64(policy.InitialDelay) * math.Pow(policy.Multiplier, float64(retryCount)))
    if delay > policy.MaxDelay {
        delay = policy.MaxDelay
    }

    time.Sleep(delay)

    // 重新推送
    if err := s.ProcessMessage(msg); err != nil {
        s.retryPush(msg, retryCount+1)
    }
}
```

##### **4. 幂等性保证**
```go
// 基于Redis实现幂等去重
func (s *LogicServer) checkDuplicate(messageID string, userID string) bool {
    key := fmt.Sprintf("push:dedup:%s:%s", messageID, userID)

    // SETNX + 过期时间
    ok, err := s.redis.SetNX(key, "1", 24*time.Hour).Result()
    if err != nil || !ok {
        // 已存在,说明重复推送
        return true
    }

    return false
}
```

#### 3.4 海量推送优化(广播场景)

**问题**: 全员推送时,需要向千万用户发送消息,如何避免系统崩溃?

**解决方案 - 分批推送**:
```go
func (s *LogicServer) BroadcastPush(msg *Message) {
    // 1. 将广播消息拆分为批次任务
    batchSize := 10000 // 每批1万用户

    // 2. 从数据库分页读取用户ID
    offset := 0
    for {
        userIDs := s.getUserIDBatch(offset, batchSize)
        if len(userIDs) == 0 {
            break
        }

        // 3. 每批用户作为一个任务投递到队列
        task := &PushTask{
            MessageID: msg.MessageID,
            UserIDs:   userIDs,
            Content:   msg.Content,
        }
        s.messageQueue.Publish(task)

        offset += batchSize

        // 4. 限速控制(防止队列积压)
        time.Sleep(100 * time.Millisecond)
    }
}
```

**写扩散 vs 读扩散**:
- **写扩散**(推荐): 推送时为每个用户生成单独的消息记录,适合高实时性场景
- **读扩散**: 只存储一条广播消息,用户上线后主动拉取,适合非紧急通知

---

### 四、高可用和性能优化

#### 4.1 高可用设计

##### **1. 服务多副本部署**
```yaml
# Kubernetes 部署示例
apiVersion: apps/v1
kind: Deployment
metadata:
  name: connection-server
spec:
  replicas: 10  # 10个副本
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 1
  template:
    spec:
      containers:
      - name: conn-server
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
---
apiVersion: v1
kind: Service
metadata:
  name: connection-server-svc
spec:
  type: LoadBalancer
  ports:
  - port: 8080
    targetPort: 8080
```

##### **2. 故障检测和自动切换**
```go
// Connection Server 健康检查
func (s *ConnectionServer) HealthCheck() bool {
    // 检查指标
    activeConns := s.getActiveConnectionCount()
    memUsage := s.getMemoryUsage()
    cpuUsage := s.getCPUUsage()

    if activeConns > 100000 || memUsage > 0.9 || cpuUsage > 0.9 {
        return false // 不健康,从负载均衡摘除
    }

    return true
}

// 连接迁移(服务下线前)
func (s *ConnectionServer) GracefulShutdown() {
    // 1. 停止接受新连接
    s.stopAcceptingNewConns()

    // 2. 通知客户端重新连接(发送特殊消息)
    s.notifyClientsToReconnect()

    // 3. 等待所有连接关闭(超时强制关闭)
    s.waitForConnectionsDrain(30 * time.Second)

    // 4. 清理资源
    s.cleanup()
}
```

##### **3. 消息队列高可用**
- Kafka 集群部署(3个 Broker,副本数=3)
- 消费者组保证消息至少消费一次
- 死信队列存储失败消息

#### 4.2 性能优化

##### **1. 长连接优化**
```go
// 连接参数优化
func configureWebSocket(ws *websocket.Conn) {
    ws.SetReadDeadline(time.Now().Add(90 * time.Second))
    ws.SetWriteDeadline(time.Now().Add(10 * time.Second))

    // 启用压缩(减少流量)
    ws.EnableWriteCompression(true)

    // 设置缓冲区大小
    ws.SetReadBuffer(4096)
    ws.SetWriteBuffer(4096)
}

// 系统参数调优(Linux)
// /etc/sysctl.conf
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_fin_timeout = 30
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 8192
fs.file-max = 1000000

// ulimit 调整
ulimit -n 1000000  # 最大文件描述符
```

##### **2. 数据库优化**
```sql
-- 分库分表(按用户ID哈希)
CREATE TABLE push_records_0 (...);  -- 用户ID尾号0
CREATE TABLE push_records_1 (...);  -- 用户ID尾号1
...
CREATE TABLE push_records_9 (...);  -- 用户ID尾号9

-- 冷热数据分离
-- 热数据(近7天): 留在主表,频繁查询
-- 冷数据(7天前): 归档到历史表或对象存储
```

##### **3. Redis 优化**
```go
// 使用 Redis Cluster 提升吞吐
redisCluster := redis.NewClusterClient(&redis.ClusterOptions{
    Addrs: []string{
        "redis-node-1:6379",
        "redis-node-2:6379",
        "redis-node-3:6379",
    },
    PoolSize:     100,        // 连接池大小
    MinIdleConns: 10,
    ReadTimeout:  3 * time.Second,
    WriteTimeout: 3 * time.Second,
})

// Pipeline 批量操作
pipe := redisCluster.Pipeline()
for _, userID := range userIDs {
    key := fmt.Sprintf("user_connection:%s", userID)
    pipe.Get(key)
}
results, err := pipe.Exec()
```

---

### 五、监控和运维

#### 5.1 关键指标监控

```go
// Prometheus 指标定义
var (
    // 推送总量
    pushTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "push_total",
            Help: "Total number of push messages",
        },
        []string{"app_id", "status"}, // 标签: 应用ID, 状态(success/fail)
    )

    // 推送延迟
    pushLatency = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "push_latency_seconds",
            Help:    "Push latency distribution",
            Buckets: []float64{0.1, 0.5, 1, 3, 5, 10},
        },
        []string{"app_id"},
    )

    // 在线连接数
    activeConnections = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "active_connections",
            Help: "Number of active WebSocket connections",
        },
    )

    // 消息队列堆积
    queueLag = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "message_queue_lag",
            Help: "Message queue lag",
        },
    )
)
```

**告警规则**(Prometheus Alertmanager):
```yaml
groups:
- name: push_alerts
  rules:
  - alert: PushFailureRateHigh
    expr: rate(push_total{status="fail"}[5m]) / rate(push_total[5m]) > 0.05
    for: 5m
    annotations:
      summary: "推送失败率超过5%"

  - alert: PushLatencyHigh
    expr: histogram_quantile(0.99, push_latency_seconds) > 5
    for: 5m
    annotations:
      summary: "P99推送延迟超过5秒"

  - alert: QueueLagHigh
    expr: message_queue_lag > 100000
    for: 10m
    annotations:
      summary: "消息队列堆积超过10万条"
```

#### 5.2 日志追踪

```go
// 使用 OpenTelemetry 实现分布式追踪
func (s *LogicServer) ProcessMessageWithTracing(ctx context.Context, msg *Message) {
    ctx, span := tracer.Start(ctx, "LogicServer.ProcessMessage")
    defer span.End()

    span.SetAttributes(
        attribute.String("message_id", msg.MessageID),
        attribute.String("app_id", msg.AppID),
        attribute.Int("target_count", len(msg.TargetIDs)),
    )

    // 查询路由
    ctx, routeSpan := tracer.Start(ctx, "QueryRoute")
    onlineUsers := s.userRouter.GetOnlineUsers(msg.TargetIDs)
    routeSpan.End()

    // 推送到连接服务器
    ctx, pushSpan := tracer.Start(ctx, "PushToConnServer")
    for userID, serverAddr := range onlineUsers {
        s.pushToConnectionServer(ctx, serverAddr, userID, msg)
    }
    pushSpan.End()

    span.SetAttributes(attribute.Int("success_count", len(onlineUsers)))
}
```

---

### 六、容量评估

#### 6.1 场景假设
- **用户规模**: 5000万注册用户
- **日活用户**: 1000万(20%日活率)
- **在线峰值**: 300万并发在线
- **推送量**: 日均1亿条推送,峰值QPS 10万

#### 6.2 资源估算

##### **Connection Server**
```
单机连接数: 10万长连接
所需服务器数: 300万 / 10万 = 30台

单机配置:
- CPU: 8核
- 内存: 16GB (平均每连接占用 ~5KB)
- 网络: 1Gbps
```

##### **Logic Server**
```
峰值QPS: 10万/秒
单机处理能力: 5000 QPS(含数据库查询)
所需服务器数: 10万 / 5000 = 20台

单机配置:
- CPU: 16核
- 内存: 32GB
```

##### **Redis Cluster**
```
路由数据存储: 300万在线用户 * 200字节 = 600MB
冗余和扩展: 预留10倍空间 = 6GB
推荐配置: 6个节点(3主3从),每节点16GB内存
```

##### **Kafka**
```
消息大小: 平均 2KB/条
峰值流量: 10万条/秒 * 2KB = 200MB/s
存储保留: 7天 * 1亿条/天 * 2KB = 1.4TB
推荐配置: 6个Broker,每个4TB SSD
```

##### **MySQL**
```
消息记录: 1亿条/天 * 2KB = 200GB/天
分表策略: 按日期分表,每天一张表
历史数据: 保留30天热数据,超过归档到对象存储
推荐配置: 主从架构,主库64GB内存,2TB SSD
```

---

### 七、安全设计

#### 7.1 认证和加密
```go
// JWT Token 认证
func (s *ConnectionServer) authenticate(conn *Connection) error {
    // 从握手请求中获取Token
    token := conn.Conn.Request().Header.Get("Authorization")

    claims, err := jwt.ValidateToken(token)
    if err != nil {
        return fmt.Errorf("invalid token: %w", err)
    }

    conn.UserID = claims.UserID
    conn.Platform = claims.Platform

    return nil
}

// TLS 加密通信
tlsConfig := &tls.Config{
    MinVersion: tls.VersionTLS12,
    CipherSuites: []uint16{
        tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,
        tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,
    },
}
listener := tls.Listen("tcp", ":8443", tlsConfig)
```

#### 7.2 防刷和限流
```go
// 用户级限流(防止单个用户频繁推送)
func (s *APIGateway) checkUserRateLimit(userID string) bool {
    key := fmt.Sprintf("rate_limit:user:%s", userID)

    // 滑动窗口限流: 每分钟最多100条
    count, _ := s.redis.Incr(key).Result()
    if count == 1 {
        s.redis.Expire(key, 60*time.Second)
    }

    return count <= 100
}

// IP级限流(防止恶意攻击)
func (s *APIGateway) checkIPRateLimit(ip string) bool {
    key := fmt.Sprintf("rate_limit:ip:%s", ip)

    // 令牌桶算法: 每秒100次请求
    allowed, _ := s.rateLimiter.Allow(key, 100, time.Second)
    return allowed
}
```

---

## 面试回答要点总结

在面试中回答该问题时,可以按以下思路展开:

### 1. 开场破题(1-2分钟)
"消息推送系统的核心挑战在于**海量长连接管理**和**推送可靠性保障**。我会设计一个**分层架构**:
- API网关负责请求接入和限流
- 推送调度服务负责路由和调度
- 长连接服务维持与客户端的WebSocket连接
- 结合第三方推送通道(APNs/FCM)处理离线场景"

### 2. 核心架构讲解(3-4分钟)
- 画出架构图,重点讲解各层职责
- 强调**用户连接路由表**(Redis)的设计,这是实现精准推送的关键
- 说明在线推送和离线推送的分流处理

### 3. 技术难点深入(5-6分钟)
选择2-3个重点深入:
- **长连接优化**: 单机10万连接的实现(epoll/kqueue,内存优化,心跳机制)
- **消息可靠性**: 持久化、重试、幂等、ACK确认机制
- **广播推送**: 分批推送、写扩散策略、队列削峰

### 4. 扩展问题应对
- **如何支持亿级用户?** 水平扩展+分布式架构+数据分片
- **推送延迟如何优化到1秒内?** 优化队列、减少跳数、长连接预热
- **如何防止推送风暴?** 限流、分批推送、优先级队列

### 5. 总结(1分钟)
"这个系统的设计思想是**高内聚低耦合**,通过消息队列解耦各层,通过Redis缓存提升性能,通过多通道保证可靠性。在我之前的项目中,类似架构支撑了千万级DAU的推送需求,P99延迟控制在2秒内,到达率达到99.5%。"

---

## 参考资料
- [APNs官方文档](https://developer.apple.com/documentation/usernotifications)
- [Firebase Cloud Messaging](https://firebase.google.com/docs/cloud-messaging)
- [WebSocket协议RFC6455](https://tools.ietf.org/html/rfc6455)
- [极光推送架构设计](https://docs.jiguang.cn/)
