---
title: 设计一个视频转码系统
tags:
  - 系统设计
status: robot
class: 系统设计
slug: video-transcoding-system-design
ref:
---

## 核心要点提炼

**系统定位**: 支持海量视频上传、转码、分发的视频处理平台,类似 YouTube/B站 后台转码系统

**技术核心**:
- **分布式转码**: 任务队列 + 转码Worker集群,支持水平扩展
- **多格式输出**: 自适应码率(ABR),生成多清晰度版本(1080p/720p/480p等)
- **转码加速**: FFmpeg 硬件加速(GPU/FPGA)、切片并行转码
- **存储优化**: 对象存储(OSS/S3)、CDN 加速分发

**关键指标**: 转码成功率 >99%、平均转码时长 < 视频时长×0.5、并发处理能力 1万+视频/小时

---

## 详细设计方案

### 一、需求分析

#### 1.1 功能需求
- **视频上传**: 支持大文件上传(分片上传、断点续传)
- **格式转换**: 支持常见格式互转(MP4/MOV/AVI/FLV → MP4/HLS)
- **多码率输出**: 生成多个清晰度版本(4K/1080p/720p/480p/360p)
- **视频处理**: 添加水印、字幕、片头片尾、视频剪辑
- **截图封面**: 自动提取关键帧生成封面图
- **音频提取**: 独立音频轨道提取
- **进度追踪**: 实时显示转码进度和状态

#### 1.2 非功能需求
- **高吞吐**: 支持每小时处理 1 万个视频
- **高效率**: 转码速度 ≥ 2x(即10分钟视频5分钟内完成)
- **可靠性**: 转码成功率 > 99%,失败自动重试
- **可扩展**: 支持动态增减转码节点
- **成本优化**: 按需分配资源,低优先级任务可排队

#### 1.3 典型场景
```
场景1: 用户上传视频
1. 用户上传原始视频(1080p, 500MB, MOV格式)
2. 系统转码为:
   - 1080p MP4 (H.264)
   - 720p MP4
   - 480p MP4
   - HLS切片(用于流媒体播放)
3. 生成3张封面缩略图
4. 添加水印(可选)
5. 上传CDN,更新视频状态为"可播放"

场景2: 直播录像转码
1. 直播结束,生成录像文件(FLV, 2小时)
2. 转码为MP4并切片
3. 生成时间轴缩略图(每10秒一张)
4. 归档到对象存储
```

---

### 二、核心架构设计

#### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────┐
│                      用户层(客户端)                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │Web上传   │  │移动端App │  │开放API   │  │管理后台  │   │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘   │
│       │             │              │             │          │
│       └─────────────┴──────────────┴─────────────┘          │
└───────────────────────────┬─────────────────────────────────┘
                            │ HTTPS
┌───────────────────────────▼─────────────────────────────────┐
│                      API网关层                               │
│  ┌────────────────────────────────────────────────────────┐ │
│  │  上传接口 | 状态查询 | 任务管理 | 权限校验             │ │
│  └────────────────────┬───────────────────────────────────┘ │
└───────────────────────┼─────────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
┌───────▼──────┐ ┌─────▼──────┐ ┌─────▼──────┐
│上传服务      │ │任务调度服务│ │状态管理服务│
│(Upload Svc)  │ │(Scheduler) │ │(State Svc) │
└──────┬───────┘ └──────┬──────┘ └──────┬─────┘
       │                │               │
       │         ┌──────▼──────┐        │
       │         │ 任务队列     │        │
       └────────>│ (Kafka/     │<───────┘
                 │  RabbitMQ)  │
                 └──────┬──────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
┌───────▼──────┐ ┌─────▼──────┐ ┌─────▼──────┐
│转码Worker-1  │ │转码Worker-2│ │转码Worker-N│
│ ┌──────────┐ │ │ ┌──────────┐│ │ ┌──────────┐│
│ │FFmpeg GPU│ │ │ │FFmpeg GPU│ │ │ │FFmpeg GPU│ │
│ └──────────┘ │ │ └──────────┘│ │ └──────────┘│
└──────┬───────┘ └──────┬──────┘ └──────┬─────┘
       │                │               │
       └────────────────┼───────────────┘
                        │
        ┌───────────────┴───────────────┐
        │                               │
┌───────▼──────┐                 ┌──────▼──────┐
│对象存储(OSS/S3)│                │Redis缓存    │
│ - 原始视频    │                │ - 任务状态   │
│ - 转码结果    │                │ - 进度信息   │
│ - 封面图片    │                │ - 元数据     │
└──────┬───────┘                 └─────────────┘
       │
       │ CDN分发
┌──────▼───────┐
│CDN边缘节点   │
│ - 加速播放   │
│ - 就近访问   │
└──────────────┘

┌──────────────────────────────────────────────────────────────┐
│                    元数据数据库(MySQL)                        │
│  ┌────────────┐  ┌────────────┐  ┌────────────┐            │
│  │视频信息表  │  │转码任务表  │  │转码记录表  │            │
│  └────────────┘  └────────────┘  └────────────┘            │
└──────────────────────────────────────────────────────────────┘
```

#### 2.2 数据模型设计

##### **1. 视频信息表**
```sql
CREATE TABLE videos (
    video_id BIGINT PRIMARY KEY AUTO_INCREMENT,
    video_uuid VARCHAR(36) UNIQUE NOT NULL,
    user_id BIGINT NOT NULL,
    title VARCHAR(255),
    description TEXT,
    duration INT,                    -- 时长(秒)
    original_url VARCHAR(512),       -- 原始视频OSS路径
    original_size BIGINT,            -- 原始文件大小(字节)
    original_format VARCHAR(32),     -- 原始格式(mov/avi/mp4等)
    original_resolution VARCHAR(32), -- 原始分辨率(1920x1080)
    status ENUM('uploading','uploaded','transcoding','completed','failed') DEFAULT 'uploading',
    cover_url VARCHAR(512),          -- 封面图URL
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_user_created (user_id, created_at),
    INDEX idx_status (status)
) ENGINE=InnoDB;
```

##### **2. 转码任务表**
```sql
CREATE TABLE transcode_tasks (
    task_id BIGINT PRIMARY KEY AUTO_INCREMENT,
    task_uuid VARCHAR(36) UNIQUE NOT NULL,
    video_id BIGINT NOT NULL,
    priority TINYINT DEFAULT 3,      -- 优先级 1=高 2=中 3=低
    status ENUM('pending','processing','completed','failed','cancelled') DEFAULT 'pending',
    worker_id VARCHAR(64),           -- 执行的Worker节点ID
    retry_count INT DEFAULT 0,       -- 重试次数
    max_retries INT DEFAULT 3,       -- 最大重试次数
    error_msg VARCHAR(512),          -- 错误信息
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    INDEX idx_status_priority (status, priority, created_at),
    INDEX idx_video (video_id),
    FOREIGN KEY (video_id) REFERENCES videos(video_id)
) ENGINE=InnoDB;
```

##### **3. 转码输出表**
```sql
CREATE TABLE transcode_outputs (
    output_id BIGINT PRIMARY KEY AUTO_INCREMENT,
    task_id BIGINT NOT NULL,
    video_id BIGINT NOT NULL,
    resolution VARCHAR(32),          -- 分辨率(1080p/720p等)
    bitrate INT,                     -- 码率(kbps)
    format VARCHAR(32),              -- 格式(mp4/hls)
    codec VARCHAR(32),               -- 编码(h264/h265)
    file_size BIGINT,                -- 文件大小(字节)
    url VARCHAR(512),                -- OSS存储路径
    cdn_url VARCHAR(512),            -- CDN加速URL
    duration INT,                    -- 转码后时长(秒)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_task (task_id),
    INDEX idx_video (video_id),
    FOREIGN KEY (task_id) REFERENCES transcode_tasks(task_id),
    FOREIGN KEY (video_id) REFERENCES videos(video_id)
) ENGINE=InnoDB;
```

##### **4. 转码配置模板**
```sql
CREATE TABLE transcode_templates (
    template_id INT PRIMARY KEY AUTO_INCREMENT,
    template_name VARCHAR(64) NOT NULL,
    resolution VARCHAR(32),          -- 输出分辨率
    video_bitrate INT,               -- 视频码率(kbps)
    audio_bitrate INT,               -- 音频码率(kbps)
    video_codec VARCHAR(32),         -- 视频编码(h264/h265/vp9)
    audio_codec VARCHAR(32),         -- 音频编码(aac/opus)
    format VARCHAR(32),              -- 输出格式(mp4/hls/dash)
    frame_rate INT,                  -- 帧率(25/30/60)
    preset VARCHAR(32),              -- 编码预设(fast/medium/slow)
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY uk_name (template_name)
) ENGINE=InnoDB;

-- 预置模板数据
INSERT INTO transcode_templates (template_name, resolution, video_bitrate, audio_bitrate, video_codec, audio_codec, format, frame_rate, preset) VALUES
('1080p_high', '1920x1080', 4000, 192, 'h264', 'aac', 'mp4', 30, 'medium'),
('1080p_standard', '1920x1080', 2500, 128, 'h264', 'aac', 'mp4', 30, 'fast'),
('720p', '1280x720', 1500, 128, 'h264', 'aac', 'mp4', 30, 'fast'),
('480p', '854x480', 800, 96, 'h264', 'aac', 'mp4', 25, 'fast'),
('360p', '640x360', 400, 64, 'h264', 'aac', 'mp4', 25, 'fast'),
('hls_adaptive', 'adaptive', 0, 0, 'h264', 'aac', 'hls', 30, 'fast');
```

---

### 三、核心流程实现

#### 3.1 视频上传流程

```go
// 1. 分片上传处理
type UploadService struct {
    ossClient *oss.Client
    redis     *redis.Client
    mysql     *sql.DB
}

// 初始化分片上传
func (s *UploadService) InitMultipartUpload(req *UploadInitRequest) (*UploadInitResponse, error) {
    // 1. 生成视频UUID
    videoUUID := uuid.New().String()

    // 2. 在数据库创建视频记录
    videoID, err := s.createVideo(req.UserID, req.FileName, req.FileSize, "uploading")
    if err != nil {
        return nil, err
    }

    // 3. 初始化OSS分片上传
    objectKey := fmt.Sprintf("videos/original/%s/%s", videoUUID, req.FileName)
    uploadID, err := s.ossClient.InitiateMultipartUpload(objectKey)
    if err != nil {
        return nil, err
    }

    // 4. 在Redis缓存上传会话信息
    uploadKey := fmt.Sprintf("upload:session:%s", videoUUID)
    s.redis.HMSet(uploadKey, map[string]interface{}{
        "video_id":  videoID,
        "upload_id": uploadID,
        "object_key": objectKey,
        "total_chunks": req.TotalChunks,
        "uploaded_chunks": 0,
    })
    s.redis.Expire(uploadKey, 24*time.Hour) // 24小时过期

    return &UploadInitResponse{
        VideoUUID: videoUUID,
        UploadID:  uploadID,
    }, nil
}

// 上传分片
func (s *UploadService) UploadChunk(req *UploadChunkRequest) error {
    uploadKey := fmt.Sprintf("upload:session:%s", req.VideoUUID)

    // 1. 获取上传会话信息
    session, err := s.redis.HGetAll(uploadKey).Result()
    if err != nil {
        return errors.New("upload session not found")
    }

    // 2. 上传分片到OSS
    partNum := req.ChunkIndex + 1 // OSS分片编号从1开始
    etag, err := s.ossClient.UploadPart(session["upload_id"], session["object_key"], partNum, req.ChunkData)
    if err != nil {
        return err
    }

    // 3. 记录已上传的分片信息
    partKey := fmt.Sprintf("upload:parts:%s", req.VideoUUID)
    s.redis.HSet(partKey, fmt.Sprintf("part_%d", partNum), etag)

    // 4. 更新上传进度
    uploadedChunks := s.redis.HIncrBy(uploadKey, "uploaded_chunks", 1).Val()
    totalChunks, _ := strconv.ParseInt(session["total_chunks"], 10, 64)

    // 5. 检查是否全部上传完成
    if uploadedChunks == totalChunks {
        go s.completeUpload(req.VideoUUID, session)
    }

    return nil
}

// 完成上传
func (s *UploadService) completeUpload(videoUUID string, session map[string]string) error {
    // 1. 获取所有分片ETag
    partKey := fmt.Sprintf("upload:parts:%s", videoUUID)
    parts, _ := s.redis.HGetAll(partKey).Result()

    var partInfos []oss.Part
    for partNumStr, etag := range parts {
        partNum, _ := strconv.Atoi(strings.TrimPrefix(partNumStr, "part_"))
        partInfos = append(partInfos, oss.Part{PartNumber: partNum, ETag: etag})
    }

    // 按分片编号排序
    sort.Slice(partInfos, func(i, j int) bool {
        return partInfos[i].PartNumber < partInfos[j].PartNumber
    })

    // 2. 完成OSS分片上传
    err := s.ossClient.CompleteMultipartUpload(session["upload_id"], session["object_key"], partInfos)
    if err != nil {
        return err
    }

    // 3. 更新视频状态为"已上传"
    videoID, _ := strconv.ParseInt(session["video_id"], 10, 64)
    s.updateVideoStatus(videoID, "uploaded", session["object_key"])

    // 4. 提取视频元信息(异步)
    go s.extractVideoMetadata(videoID, session["object_key"])

    // 5. 创建转码任务(异步)
    go s.createTranscodeTask(videoID)

    // 6. 清理Redis缓存
    s.redis.Del(fmt.Sprintf("upload:session:%s", videoUUID))
    s.redis.Del(partKey)

    return nil
}
```

#### 3.2 转码任务调度流程

```go
// 转码调度服务
type TranscodeScheduler struct {
    kafka     *kafka.Producer
    redis     *redis.Client
    mysql     *sql.DB
}

// 创建转码任务
func (s *TranscodeScheduler) CreateTranscodeTask(videoID int64) error {
    // 1. 获取视频信息
    video, err := s.getVideo(videoID)
    if err != nil {
        return err
    }

    // 2. 选择转码模板(根据原始分辨率)
    templates := s.selectTemplates(video.OriginalResolution)

    // 3. 为每个模板创建转码子任务
    taskUUID := uuid.New().String()
    taskID, err := s.createTask(videoID, taskUUID, len(templates))
    if err != nil {
        return err
    }

    // 4. 将子任务推送到消息队列
    for _, template := range templates {
        task := &TranscodeMessage{
            TaskID:     taskID,
            TaskUUID:   taskUUID,
            VideoID:    videoID,
            SourceURL:  video.OriginalURL,
            Template:   template,
            Priority:   s.calculatePriority(video.UserID), // 根据用户等级计算优先级
            CreatedAt:  time.Now().Unix(),
        }

        // 根据优先级选择不同的Kafka Topic
        topic := fmt.Sprintf("transcode_tasks_p%d", task.Priority)
        s.kafka.Publish(topic, task)
    }

    // 5. 更新视频状态
    s.updateVideoStatus(videoID, "transcoding")

    return nil
}

// 选择转码模板
func (s *TranscodeScheduler) selectTemplates(originalResolution string) []Template {
    // 解析原始分辨率
    width, height := parseResolution(originalResolution) // 例如 "1920x1080" -> 1920, 1080

    templates := []Template{}

    // 根据原始分辨率选择合适的输出分辨率(不能超过原始)
    if height >= 1080 {
        templates = append(templates, s.getTemplate("1080p_standard"))
    }
    if height >= 720 {
        templates = append(templates, s.getTemplate("720p"))
    }
    if height >= 480 {
        templates = append(templates, s.getTemplate("480p"))
    }
    // 低分辨率视频也生成360p(移动端)
    templates = append(templates, s.getTemplate("360p"))

    // 生成HLS自适应码率版本
    templates = append(templates, s.getTemplate("hls_adaptive"))

    return templates
}
```

#### 3.3 转码Worker核心逻辑

```go
// 转码Worker
type TranscodeWorker struct {
    workerID  string
    kafka     *kafka.Consumer
    ossClient *oss.Client
    redis     *redis.Client
    mysql     *sql.DB
    ffmpeg    *FFmpegExecutor
}

func (w *TranscodeWorker) Run() {
    // 1. 订阅多个优先级的Kafka Topic
    topics := []string{"transcode_tasks_p1", "transcode_tasks_p2", "transcode_tasks_p3"}
    w.kafka.Subscribe(topics)

    for {
        // 2. 消费转码任务(优先消费高优先级)
        msg := w.kafka.Poll(1 * time.Second)
        if msg == nil {
            continue
        }

        task := &TranscodeMessage{}
        json.Unmarshal(msg.Value, task)

        // 3. 执行转码
        w.processTask(task)
    }
}

func (w *TranscodeWorker) processTask(task *TranscodeMessage) {
    ctx := context.Background()

    // 1. 更新任务状态为"处理中"
    w.updateTaskStatus(task.TaskID, "processing", w.workerID)

    // 2. 下载原始视频到本地临时目录
    localInputPath := fmt.Sprintf("/tmp/transcode/%d/input.mp4", task.VideoID)
    err := w.downloadVideo(task.SourceURL, localInputPath)
    if err != nil {
        w.handleError(task, err)
        return
    }
    defer os.Remove(localInputPath)

    // 3. 执行FFmpeg转码
    localOutputPath := fmt.Sprintf("/tmp/transcode/%d/output_%s.mp4",
        task.VideoID, task.Template.Resolution)

    transcodeParams := w.buildFFmpegParams(localInputPath, localOutputPath, task.Template)

    // 启动转码并监控进度
    progressChan := make(chan float64)
    go w.ffmpeg.Execute(ctx, transcodeParams, progressChan)

    // 4. 实时更新转码进度到Redis
    for progress := range progressChan {
        progressKey := fmt.Sprintf("transcode:progress:%d", task.TaskID)
        w.redis.Set(progressKey, fmt.Sprintf("%.2f", progress), 10*time.Minute)
    }

    // 5. 转码完成,上传到OSS
    outputKey := fmt.Sprintf("videos/transcoded/%s/%s_%s.mp4",
        task.TaskUUID, task.VideoID, task.Template.Resolution)

    outputURL, err := w.uploadToOSS(localOutputPath, outputKey)
    if err != nil {
        w.handleError(task, err)
        return
    }
    defer os.Remove(localOutputPath)

    // 6. 获取输出文件信息
    outputInfo, _ := os.Stat(localOutputPath)

    // 7. 保存转码输出记录
    w.saveOutput(&TranscodeOutput{
        TaskID:     task.TaskID,
        VideoID:    task.VideoID,
        Resolution: task.Template.Resolution,
        Bitrate:    task.Template.VideoBitrate,
        Format:     task.Template.Format,
        Codec:      task.Template.VideoCodec,
        FileSize:   outputInfo.Size(),
        URL:        outputURL,
    })

    // 8. 更新任务状态为"完成"
    w.updateTaskStatus(task.TaskID, "completed", "")

    // 9. 检查是否所有子任务完成
    if w.allSubTasksCompleted(task.TaskID) {
        w.updateVideoStatus(task.VideoID, "completed")

        // 生成封面图(异步)
        go w.generateThumbnails(task.VideoID, localInputPath)

        // 推送CDN预热
        go w.cdnPreheat(task.VideoID)
    }

    log.Infof("Transcode completed: task=%d, video=%d, resolution=%s",
        task.TaskID, task.VideoID, task.Template.Resolution)
}

// 构建FFmpeg参数
func (w *TranscodeWorker) buildFFmpegParams(input, output string, tpl Template) []string {
    params := []string{
        "-i", input,
        "-c:v", tpl.VideoCodec, // 视频编码器
        "-b:v", fmt.Sprintf("%dk", tpl.VideoBitrate), // 视频码率
        "-c:a", tpl.AudioCodec, // 音频编码器
        "-b:a", fmt.Sprintf("%dk", tpl.AudioBitrate), // 音频码率
        "-r", fmt.Sprintf("%d", tpl.FrameRate), // 帧率
        "-s", tpl.Resolution, // 分辨率
        "-preset", tpl.Preset, // 编码速度预设
    }

    // GPU硬件加速(NVIDIA)
    if w.hasGPU() {
        params = append([]string{"-hwaccel", "cuda", "-hwaccel_output_format", "cuda"}, params...)
        // 使用硬件编码器
        if tpl.VideoCodec == "h264" {
            params[5] = "h264_nvenc"
        } else if tpl.VideoCodec == "h265" {
            params[5] = "hevc_nvenc"
        }
    }

    // 两遍编码(质量更好)
    if tpl.Preset == "slow" {
        params = append(params, "-pass", "2")
    }

    // 输出文件
    params = append(params, "-y", output) // -y 覆盖已存在文件

    return params
}

// FFmpeg执行器(监控进度)
type FFmpegExecutor struct{}

func (e *FFmpegExecutor) Execute(ctx context.Context, params []string, progressChan chan float64) error {
    cmd := exec.CommandContext(ctx, "ffmpeg", params...)

    // 捕获stderr输出(FFmpeg进度信息在stderr)
    stderr, _ := cmd.StderrPipe()
    cmd.Start()

    scanner := bufio.NewScanner(stderr)
    durationRegex := regexp.MustCompile(`Duration: (\d{2}):(\d{2}):(\d{2})`)
    timeRegex := regexp.MustCompile(`time=(\d{2}):(\d{2}):(\d{2})`)

    var totalSeconds float64
    for scanner.Scan() {
        line := scanner.Text()

        // 提取视频总时长
        if matches := durationRegex.FindStringSubmatch(line); matches != nil {
            h, _ := strconv.Atoi(matches[1])
            m, _ := strconv.Atoi(matches[2])
            s, _ := strconv.Atoi(matches[3])
            totalSeconds = float64(h*3600 + m*60 + s)
        }

        // 提取当前处理时间
        if matches := timeRegex.FindStringSubmatch(line); matches != nil {
            h, _ := strconv.Atoi(matches[1])
            m, _ := strconv.Atoi(matches[2])
            s, _ := strconv.Atoi(matches[3])
            currentSeconds := float64(h*3600 + m*60 + s)

            if totalSeconds > 0 {
                progress := (currentSeconds / totalSeconds) * 100
                progressChan <- progress
            }
        }
    }

    close(progressChan)
    return cmd.Wait()
}
```

#### 3.4 HLS 自适应码率转码

```go
// 生成HLS自适应码率版本(用于流媒体播放)
func (w *TranscodeWorker) transcodeToHLS(task *TranscodeMessage) error {
    localInputPath := fmt.Sprintf("/tmp/transcode/%d/input.mp4", task.VideoID)
    hlsDir := fmt.Sprintf("/tmp/transcode/%d/hls/", task.VideoID)
    os.MkdirAll(hlsDir, 0755)
    defer os.RemoveAll(hlsDir)

    // 生成多个码率版本
    resolutions := []struct {
        Name    string
        Scale   string
        Bitrate string
    }{
        {"1080p", "1920:1080", "4000k"},
        {"720p", "1280:720", "2500k"},
        {"480p", "854:480", "1000k"},
        {"360p", "640:360", "600k"},
    }

    // FFmpeg HLS命令
    params := []string{"-i", localInputPath}

    for i, res := range resolutions {
        params = append(params,
            "-map", "0:v", "-map", "0:a",
            "-s:v:"+strconv.Itoa(i), res.Scale,
            "-b:v:"+strconv.Itoa(i), res.Bitrate,
            "-b:a:"+strconv.Itoa(i), "128k",
        )
    }

    // HLS输出参数
    params = append(params,
        "-f", "hls",
        "-hls_time", "10", // 每个切片10秒
        "-hls_playlist_type", "vod",
        "-hls_segment_filename", hlsDir+"segment_%v_%03d.ts",
        "-master_pl_name", "master.m3u8",
        "-var_stream_map", "v:0,a:0 v:1,a:1 v:2,a:2 v:3,a:3",
        hlsDir+"stream_%v.m3u8",
    )

    // 执行转码
    cmd := exec.Command("ffmpeg", params...)
    err := cmd.Run()
    if err != nil {
        return err
    }

    // 上传所有生成的文件到OSS
    files, _ := ioutil.ReadDir(hlsDir)
    for _, file := range files {
        localPath := hlsDir + file.Name()
        ossKey := fmt.Sprintf("videos/hls/%s/%s", task.TaskUUID, file.Name())
        w.uploadToOSS(localPath, ossKey)
    }

    return nil
}
```

#### 3.5 封面图生成

```go
// 生成视频封面缩略图
func (w *TranscodeWorker) generateThumbnails(videoID int64, videoPath string) error {
    // 1. 获取视频时长
    duration := w.getVideoDuration(videoPath)

    // 2. 在3个时间点截图(10%, 50%, 90%)
    timestamps := []float64{
        duration * 0.1,
        duration * 0.5,
        duration * 0.9,
    }

    thumbnailURLs := []string{}

    for i, ts := range timestamps {
        outputPath := fmt.Sprintf("/tmp/thumbnail_%d_%d.jpg", videoID, i)

        // FFmpeg截图命令
        params := []string{
            "-i", videoPath,
            "-ss", fmt.Sprintf("%.2f", ts), // 跳转到时间点
            "-vframes", "1", // 提取1帧
            "-vf", "scale=320:180", // 缩放到320x180
            "-y", outputPath,
        }

        cmd := exec.Command("ffmpeg", params...)
        err := cmd.Run()
        if err != nil {
            continue
        }

        // 上传到OSS
        ossKey := fmt.Sprintf("videos/thumbnails/%d/thumb_%d.jpg", videoID, i)
        url, _ := w.uploadToOSS(outputPath, ossKey)
        thumbnailURLs = append(thumbnailURLs, url)

        os.Remove(outputPath)
    }

    // 3. 更新数据库,设置第一张为封面
    if len(thumbnailURLs) > 0 {
        w.updateVideoCover(videoID, thumbnailURLs[0])
    }

    return nil
}
```

---

### 四、高级特性实现

#### 4.1 切片并行转码(加速长视频)

```go
// 对于长视频(>1小时),切片并行转码可大幅提升速度

func (w *TranscodeWorker) parallelTranscode(task *TranscodeMessage) error {
    duration := w.getVideoDuration(task.SourceURL)

    // 1. 将视频切分为5分钟一段
    segmentDuration := 300.0 // 5分钟
    numSegments := int(math.Ceil(duration / segmentDuration))

    // 2. 并行转码每一段
    var wg sync.WaitGroup
    segmentFiles := make([]string, numSegments)

    for i := 0; i < numSegments; i++ {
        wg.Add(1)
        go func(segmentIdx int) {
            defer wg.Done()

            startTime := float64(segmentIdx) * segmentDuration
            outputPath := fmt.Sprintf("/tmp/segment_%d_%d.mp4", task.VideoID, segmentIdx)

            // FFmpeg切片转码
            params := []string{
                "-ss", fmt.Sprintf("%.2f", startTime),
                "-t", fmt.Sprintf("%.2f", segmentDuration),
                "-i", task.SourceURL,
                "-c:v", task.Template.VideoCodec,
                "-b:v", fmt.Sprintf("%dk", task.Template.VideoBitrate),
                "-y", outputPath,
            }

            cmd := exec.Command("ffmpeg", params...)
            cmd.Run()

            segmentFiles[segmentIdx] = outputPath
        }(i)
    }

    wg.Wait()

    // 3. 合并所有切片
    concatListPath := fmt.Sprintf("/tmp/concat_%d.txt", task.VideoID)
    concatList := ""
    for _, file := range segmentFiles {
        concatList += fmt.Sprintf("file '%s'\n", file)
    }
    ioutil.WriteFile(concatListPath, []byte(concatList), 0644)

    finalOutputPath := fmt.Sprintf("/tmp/final_%d.mp4", task.VideoID)
    params := []string{
        "-f", "concat",
        "-safe", "0",
        "-i", concatListPath,
        "-c", "copy", // 直接拷贝,不重新编码
        "-y", finalOutputPath,
    }

    cmd := exec.Command("ffmpeg", params...)
    cmd.Run()

    // 4. 上传最终文件
    w.uploadToOSS(finalOutputPath, task.OutputKey)

    // 5. 清理临时文件
    os.Remove(concatListPath)
    os.Remove(finalOutputPath)
    for _, file := range segmentFiles {
        os.Remove(file)
    }

    return nil
}
```

#### 4.2 水印添加

```go
// 在转码时添加水印
func (w *TranscodeWorker) addWatermark(inputPath, outputPath, watermarkPath string) error {
    // FFmpeg水印参数
    params := []string{
        "-i", inputPath,
        "-i", watermarkPath,
        "-filter_complex",
        "[1:v]scale=120:40[wm];[0:v][wm]overlay=W-w-10:H-h-10", // 右下角,距离边缘10像素
        "-codec:a", "copy", // 音频直接拷贝
        "-y", outputPath,
    }

    cmd := exec.Command("ffmpeg", params...)
    return cmd.Run()
}
```

#### 4.3 失败重试机制

```go
// 转码失败自动重试
func (w *TranscodeWorker) handleError(task *TranscodeMessage, err error) {
    // 1. 记录错误信息
    w.updateTaskError(task.TaskID, err.Error())

    // 2. 检查重试次数
    retryCount := w.getRetryCount(task.TaskID)
    if retryCount >= task.MaxRetries {
        // 重试次数耗尽,标记为失败
        w.updateTaskStatus(task.TaskID, "failed", "")
        w.updateVideoStatus(task.VideoID, "failed")

        // 发送告警通知
        w.sendAlert(task, err)
        return
    }

    // 3. 增加重试计数
    w.incrementRetryCount(task.TaskID)

    // 4. 延迟后重新推送到队列
    delay := time.Duration(math.Pow(2, float64(retryCount))) * time.Minute // 指数退避: 2^n分钟
    time.Sleep(delay)

    w.kafka.Publish(fmt.Sprintf("transcode_tasks_p%d", task.Priority), task)

    log.Warnf("Retry transcode task: task=%d, retry=%d/%d, error=%v",
        task.TaskID, retryCount+1, task.MaxRetries, err)
}
```

#### 4.4 转码进度实时查询

```go
// API接口: 查询转码进度
func (api *TranscodeAPI) GetProgress(videoID int64) (*ProgressResponse, error) {
    // 1. 查询所有子任务
    tasks := api.getVideoTasks(videoID)

    totalProgress := 0.0
    completedTasks := 0

    for _, task := range tasks {
        if task.Status == "completed" {
            completedTasks++
            totalProgress += 100.0
        } else if task.Status == "processing" {
            // 从Redis获取实时进度
            progressKey := fmt.Sprintf("transcode:progress:%d", task.TaskID)
            progress, _ := api.redis.Get(progressKey).Float64()
            totalProgress += progress
        }
    }

    // 2. 计算总体进度
    overallProgress := totalProgress / float64(len(tasks))

    return &ProgressResponse{
        VideoID:        videoID,
        Status:         api.getVideoStatus(videoID),
        Progress:       overallProgress,
        CompletedTasks: completedTasks,
        TotalTasks:     len(tasks),
    }, nil
}
```

---

### 五、性能优化

#### 5.1 GPU硬件加速

```bash
# NVIDIA GPU加速(使用NVENC编码器)
# 性能提升: 转码速度提升 3-5倍

# 检测GPU
ffmpeg -hwaccels

# GPU加速转码示例
ffmpeg -hwaccel cuda -hwaccel_output_format cuda \
  -i input.mp4 \
  -c:v h264_nvenc -preset fast -b:v 2000k \
  -c:a aac -b:a 128k \
  output.mp4

# Worker配置要求
# - NVIDIA GPU (Tesla T4/V100等)
# - CUDA Toolkit 11.x
# - FFmpeg编译时启用 --enable-cuda-nvcc --enable-libnpp
```

#### 5.2 转码资源调度策略

```go
// 根据视频特征动态分配Worker资源

type ResourceScheduler struct {
    workers map[string]*WorkerInfo // workerID -> WorkerInfo
}

type WorkerInfo struct {
    WorkerID    string
    HasGPU      bool
    CPUCores    int
    MemoryGB    int
    CurrentLoad int // 当前正在处理的任务数
    MaxLoad     int // 最大并发任务数
}

func (s *ResourceScheduler) selectWorker(task *TranscodeMessage) string {
    // 1. 根据任务特征选择Worker
    requireGPU := task.Template.Resolution == "1080p" || task.Template.Resolution == "4k"

    // 2. 筛选符合条件的Worker
    candidates := []string{}
    for workerID, info := range s.workers {
        if requireGPU && !info.HasGPU {
            continue // 跳过无GPU的Worker
        }

        if info.CurrentLoad < info.MaxLoad {
            candidates = append(candidates, workerID)
        }
    }

    // 3. 选择负载最低的Worker
    if len(candidates) == 0 {
        return "" // 无可用Worker
    }

    bestWorker := candidates[0]
    minLoad := s.workers[bestWorker].CurrentLoad

    for _, workerID := range candidates {
        if s.workers[workerID].CurrentLoad < minLoad {
            bestWorker = workerID
            minLoad = s.workers[workerID].CurrentLoad
        }
    }

    return bestWorker
}
```

#### 5.3 转码参数优化

```
转码速度 vs 质量 vs 文件大小权衡:

Preset选项:
- ultrafast: 速度最快,质量最差,文件大
- fast: 平衡选项,适合大多数场景
- medium: 默认,质量较好
- slow: 质量好,速度慢,文件小

推荐配置:
- 实时直播转码: ultrafast/veryfast
- UGC内容转码: fast
- 版权内容转码: medium/slow

编码器选择:
- h264: 兼容性最好,广泛支持
- h265(HEVC): 压缩率高50%,但解码复杂度高
- VP9: 开源,质量好,适合WebM格式
- AV1: 新一代编码,压缩率最高,但编码慢
```

---

### 六、监控和运维

#### 6.1 关键指标监控

```go
// Prometheus指标定义
var (
    // 转码任务总量
    transcodeTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "transcode_tasks_total",
            Help: "Total number of transcode tasks",
        },
        []string{"status", "resolution"}, // 状态, 分辨率
    )

    // 转码时长
    transcodeDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "transcode_duration_seconds",
            Help:    "Transcode duration in seconds",
            Buckets: []float64{60, 300, 600, 1800, 3600, 7200}, // 1分钟到2小时
        },
        []string{"resolution"},
    )

    // 转码速度(倍速)
    transcodeSpeed = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "transcode_speed_ratio",
            Help: "Transcode speed ratio (transcode_time / video_duration)",
        },
        []string{"worker_id"},
    )

    // Worker负载
    workerLoad = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "worker_current_load",
            Help: "Current number of tasks processing on worker",
        },
        []string{"worker_id"},
    )

    // 队列长度
    queueLength = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "transcode_queue_length",
            Help: "Number of pending tasks in queue",
        },
        []string{"priority"},
    )
)
```

#### 6.2 告警规则

```yaml
groups:
- name: transcode_alerts
  rules:
  - alert: TranscodeFailureRateHigh
    expr: rate(transcode_tasks_total{status="failed"}[10m]) / rate(transcode_tasks_total[10m]) > 0.1
    for: 5m
    annotations:
      summary: "转码失败率超过10%"

  - alert: TranscodeQueueBacklog
    expr: transcode_queue_length > 1000
    for: 15m
    annotations:
      summary: "转码队列积压超过1000个任务"

  - alert: WorkerOffline
    expr: up{job="transcode_worker"} == 0
    for: 2m
    annotations:
      summary: "转码Worker节点离线"

  - alert: TranscodeSpeedSlow
    expr: transcode_speed_ratio > 0.8
    for: 10m
    annotations:
      summary: "转码速度过慢(倍速<1.25x)"
```

---

### 七、容量评估

#### 7.1 场景假设
- **日上传视频**: 10万个视频
- **平均视频时长**: 10分钟
- **平均文件大小**: 500MB
- **转码输出**: 5个版本(1080p/720p/480p/360p/HLS)
- **转码速度**: 2x(10分钟视频5分钟完成)

#### 7.2 资源估算

##### **转码Worker集群**
```
日转码总时长: 10万视频 * 10分钟 * 5版本 = 500万分钟

转码能力需求: 500万分钟 / 24小时 / 60分钟 = 3472分钟/小时
考虑2x转码速度: 3472 / 2 = 1736个并发转码任务

单Worker并发能力:
- GPU Worker: 4个并发任务
- CPU Worker: 2个并发任务

所需Worker数量:
- GPU Worker: 1736 / 4 = 434 台
- 或 CPU Worker: 1736 / 2 = 868 台

推荐配置(GPU Worker):
- GPU: NVIDIA Tesla T4
- CPU: 16核
- 内存: 64GB
- 磁盘: 500GB SSD(临时存储)
```

##### **对象存储(OSS)**
```
存储需求:
- 原始视频: 10万 * 500MB = 50TB/天
- 转码输出: 50TB * 5版本 * 0.6(压缩率) = 150TB/天
- 封面图片: 10万 * 3张 * 100KB = 30GB/天

总存储: 200TB/天

保留策略:
- 原始视频: 保留30天(6PB)
- 转码视频: 保留1年(73PB)
- 封面图片: 永久保留(11TB/年)

推荐: 阿里云OSS标准存储,价格约0.12元/GB/月
月成本: 6000TB * 0.12 = 72万元/月
```

##### **MySQL数据库**
```
数据量估算:
- 视频记录: 10万/天 * 500字节 = 50MB/天
- 转码任务: 10万 * 5版本 * 1KB = 500MB/天
- 转码输出: 10万 * 5版本 * 800字节 = 400MB/天

总计: 约1GB/天,年增长365GB

推荐配置: 主从架构,256GB内存,2TB SSD
```

##### **Kafka消息队列**
```
消息量: 10万视频 * 5版本 = 50万条/天
峰值QPS: 50万 / 86400秒 * 3(峰值倍数) = 17 QPS

消息大小: 2KB/条
存储保留: 7天

推荐配置: 3个Broker,每个500GB SSD
```

---

### 八、成本优化

#### 8.1 弹性伸缩策略

```go
// 根据队列长度动态调整Worker数量

type AutoScaler struct {
    k8s        *kubernetes.Clientset
    prometheus *prometheus.Client
}

func (a *AutoScaler) Run() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()

    for range ticker.C {
        a.scaleWorkers()
    }
}

func (a *AutoScaler) scaleWorkers() {
    // 1. 查询当前队列长度
    queueLength := a.prometheus.QueryQueueLength()

    // 2. 查询当前Worker数量
    currentWorkers := a.k8s.GetDeploymentReplicas("transcode-worker")

    // 3. 计算所需Worker数量
    // 假设每个Worker处理4个任务,期望队列长度<100
    desiredWorkers := int(math.Ceil(float64(queueLength) / 100.0))

    // 限制最小和最大值
    if desiredWorkers < 10 {
        desiredWorkers = 10 // 最少10个Worker
    } else if desiredWorkers > 500 {
        desiredWorkers = 500 // 最多500个Worker
    }

    // 4. 扩缩容
    if desiredWorkers != currentWorkers {
        log.Infof("Scaling workers: %d -> %d (queue_length=%d)",
            currentWorkers, desiredWorkers, queueLength)

        a.k8s.ScaleDeployment("transcode-worker", desiredWorkers)
    }
}
```

#### 8.2 冷热分级策略

```go
// 老视频降级到低成本存储

func (s *StorageOptimizer) migrateToArchive() {
    // 1. 查询90天未播放的视频
    coldVideos := s.mysql.Query(`
        SELECT video_id, url FROM transcode_outputs
        WHERE last_play_time < DATE_SUB(NOW(), INTERVAL 90 DAY)
        AND storage_class = 'standard'
    `)

    for _, video := range coldVideos {
        // 2. 迁移到归档存储(成本降低80%)
        s.ossClient.SetObjectStorageClass(video.URL, oss.StorageArchive)

        // 3. 更新数据库
        s.mysql.Exec(`
            UPDATE transcode_outputs
            SET storage_class = 'archive'
            WHERE video_id = ?
        `, video.VideoID)
    }
}
```

---

## 面试回答要点总结

### 1. 开场破题(1-2分钟)
"视频转码系统的核心挑战是**高吞吐**和**成本控制**。我会设计一个**分布式转码架构**:
- 使用消息队列解耦上传和转码,支持异步处理
- 部署转码Worker集群,利用GPU硬件加速提升效率
- 生成多码率版本,支持自适应播放
- 对象存储+CDN分发,保证播放体验"

### 2. 核心流程讲解(3-4分钟)
- **上传**: 分片上传到OSS,支持断点续传
- **调度**: 根据原始分辨率选择转码模板,推送到Kafka队列
- **转码**: Worker消费任务,FFmpeg转码,实时上报进度
- **分发**: 上传到OSS,推送CDN预热,更新视频状态

### 3. 技术难点深入(4-5分钟)
- **转码加速**: GPU硬件编码(NVENC),切片并行转码
- **多码率**: 生成1080p/720p/480p/360p,HLS自适应码率
- **可靠性**: 失败重试(指数退避),任务幂等性
- **成本优化**: 弹性伸缩,冷热数据分级存储

### 4. 扩展问题应对
- **如何处理4K超高清?** GPU集群,切片并行,H.265编码
- **如何优化转码速度?** 硬件加速,预设参数调优,并行化
- **如何保证转码质量?** 两遍编码,动态码率控制,VMAF质量评估

### 5. 总结(1分钟)
"这个系统的设计思想是**异步解耦+分布式扩展+硬件加速**,通过消息队列支持高并发,通过GPU提升效率,通过弹性伸缩控制成本。类似架构在YouTube、B站等视频平台广泛应用,能支撑千万级视频处理。"

---

## 参考资料
- [FFmpeg官方文档](https://ffmpeg.org/documentation.html)
- [NVIDIA Video Codec SDK](https://developer.nvidia.com/nvidia-video-codec-sdk)
- [HLS流媒体协议](https://developer.apple.com/streaming/)
- [Netflix转码架构](https://netflixtechblog.com/high-quality-video-encoding-at-scale-d159db052746)
- [阿里云视频点播服务](https://help.aliyun.com/product/29932.html)
