---
title: 如何设计一个高性能的全文搜索系统?
tags:
  - 性能优化
status: robot
class: 性能优化
slug: design-high-performance-full-text-search-system
ref:
---

## 核心要点

**倒排索引** → **分词优化** → **索引分片** → **缓存热词** → **异步更新** → **相关性排序** → **集群架构**

---

## 详细回答

### 一、全文搜索系统的核心原理

全文搜索的本质是在海量文本中快速找到包含关键词的文档,并按相关性排序。

**传统数据库查询 vs 全文搜索**:

```sql
-- 传统 SQL: 慢 (全表扫描)
SELECT * FROM articles WHERE content LIKE '%关键词%';

-- 全文搜索: 快 (倒排索引)
索引查找 "关键词" → 获取文档 ID 列表 → 按相关性排序
```

**性能对比**:
- 数据库 LIKE 查询: O(n),百万级数据需要数秒
- 全文搜索引擎: O(log n),亿级数据毫秒级响应

---

### 二、核心数据结构:倒排索引

倒排索引是全文搜索的基石,将"文档 → 词"的关系倒转为"词 → 文档"。

#### 1. **正排索引 vs 倒排索引**

**正排索引**(传统方式):
```
文档1: "Go 语言高性能编程"
文档2: "Go 并发编程实战"
文档3: "Python 高性能优化"

查询 "高性能" → 需要遍历所有文档
```

**倒排索引**(高效方式):
```
"Go"      → [文档1, 文档2]
"语言"    → [文档1]
"高性能"  → [文档1, 文档3]
"编程"    → [文档1, 文档2]
"并发"    → [文档2]
"Python"  → [文档3]
"优化"    → [文档3]

查询 "高性能" → 直接返回 [文档1, 文档3]
```

#### 2. **倒排索引的数据结构**

```go
type InvertedIndex struct {
    // 词项 → 倒排列表
    Terms map[string]*PostingList
}

type PostingList struct {
    // 文档频率(包含该词的文档数)
    DocFreq int

    // 倒排列表
    Postings []Posting
}

type Posting struct {
    DocID    int64   // 文档 ID
    TF       int     // 词频(该词在文档中出现次数)
    Positions []int  // 词位置(用于短语查询)
}
```

**示例**:
```go
index := &InvertedIndex{
    Terms: map[string]*PostingList{
        "高性能": {
            DocFreq: 2,
            Postings: []Posting{
                {DocID: 1, TF: 1, Positions: []int{3}},
                {DocID: 3, TF: 1, Positions: []int{2}},
            },
        },
        "Go": {
            DocFreq: 2,
            Postings: []Posting{
                {DocID: 1, TF: 1, Positions: []int{0}},
                {DocID: 2, TF: 1, Positions: []int{0}},
            },
        },
    },
}
```

---

### 三、分词技术

分词是中文全文搜索的关键,直接影响搜索准确性和性能。

#### 1. **分词算法**

**基于词典的分词**:
```go
// 使用 jieba 分词
import "github.com/yanyiwu/gojieba"

jieba := gojieba.NewJieba()
defer jieba.Free()

words := jieba.Cut("Go语言高性能编程", true)
// 结果: ["Go", "语言", "高性能", "编程"]
```

**优化策略**:
- **最大匹配**: 贪心匹配最长词
- **双向最大匹配**: 正向 + 反向匹配,取最优结果
- **统计分词**: 基于 HMM、CRF 等机器学习模型

#### 2. **分词优化**

**停用词过滤**:
```go
stopWords := map[string]bool{
    "的": true, "了": true, "在": true, "是": true,
    "我": true, "有": true, "和": true, "就": true,
}

func FilterStopWords(words []string) []string {
    var result []string
    for _, word := range words {
        if !stopWords[word] {
            result = append(result, word)
        }
    }
    return result
}
```

**同义词扩展**:
```go
synonyms := map[string][]string{
    "手机": {"手机", "移动电话", "大哥大"},
    "电脑": {"电脑", "计算机", "PC"},
}

// 查询 "手机" 时自动扩展为 "手机 OR 移动电话 OR 大哥大"
```

**词干提取**(英文):
```go
// "running" → "run"
// "better" → "good"
import "github.com/kljensen/snowball"

stemmed, _ := snowball.Stem("running", "english", true)
// 结果: "run"
```

---

### 四、索引构建与更新

#### 1. **批量索引构建**

**单文档索引**:
```go
func (idx *InvertedIndex) AddDocument(docID int64, content string) {
    // 1. 分词
    words := idx.tokenizer.Cut(content)

    // 2. 构建倒排索引
    for pos, word := range words {
        if idx.Terms[word] == nil {
            idx.Terms[word] = &PostingList{}
        }

        posting := Posting{
            DocID:     docID,
            TF:        1,
            Positions: []int{pos},
        }

        idx.Terms[word].Postings = append(idx.Terms[word].Postings, posting)
        idx.Terms[word].DocFreq++
    }
}
```

**批量构建**(MapReduce 思想):
```go
// Phase 1: Map - 并行分词
func MapPhase(docs []Document) []KeyValue {
    var result []KeyValue
    for _, doc := range docs {
        words := tokenize(doc.Content)
        for pos, word := range words {
            kv := KeyValue{
                Key:   word,
                Value: Posting{DocID: doc.ID, TF: 1, Positions: []int{pos}},
            }
            result = append(result, kv)
        }
    }
    return result
}

// Phase 2: Reduce - 合并倒排列表
func ReducePhase(kvs []KeyValue) map[string]*PostingList {
    grouped := make(map[string][]Posting)
    for _, kv := range kvs {
        grouped[kv.Key] = append(grouped[kv.Key], kv.Value.(Posting))
    }

    result := make(map[string]*PostingList)
    for word, postings := range grouped {
        result[word] = &PostingList{
            DocFreq:  len(postings),
            Postings: postings,
        }
    }
    return result
}
```

#### 2. **增量更新策略**

**方案一: 双缓冲**
```go
type SearchEngine struct {
    activeIndex  *InvertedIndex  // 当前查询索引
    buildingIndex *InvertedIndex // 正在构建的索引
    mu           sync.RWMutex
}

func (se *SearchEngine) RebuildIndex() {
    // 1. 在后台构建新索引
    newIndex := buildIndexFromDB()

    // 2. 原子切换
    se.mu.Lock()
    se.activeIndex = newIndex
    se.mu.Unlock()
}
```

**方案二: 增量索引 + 定期合并**
```go
type SearchEngine struct {
    mainIndex  *InvertedIndex  // 主索引(不可变)
    deltaIndex *InvertedIndex  // 增量索引(可变)
}

func (se *SearchEngine) Search(query string) []Document {
    // 同时查询主索引和增量索引
    results1 := se.mainIndex.Search(query)
    results2 := se.deltaIndex.Search(query)

    // 合并结果
    return merge(results1, results2)
}

// 定期合并增量索引到主索引
func (se *SearchEngine) MergeIndex() {
    se.mainIndex.Merge(se.deltaIndex)
    se.deltaIndex = NewInvertedIndex()
}
```

---

### 五、查询优化

#### 1. **布尔查询**

```go
// AND 查询: "Go" AND "高性能"
func (idx *InvertedIndex) SearchAND(terms []string) []int64 {
    if len(terms) == 0 {
        return nil
    }

    // 获取第一个词的倒排列表
    result := idx.getDocIDs(terms[0])

    // 依次与其他词做交集
    for i := 1; i < len(terms); i++ {
        docIDs := idx.getDocIDs(terms[i])
        result = intersect(result, docIDs)
    }

    return result
}

// OR 查询: "Go" OR "Python"
func (idx *InvertedIndex) SearchOR(terms []string) []int64 {
    var result []int64
    for _, term := range terms {
        docIDs := idx.getDocIDs(term)
        result = union(result, docIDs)
    }
    return result
}

// 高效的有序数组交集
func intersect(list1, list2 []int64) []int64 {
    var result []int64
    i, j := 0, 0

    for i < len(list1) && j < len(list2) {
        if list1[i] == list2[j] {
            result = append(result, list1[i])
            i++
            j++
        } else if list1[i] < list2[j] {
            i++
        } else {
            j++
        }
    }

    return result
}
```

#### 2. **短语查询**

```go
// 查询 "高性能编程"(要求词连续出现)
func (idx *InvertedIndex) PhraseQuery(phrase string) []int64 {
    words := idx.tokenizer.Cut(phrase)
    if len(words) == 0 {
        return nil
    }

    // 1. 找到包含所有词的文档
    docIDs := idx.SearchAND(words)

    // 2. 验证词的位置是否连续
    var result []int64
    for _, docID := range docIDs {
        if idx.checkPhrase(docID, words) {
            result = append(result, docID)
        }
    }

    return result
}

func (idx *InvertedIndex) checkPhrase(docID int64, words []string) bool {
    // 获取第一个词的位置
    positions := idx.getPositions(docID, words[0])

    for _, startPos := range positions {
        match := true
        // 检查后续词是否在连续位置
        for i := 1; i < len(words); i++ {
            expectedPos := startPos + i
            if !idx.hasPosition(docID, words[i], expectedPos) {
                match = false
                break
            }
        }
        if match {
            return true
        }
    }

    return false
}
```

#### 3. **前缀查询与模糊查询**

**前缀查询**(基于 Trie 树):
```go
type TrieNode struct {
    children map[rune]*TrieNode
    terms    []string  // 以该节点为前缀的所有完整词
}

func (trie *Trie) PrefixSearch(prefix string) []string {
    node := trie.root
    for _, ch := range prefix {
        if node.children[ch] == nil {
            return nil
        }
        node = node.children[ch]
    }
    return node.terms
}

// 查询 "高性*" → ["高性能", "高性价比", "高性能计算"]
```

**模糊查询**(基于编辑距离):
```go
import "github.com/agnivade/levenshtein"

func FuzzySearch(term string, maxDistance int) []string {
    var results []string
    for dictTerm := range idx.Terms {
        distance := levenshtein.ComputeDistance(term, dictTerm)
        if distance <= maxDistance {
            results = append(results, dictTerm)
        }
    }
    return results
}

// 查询 "helo" (拼写错误) → 匹配 "hello"
```

---

### 六、相关性排序

#### 1. **TF-IDF 算法**

**公式**:
```
TF-IDF(t, d) = TF(t, d) × IDF(t)

TF(t, d) = 词 t 在文档 d 中的频率
IDF(t) = log(文档总数 / 包含词 t 的文档数)
```

**实现**:
```go
func (idx *InvertedIndex) CalculateTFIDF(term string, docID int64) float64 {
    // 1. 计算 TF
    tf := float64(idx.getTermFreq(term, docID))

    // 2. 计算 IDF
    docFreq := idx.Terms[term].DocFreq
    totalDocs := idx.getTotalDocs()
    idf := math.Log(float64(totalDocs) / float64(docFreq))

    return tf * idf
}

func (idx *InvertedIndex) RankDocuments(query string) []ScoredDocument {
    words := idx.tokenizer.Cut(query)
    docIDs := idx.SearchOR(words)

    var results []ScoredDocument
    for _, docID := range docIDs {
        // 计算文档得分(所有查询词的 TF-IDF 之和)
        score := 0.0
        for _, word := range words {
            score += idx.CalculateTFIDF(word, docID)
        }

        results = append(results, ScoredDocument{
            DocID: docID,
            Score: score,
        })
    }

    // 按得分降序排序
    sort.Slice(results, func(i, j int) bool {
        return results[i].Score > results[j].Score
    })

    return results
}
```

#### 2. **BM25 算法**(改进版 TF-IDF)

```go
// BM25 考虑了文档长度归一化
func (idx *InvertedIndex) CalculateBM25(term string, docID int64) float64 {
    k1 := 1.5  // 词频饱和参数
    b := 0.75  // 长度归一化参数

    tf := float64(idx.getTermFreq(term, docID))
    docLen := float64(idx.getDocLength(docID))
    avgDocLen := idx.getAvgDocLength()

    // IDF
    docFreq := idx.Terms[term].DocFreq
    totalDocs := idx.getTotalDocs()
    idf := math.Log(float64(totalDocs-docFreq+0.5) / float64(docFreq+0.5))

    // BM25
    lengthNorm := 1 - b + b*(docLen/avgDocLen)
    score := idf * (tf * (k1 + 1)) / (tf + k1*lengthNorm)

    return score
}
```

---

### 七、性能优化技术

#### 1. **索引压缩**

**变长编码**(节省存储空间):
```go
// 倒排列表通常是递增的整数序列
// [1, 3, 5, 100, 105, 200]

// 差分编码
// [1, 2, 2, 95, 5, 95]

// 变长整数编码(VInt)
func EncodeVInt(n int) []byte {
    var result []byte
    for n >= 128 {
        result = append(result, byte(n%128|128))
        n /= 128
    }
    result = append(result, byte(n))
    return result
}
```

**跳表加速**(Skip List):
```go
// 每隔 k 个元素建立一个跳跃指针
type PostingList struct {
    Postings []Posting
    SkipList []int  // 跳表索引: [0, 100, 200, 300, ...]
}

func (pl *PostingList) Search(targetDocID int64) *Posting {
    // 1. 先在跳表中二分查找
    idx := sort.Search(len(pl.SkipList), func(i int) bool {
        return pl.Postings[pl.SkipList[i]].DocID >= targetDocID
    })

    // 2. 在跳表区间内线性查找
    start := 0
    if idx > 0 {
        start = pl.SkipList[idx-1]
    }

    for i := start; i < len(pl.Postings); i++ {
        if pl.Postings[i].DocID == targetDocID {
            return &pl.Postings[i]
        }
    }

    return nil
}
```

#### 2. **缓存优化**

**查询结果缓存**:
```go
type SearchEngine struct {
    index *InvertedIndex
    cache *lru.Cache  // LRU 缓存
}

func (se *SearchEngine) Search(query string) []Document {
    // 1. 查缓存
    if cached, ok := se.cache.Get(query); ok {
        return cached.([]Document)
    }

    // 2. 执行搜索
    results := se.index.Search(query)

    // 3. 写入缓存
    se.cache.Add(query, results)

    return results
}
```

**热词缓存**:
```go
// 预先计算热门查询的结果
func (se *SearchEngine) WarmupCache() {
    hotQueries := []string{
        "Go语言", "高性能", "并发编程", "微服务",
    }

    for _, query := range hotQueries {
        results := se.index.Search(query)
        se.cache.Add(query, results)
    }
}
```

#### 3. **索引分片**(Sharding)

```go
type ShardedIndex struct {
    shards []*InvertedIndex
}

// 根据文档 ID 哈希分片
func (si *ShardedIndex) GetShard(docID int64) *InvertedIndex {
    shardID := int(docID % int64(len(si.shards)))
    return si.shards[shardID]
}

func (si *ShardedIndex) Search(query string) []Document {
    // 并行查询所有分片
    resultChan := make(chan []Document, len(si.shards))

    for _, shard := range si.shards {
        go func(s *InvertedIndex) {
            resultChan <- s.Search(query)
        }(shard)
    }

    // 合并结果
    var allResults []Document
    for i := 0; i < len(si.shards); i++ {
        allResults = append(allResults, <-resultChan...)
    }

    // 重新排序
    sort.Slice(allResults, func(i, j int) bool {
        return allResults[i].Score > allResults[j].Score
    })

    return allResults
}
```

---

### 八、分布式架构

#### 1. **Elasticsearch 架构借鉴**

```
                 [负载均衡]
                      |
        +-------------+-------------+
        |             |             |
    [Node 1]      [Node 2]      [Node 3]
    (Master)      (Data)        (Data)
        |             |             |
    +---------+-----------+---------+
    | Shard 0 | Shard 1   | Shard 2 |
    | Replica | Primary   | Primary |
    +---------+-----------+---------+
```

**角色划分**:
- **Master 节点**: 管理集群元数据、索引创建/删除
- **Data 节点**: 存储数据、执行查询
- **Coordinating 节点**: 接收请求、分发查询、聚合结果

#### 2. **分片与副本**

```go
type Cluster struct {
    nodes  []*Node
    shards map[int]*ShardGroup  // 分片 ID → 主分片 + 副本
}

type ShardGroup struct {
    primary  *Shard
    replicas []*Shard
}

func (c *Cluster) Search(query string) []Document {
    var wg sync.WaitGroup
    resultChan := make(chan []Document, len(c.shards))

    for shardID := range c.shards {
        wg.Add(1)
        go func(sid int) {
            defer wg.Done()

            // 从主分片或副本中选一个查询(负载均衡)
            shard := c.selectShard(sid)
            results := shard.Search(query)
            resultChan <- results
        }(shardID)
    }

    wg.Wait()
    close(resultChan)

    // 合并结果
    return c.mergeResults(resultChan)
}
```

#### 3. **一致性保证**

**写入流程**:
```go
func (c *Cluster) IndexDocument(doc Document) error {
    // 1. 计算文档应该写入哪个分片
    shardID := c.getShardID(doc.ID)
    shardGroup := c.shards[shardID]

    // 2. 先写主分片
    if err := shardGroup.primary.Index(doc); err != nil {
        return err
    }

    // 3. 并行写副本(可选:等待多数副本确认)
    var wg sync.WaitGroup
    for _, replica := range shardGroup.replicas {
        wg.Add(1)
        go func(r *Shard) {
            defer wg.Done()
            r.Index(doc)
        }(replica)
    }
    wg.Wait()

    return nil
}
```

---

### 九、实战案例

**场景**: 构建一个支持 1000 万文档、QPS 5000 的搜索系统。

**架构设计**:

1. **分片策略**:
   - 10 个分片,每个分片 100 万文档
   - 3 副本(1 主 + 2 从)

2. **硬件配置**:
   - 6 台服务器(32C64G,SSD)
   - 3 台 Data 节点 + 3 台 Coordinating 节点

3. **索引设计**:
```json
{
  "settings": {
    "number_of_shards": 10,
    "number_of_replicas": 2,
    "refresh_interval": "30s"  // 降低刷新频率
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "ik_max_word",  // 中文分词
        "search_analyzer": "ik_smart"
      },
      "content": {
        "type": "text",
        "analyzer": "ik_max_word"
      },
      "category": {
        "type": "keyword"  // 不分词
      }
    }
  }
}
```

4. **优化措施**:
   - **缓存**: Redis 缓存热门查询(命中率 60%)
   - **预加载**: 系统启动时预热前 1000 个热词
   - **异步更新**: 文档更新先写入 MQ,批量索引
   - **分词优化**: 使用 IK 分词器,自定义行业词典

5. **性能指标**:
   - 平均响应时间: 50ms
   - P99 响应时间: 200ms
   - QPS: 8000(超过目标)
   - 可用性: 99.9%

---

### 十、开源方案对比

| 特性 | Elasticsearch | Solr | Meilisearch | Bleve(Go) |
|------|--------------|------|-------------|-----------|
| 语言 | Java | Java | Rust | Go |
| 易用性 | ★★★★☆ | ★★★☆☆ | ★★★★★ | ★★★★☆ |
| 性能 | ★★★★★ | ★★★★☆ | ★★★★☆ | ★★★☆☆ |
| 分布式 | ✅ 原生支持 | ✅ 需配置 | ❌ 单机 | ❌ 单机 |
| 社区 | 最活跃 | 活跃 | 成长中 | 小众 |
| 适用场景 | 大规模分布式 | 企业搜索 | 小型项目 | 嵌入式搜索 |

**选型建议**:
- **亿级数据 + 高并发**: Elasticsearch
- **企业内部搜索**: Solr
- **快速原型 + 小规模**: Meilisearch
- **Go 应用嵌入式**: Bleve

---

### 十一、总结

设计高性能全文搜索系统的关键:

1. **核心数据结构**: 倒排索引是基础,决定查询效率
2. **分词质量**: 直接影响搜索准确性(中文尤其重要)
3. **相关性排序**: TF-IDF/BM25 算法保证结果质量
4. **性能优化**: 缓存、压缩、分片、并行查询
5. **分布式架构**: 分片 + 副本实现高可用和水平扩展

**优化顺序**:
1. 倒排索引 + 分词(核心)
2. 相关性排序
3. 缓存热词
4. 索引分片
5. 分布式部署

**经验法则**:
- 百万级数据: 单机 Elasticsearch/Bleve
- 千万级数据: 3-5 节点集群
- 亿级数据: 10+ 节点集群 + 索引优化
