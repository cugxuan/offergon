---
title: 如何优化 Go 程序的 CPU 和内存使用？
tags:
  - 内存管理
  - 性能优化
status: robot
class: 性能优化
slug: optimize-go-cpu-memory-usage
ref:
---

## 核心要点

**CPU优化关键**:减少锁竞争、优化算法复杂度、使用sync.Pool复用对象、合理使用goroutine池。
**内存优化关键**:避免内存泄漏、减少GC压力(预分配切片、复用对象、使用指针传递大对象)、优化数据结构。

---

## 详细回答

### 一、CPU 优化策略

#### 1. 减少锁竞争

**问题**: 高并发场景下,多个goroutine争抢同一把锁会导致CPU空转

```go
// ❌ 全局锁导致性能瓶颈
type Counter struct {
    mu    sync.Mutex
    count int64
}

func (c *Counter) Increment() {
    c.mu.Lock()
    c.count++
    c.mu.Unlock()
}
```

**优化方案1**: 使用原子操作替代锁
```go
// ✅ 无锁化:性能提升10倍+
type Counter struct {
    count int64
}

func (c *Counter) Increment() {
    atomic.AddInt64(&c.count, 1)
}
```

**优化方案2**: 分段锁(减少锁粒度)
```go
// ✅ 将数据分段,每段独立加锁
type ShardedMap struct {
    shards [16]*shard  // 16个分片
}

type shard struct {
    mu   sync.RWMutex
    data map[string]interface{}
}

func (m *ShardedMap) getShard(key string) *shard {
    hash := fnv.New32()
    hash.Write([]byte(key))
    return m.shards[hash.Sum32()%16]
}

func (m *ShardedMap) Set(key string, value interface{}) {
    s := m.getShard(key)
    s.mu.Lock()
    s.data[key] = value
    s.mu.Unlock()
}
```

**优化方案3**: 使用 `sync.Map` (适合读多写少场景)
```go
// ✅ 官方优化的并发安全map
var cache sync.Map
cache.Store("key", "value")
val, ok := cache.Load("key")
```

#### 2. 优化 Goroutine 使用

**问题**: 无限制创建goroutine会导致调度开销和内存暴涨

```go
// ❌ 每个请求创建新goroutine,QPS高时会创建数十万goroutine
func HandleRequest(w http.ResponseWriter, r *http.Request) {
    go processTask(r)  // 危险!
}
```

**优化方案**: 使用协程池限制并发数
```go
// ✅ 使用带缓冲channel控制并发数
type WorkerPool struct {
    tasks chan func()
}

func NewWorkerPool(workerCount int) *WorkerPool {
    pool := &WorkerPool{
        tasks: make(chan func(), 1000),
    }
    for i := 0; i < workerCount; i++ {
        go pool.worker()
    }
    return pool
}

func (p *WorkerPool) worker() {
    for task := range p.tasks {
        task()
    }
}

func (p *WorkerPool) Submit(task func()) {
    p.tasks <- task
}

// 使用
pool := NewWorkerPool(100)  // 固定100个worker
pool.Submit(func() {
    processTask()
})
```

**使用第三方库**: `panjf2000/ants` 或 `gammazero/workerpool`
```go
import "github.com/panjf2000/ants/v2"

pool, _ := ants.NewPool(1000)
defer pool.Release()

pool.Submit(func() {
    processTask()
})
```

#### 3. 优化算法复杂度

**案例**: 优化字符串拼接
```go
// ❌ 循环拼接字符串:O(n²)复杂度,每次+都会复制整个字符串
func concat(strs []string) string {
    result := ""
    for _, s := range strs {
        result += s  // 每次分配新内存!
    }
    return result
}

// ✅ 使用 strings.Builder:O(n)复杂度
func concat(strs []string) string {
    var builder strings.Builder
    builder.Grow(len(strs) * 10)  // 预分配容量
    for _, s := range strs {
        builder.WriteString(s)
    }
    return builder.String()
}
```

**性能对比**: 拼接10000个字符串,Builder快100倍

#### 4. 避免反射和类型断言

**问题**: 反射是运行时操作,无法被编译器优化

```go
// ❌ 反射慢100倍
func SlowSet(obj interface{}, field string, value interface{}) {
    v := reflect.ValueOf(obj).Elem()
    v.FieldByName(field).Set(reflect.ValueOf(value))
}

// ✅ 直接赋值
func FastSet(user *User, name string) {
    user.Name = name
}
```

**使用场景**: 反射仅用于框架层(ORM、序列化),业务代码避免使用

### 二、内存优化策略

#### 1. 预分配切片容量

**问题**: 动态扩容会触发内存复制

```go
// ❌ 频繁扩容:分配了4次内存
slice := []int{}
for i := 0; i < 1000; i++ {
    slice = append(slice, i)  // 容量不足时触发扩容
}

// ✅ 预分配:只分配1次
slice := make([]int, 0, 1000)
for i := 0; i < 1000; i++ {
    slice = append(slice, i)
}
```

**扩容规则**: 容量<1024时翻倍,>1024时增长25%

#### 2. 使用 sync.Pool 复用对象

**问题**: 频繁创建/销毁临时对象会给GC带来压力

```go
// ❌ 每次请求分配新buffer
func HandleRequest(w http.ResponseWriter, r *http.Request) {
    buf := new(bytes.Buffer)  // 请求结束后被GC回收
    buf.Write(processData())
    w.Write(buf.Bytes())
}

// ✅ 复用buffer,减少分配
var bufferPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func HandleRequest(w http.ResponseWriter, r *http.Request) {
    buf := bufferPool.Get().(*bytes.Buffer)
    buf.Reset()  // 清空内容
    defer bufferPool.Put(buf)

    buf.Write(processData())
    w.Write(buf.Bytes())
}
```

**适用场景**: 临时对象(如buffer、encoder、连接对象)

#### 3. 避免内存泄漏

**常见泄漏场景1**: Goroutine泄漏
```go
// ❌ goroutine永久阻塞,无法被GC
func leak() {
    ch := make(chan int)
    go func() {
        val := <-ch  // 永远等待,goroutine泄漏!
        fmt.Println(val)
    }()
}

// ✅ 使用context控制生命周期
func fixed(ctx context.Context) {
    ch := make(chan int)
    go func() {
        select {
        case val := <-ch:
            fmt.Println(val)
        case <-ctx.Done():
            return  // 可以正常退出
        }
    }()
}
```

**常见泄漏场景2**: 切片底层数组引用
```go
// ❌ 切片只用了头部10个元素,但底层数组保留全部100万元素
func getHeader(data []byte) []byte {
    return data[:10]  // 底层数组不会被GC!
}

// ✅ 复制需要的数据,释放原数组
func getHeader(data []byte) []byte {
    header := make([]byte, 10)
    copy(header, data[:10])
    return header  // data可以被GC
}
```

**常见泄漏场景3**: 定时器未关闭
```go
// ❌ time.After 会持续到超时才释放
for {
    select {
    case <-time.After(1 * time.Second):  // 每次循环创建新timer!
        doWork()
    }
}

// ✅ 复用timer
ticker := time.NewTicker(1 * time.Second)
defer ticker.Stop()
for {
    select {
    case <-ticker.C:
        doWork()
    }
}
```

#### 4. 减少 GC 压力

**策略1**: 减少堆上分配(使用值类型而非指针)
```go
// ❌ 大量小对象指针增加GC扫描负担
type User struct {
    ID   *int64   // 指针分配在堆上
    Name *string
}

// ✅ 值类型分配在栈上
type User struct {
    ID   int64    // 栈分配,无需GC
    Name string
}
```

**逃逸分析**: 使用 `go build -gcflags="-m"` 查看哪些变量逃逸到堆

**策略2**: 大对象使用指针传递
```go
// ❌ 传递大结构体会复制整个对象
func Process(data [1000]int) {  // 复制8KB数据!
    // ...
}

// ✅ 传递指针
func Process(data *[1000]int) {  // 只复制8字节指针
    // ...
}
```

**策略3**: 调整 GOGC 参数
```bash
# GOGC=100(默认):堆增长100%时触发GC
# GOGC=200:容忍更多内存换取更少GC次数
export GOGC=200
```

#### 5. 优化数据结构

**案例1**: 使用空结构体作为集合
```go
// ❌ map[string]bool 浪费内存(bool占1字节)
set := make(map[string]bool)
set["key"] = true

// ✅ map[string]struct{} 空结构体不占内存
set := make(map[string]struct{})
set["key"] = struct{}{}
```

**案例2**: 字段对齐减少内存占用
```go
// ❌ 占用32字节(因为内存对齐)
type Bad struct {
    a bool   // 1字节 + 7字节padding
    b int64  // 8字节
    c bool   // 1字节 + 7字节padding
    d int64  // 8字节
}

// ✅ 占用24字节
type Good struct {
    b int64  // 8字节
    d int64  // 8字节
    a bool   // 1字节
    c bool   // 1字节 + 6字节padding
}
```

查看对齐情况: `go vet -structtag .`

### 三、性能分析工具

#### 1. pprof 分析CPU和内存

```go
import _ "net/http/pprof"

func main() {
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()
    // ...
}
```

访问 `http://localhost:6060/debug/pprof/` 查看实时指标

#### 2. trace 分析调度

```bash
curl http://localhost:6060/debug/pprof/trace?seconds=5 > trace.out
go tool trace trace.out
```

### 四、实际优化案例

**案例**: 优化日志处理系统

**问题**:
- CPU使用率80%,主要消耗在JSON序列化
- 内存占用2GB,GC每30秒触发一次

**优化措施**:
1. 使用 `json-iterator` 替换标准库 → CPU降至60%
2. 使用 `sync.Pool` 复用encoder → 内存降至800MB
3. 日志批量写入,减少系统调用 → CPU降至40%
4. 异步写入磁盘,主流程不阻塞 → 吞吐量提升5倍

**优化后**:
- CPU使用率: 80% → 40%
- 内存占用: 2GB → 800MB
- GC频率: 30秒 → 2分钟
- 日志处理能力: 10万条/秒 → 50万条/秒

---

## 总结

**CPU优化核心**: 减少等待(锁、IO)、减少计算(算法、反射)、合理使用并发。

**内存优化核心**: 减少分配(复用对象、预分配)、减少GC(减少堆对象)、防止泄漏(goroutine、定时器)。

**优化原则**: **先测量再优化**,使用 pprof 找到真正的瓶颈,不要盲目优化。Donald Knuth说:**过早优化是万恶之源**。
