---
title: 如何优化一个慢查询 SQL?Explain 执行计划分析
tags:
  - 性能优化
status: robot
class: 性能优化
slug: sql-query-optimization-explain-plan-analysis
ref:
---

## 核心要点

**优化思路:**  定位慢查询 → 分析执行计划 → 针对性优化 → 验证效果

**关键指标:**  EXPLAIN 的 type(扫描类型)、key(使用索引)、rows(扫描行数)、Extra(额外信息)

**常见手段:**  添加/优化索引、改写 SQL、表结构调整、分库分表

---

## 详细回答

### 一、如何定位慢查询

在优化之前,首先要找到系统中的慢查询:

#### 1. 开启慢查询日志

```sql
-- 查看慢查询配置
SHOW VARIABLES LIKE '%slow_query%';

-- 开启慢查询日志
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2;  -- 设置阈值为2秒

-- 记录未使用索引的查询
SET GLOBAL log_queries_not_using_indexes = 'ON';
```

慢查询日志会记录执行时间超过 `long_query_time` 的 SQL,默认路径通常在 `/var/lib/mysql/slow.log`。

#### 2. 使用监控工具

- **Performance Schema**: MySQL 自带的性能监控工具
- **Percona Toolkit**: 如 `pt-query-digest` 可以分析慢查询日志
- **APM 工具**: 如 Skywalking、Prometheus + Grafana
- **云厂商监控**: 阿里云 RDS、AWS RDS 自带慢查询分析

```bash
# 使用 pt-query-digest 分析慢查询日志
pt-query-digest /var/lib/mysql/slow.log > slow_report.txt
```

---

### 二、使用 EXPLAIN 分析执行计划

找到慢查询后,使用 `EXPLAIN` 分析其执行计划:

```sql
EXPLAIN SELECT * FROM orders
WHERE user_id = 1001 AND create_time > '2024-01-01';
```

#### EXPLAIN 关键字段解读

| 字段 | 说明 | 优化目标 |
|------|------|----------|
| **id** | 查询的执行顺序,数字越大越先执行 | 了解子查询执行顺序 |
| **select_type** | 查询类型(SIMPLE/SUBQUERY/UNION 等) | 识别复杂查询类型 |
| **table** | 正在访问的表名 | 确认表连接顺序 |
| **type** | **访问类型**(最重要) | 至少达到 range,最好是 ref 或 const |
| **possible_keys** | 可能使用的索引 | 确认索引候选 |
| **key** | **实际使用的索引** | 确保使用了合适的索引 |
| **key_len** | 使用的索引长度 | 确认联合索引使用了几个字段 |
| **ref** | 索引的哪一列被使用 | 了解索引匹配方式 |
| **rows** | **预估扫描行数** | 越少越好,关键优化指标 |
| **filtered** | 按条件过滤的行百分比 | 越高越好(MySQL 5.7+) |
| **Extra** | **额外信息** | 关注性能相关提示 |

#### type 字段详解(性能从好到差)

```
system > const > eq_ref > ref > range > index > ALL
```

- **const**: 通过主键或唯一索引查询单行,最优
- **eq_ref**: 唯一索引关联,每次只匹配一行
- **ref**: 非唯一索引查询,可能匹配多行
- **range**: 索引范围扫描(>, <, BETWEEN, IN)
- **index**: 全索引扫描,扫描整个索引树
- **ALL**: 全表扫描,性能最差,必须优化

#### Extra 字段关键信息

- **Using index**: 覆盖索引,只需扫描索引,非常好
- **Using where**: 使用 WHERE 过滤,正常
- **Using index condition**: 索引下推(ICP),较好
- **Using temporary**: 使用临时表,需要优化
- **Using filesort**: 文件排序,性能差,需要优化
- **Using join buffer**: JOIN 缓冲,考虑添加索引

---

### 三、常见慢查询场景及优化方案

#### 场景 1: 未使用索引(type = ALL)

**问题 SQL:**
```sql
EXPLAIN SELECT * FROM orders WHERE user_id = 1001;
```

**执行计划:**
```
type: ALL
key: NULL
rows: 1000000
Extra: Using where
```

**问题分析:** 全表扫描 100 万行,user_id 字段没有索引。

**优化方案:**
```sql
-- 添加索引
ALTER TABLE orders ADD INDEX idx_user_id(user_id);
```

**优化后:**
```
type: ref
key: idx_user_id
rows: 150
Extra: NULL
```

---

#### 场景 2: 索引失效

**问题 SQL:**
```sql
-- 对索引字段使用函数
SELECT * FROM orders WHERE DATE(create_time) = '2024-01-01';
```

**问题分析:** 对索引字段使用函数导致索引失效。

**优化方案:**
```sql
-- 改写 SQL,避免对索引字段使用函数
SELECT * FROM orders
WHERE create_time >= '2024-01-01 00:00:00'
  AND create_time < '2024-01-02 00:00:00';
```

**其他导致索引失效的情况:**
- 使用 `!=` 或 `<>` 操作符
- 使用 `OR` 连接的条件(部分字段无索引)
- 使用 `LIKE '%abc'`(前缀模糊查询)
- 隐式类型转换:`WHERE user_id = '1001'`(user_id 是 int 类型)
- 联合索引不满足最左前缀原则

---

#### 场景 3: 联合索引使用不当

**问题 SQL:**
```sql
-- 已有联合索引: idx_user_status(user_id, status, create_time)
SELECT * FROM orders WHERE status = 1 AND create_time > '2024-01-01';
```

**问题分析:** 跳过了联合索引的第一个字段 user_id,索引无法使用。

**优化方案 1: 调整查询条件(如果业务允许)**
```sql
SELECT * FROM orders
WHERE user_id = 1001 AND status = 1 AND create_time > '2024-01-01';
```

**优化方案 2: 创建新的索引**
```sql
ALTER TABLE orders ADD INDEX idx_status_time(status, create_time);
```

**联合索引最左前缀原则:**
- 索引 `(a, b, c)` 可以支持: `a`, `a,b`, `a,b,c` 的查询
- 不支持: `b`, `c`, `b,c` 的查询
- `a,c` 查询时只能使用 `a` 部分

---

#### 场景 4: 使用 filesort 排序

**问题 SQL:**
```sql
SELECT * FROM orders
WHERE user_id = 1001
ORDER BY create_time DESC
LIMIT 10;
```

**执行计划:**
```
type: ref
key: idx_user_id
rows: 5000
Extra: Using filesort  -- 文件排序,性能差
```

**问题分析:** 虽然使用了索引查询,但排序字段没有索引,需要额外排序。

**优化方案:**
```sql
-- 创建联合索引,同时满足查询和排序
ALTER TABLE orders ADD INDEX idx_user_time(user_id, create_time);
```

**优化后:**
```
type: ref
key: idx_user_time
rows: 10
Extra: Using index  -- 覆盖索引,直接返回结果
```

---

#### 场景 5: JOIN 查询优化

**问题 SQL:**
```sql
SELECT o.*, u.username
FROM orders o
LEFT JOIN users u ON o.user_id = u.id
WHERE o.status = 1;
```

**执行计划:**
```
orders: type=ALL, rows=1000000, Extra: Using where
users:  type=ALL, rows=500000, Extra: Using join buffer
```

**问题分析:**
1. orders 表全表扫描
2. users 表也全表扫描
3. 使用 JOIN buffer(内存不足时会很慢)

**优化方案:**
```sql
-- 1. 在 orders.status 上添加索引
ALTER TABLE orders ADD INDEX idx_status(status);

-- 2. 确保 users.id 是主键(通常已是)

-- 3. 在 orders.user_id 上添加索引(用于 JOIN)
ALTER TABLE orders ADD INDEX idx_user_id(user_id);
```

**JOIN 优化原则:**
- 小表驱动大表(小表在前)
- 确保 JOIN 字段有索引
- 避免使用 `SELECT *`,只查询需要的字段
- 考虑使用子查询代替 JOIN(某些场景)

---

#### 场景 6: 深分页问题

**问题 SQL:**
```sql
SELECT * FROM orders ORDER BY id LIMIT 1000000, 20;
```

**问题分析:** 需要扫描 1000020 行然后丢弃前 100 万行,效率极低。

**优化方案 1: 使用子查询优化(延迟关联)**
```sql
SELECT o.* FROM orders o
INNER JOIN (
    SELECT id FROM orders ORDER BY id LIMIT 1000000, 20
) t ON o.id = t.id;
```

**优化方案 2: 使用游标(记录上次最后一条的 id)**
```sql
SELECT * FROM orders
WHERE id > 10000000  -- 上次查询的最后一个 id
ORDER BY id LIMIT 20;
```

---

### 四、其他优化技巧

#### 1. 选择合适的字段类型

```sql
-- 不推荐: VARCHAR(500) 存储手机号
phone VARCHAR(500)

-- 推荐: 使用合适的长度
phone VARCHAR(20)

-- 不推荐: TEXT 存储状态
status TEXT

-- 推荐: 使用 TINYINT 或 ENUM
status TINYINT
```

#### 2. 避免 SELECT *

```sql
-- 不推荐
SELECT * FROM orders WHERE id = 1;

-- 推荐: 只查询需要的字段
SELECT id, user_id, total_amount FROM orders WHERE id = 1;
```

好处:
- 减少网络传输
- 可以使用覆盖索引
- 降低内存消耗

#### 3. 合理使用覆盖索引

**覆盖索引:** 查询的字段全部在索引中,无需回表查询。

```sql
-- 创建覆盖索引
ALTER TABLE orders ADD INDEX idx_user_status_amount(user_id, status, total_amount);

-- 查询可以直接从索引获取数据
SELECT user_id, status, total_amount
FROM orders
WHERE user_id = 1001 AND status = 1;
```

执行计划中看到 `Extra: Using index` 表示使用了覆盖索引。

#### 4. 使用 FORCE INDEX 强制使用索引

有时 MySQL 优化器选择了错误的索引:

```sql
-- 强制使用指定索引
SELECT * FROM orders FORCE INDEX(idx_user_time)
WHERE user_id = 1001 AND create_time > '2024-01-01';
```

**注意:** 通常不建议使用,除非确认优化器选择错误。

---

### 五、优化流程总结

```
1. 定位慢查询
   ↓
2. 使用 EXPLAIN 分析执行计划
   ↓
3. 识别问题
   - type = ALL? → 添加索引
   - rows 太大? → 优化查询条件或索引
   - Extra 有 filesort/temporary? → 添加排序/分组索引
   - 索引失效? → 改写 SQL
   ↓
4. 实施优化
   - 添加/修改索引
   - 改写 SQL
   - 调整表结构
   ↓
5. 验证效果
   - 再次 EXPLAIN 查看执行计划
   - 压测对比执行时间
   - 监控线上效果
   ↓
6. 持续监控和迭代
```

---

### 六、实战案例

#### 案例: 电商订单查询优化

**原始 SQL:**
```sql
SELECT o.id, o.order_no, o.total_amount, u.username, u.phone
FROM orders o
LEFT JOIN users u ON o.user_id = u.user_id
WHERE o.status IN (1, 2, 3)
  AND o.create_time >= '2024-01-01'
  AND o.total_amount > 100
ORDER BY o.create_time DESC
LIMIT 20;
```

**EXPLAIN 分析:**
```
orders: type=ALL, rows=5000000, Extra: Using where; Using filesort
users:  type=eq_ref, key=PRIMARY, rows=1
```

**问题点:**
1. orders 表全表扫描 500 万行
2. 需要文件排序

**优化步骤:**

```sql
-- 1. 创建联合索引(覆盖查询和排序)
ALTER TABLE orders ADD INDEX idx_status_time(status, create_time);

-- 2. 在 total_amount 上添加索引(可选,看实际效果)
ALTER TABLE orders ADD INDEX idx_amount(total_amount);

-- 3. 确保 users.user_id 有索引(通常是主键)
```

**优化后的执行计划:**
```
orders: type=range, key=idx_status_time, rows=5000, Extra: Using index condition
users:  type=eq_ref, key=PRIMARY, rows=1
```

**性能提升:**
- 扫描行数: 5,000,000 → 5,000 (减少 99.9%)
- 执行时间: 8.5s → 0.03s (提升 283 倍)

---

### 七、注意事项

1. **索引不是越多越好:**
   - 每个索引都会占用存储空间
   - 写操作(INSERT/UPDATE/DELETE)需要维护索引
   - 建议单表索引数控制在 5 个以内

2. **定期分析索引使用情况:**
```sql
-- 查看未使用的索引
SELECT * FROM sys.schema_unused_indexes;

-- 查看索引使用统计
SELECT * FROM sys.schema_index_statistics;
```

3. **考虑业务场景:**
   - 读多写少:可以多建索引
   - 写多读少:谨慎建索引,考虑异步处理

4. **大表优化策略:**
   - 分库分表(水平拆分)
   - 历史数据归档
   - 冷热数据分离

---

## 面试回答模板

**回答框架:**

"优化慢查询 SQL,我通常按照以下步骤进行:

**第一步,定位慢查询:** 通过开启慢查询日志或使用 Performance Schema 找到系统中的慢 SQL。

**第二步,分析执行计划:** 使用 EXPLAIN 查看执行计划,重点关注几个关键指标:
- **type** 字段:查看是否全表扫描(ALL),优化目标是达到 ref 或 range
- **key** 字段:确认是否使用了索引
- **rows** 字段:查看预估扫描行数,越少越好
- **Extra** 字段:关注是否有 Using filesort 或 Using temporary

**第三步,针对性优化:** 根据分析结果采取相应措施:
- 如果是全表扫描,添加合适的索引
- 如果索引失效,检查是否使用了函数、不等号、或违反最左前缀原则
- 如果出现 filesort,考虑添加覆盖排序字段的联合索引
- 如果是 JOIN 查询慢,确保关联字段有索引,并遵循小表驱动大表原则

**第四步,验证效果:** 优化后再次使用 EXPLAIN 查看执行计划,并通过压测对比执行时间。

在我之前的项目中,曾优化过一个订单查询接口,通过添加联合索引和改写 SQL,将查询时间从 8 秒降低到 30 毫秒,扫描行数从 500 万降到 5000 行,效果显著。"
