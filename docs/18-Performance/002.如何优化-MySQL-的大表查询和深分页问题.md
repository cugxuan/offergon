---
title: 如何优化 MySQL 的大表查询和深分页问题？
tags:
  - 性能优化
status: robot
class: 性能优化
slug: optimize-mysql-large-table-query-deep-pagination
ref:
---

## 核心要点

**大表问题:** 数据量大导致全表扫描慢、索引维护成本高、备份恢复困难

**深分页问题:** LIMIT offset, size 需要扫描并丢弃 offset 条数据,offset 越大越慢

**核心优化策略:** 索引优化、延迟关联、游标分页、分库分表、冷热数据分离

---

## 详细回答

### 一、大表查询优化

#### 1. 什么是大表?

通常认为单表数据量超过以下标准即为大表:
- **行数:** 超过 500 万~1000 万行
- **数据大小:** 超过 2GB
- **索引大小:** 超过 500MB

#### 2. 大表带来的问题

**性能问题:**
- 查询响应时间长,全表扫描耗时严重
- 索引树层级增加,索引查询效率下降
- 内存缓存命中率降低(Buffer Pool 无法缓存所有热点数据)

**运维问题:**
- DDL 操作(加字段、修改表结构)耗时长,可能造成锁表
- 备份和恢复时间长
- 主从复制延迟增加

---

### 二、大表查询优化策略

#### 策略 1: 索引优化

**原则:**
1. 为高频查询字段添加索引
2. 使用覆盖索引减少回表
3. 避免索引失效(函数、类型转换、不等号)
4. 定期分析索引使用情况,删除冗余索引

**示例:**

```sql
-- 问题查询: 全表扫描
SELECT * FROM orders
WHERE user_id = 1001
  AND status = 1
  AND create_time > '2024-01-01'
ORDER BY create_time DESC;

-- 优化: 创建联合索引
ALTER TABLE orders ADD INDEX idx_user_status_time(user_id, status, create_time);

-- 进一步优化: 覆盖索引(如果只需要部分字段)
ALTER TABLE orders ADD INDEX idx_cover(user_id, status, create_time, id, total_amount);

-- 查询改写
SELECT id, user_id, status, create_time, total_amount
FROM orders
WHERE user_id = 1001 AND status = 1 AND create_time > '2024-01-01'
ORDER BY create_time DESC;
```

---

#### 策略 2: 查询条件优化

**避免全表扫描:**

```sql
-- 不推荐: 查询全部数据
SELECT * FROM orders WHERE status = 1;

-- 推荐: 添加时间范围限制
SELECT * FROM orders
WHERE status = 1
  AND create_time >= '2024-01-01'  -- 限制查询范围
LIMIT 1000;  -- 限制返回数量
```

**使用分区表:**

大表按时间、地区等维度分区,查询时只扫描相关分区。

```sql
-- 创建分区表(按月分区)
CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id INT,
    total_amount DECIMAL(10,2),
    create_time DATETIME,
    KEY idx_time(create_time)
) PARTITION BY RANGE (YEAR(create_time)*100 + MONTH(create_time)) (
    PARTITION p202401 VALUES LESS THAN (202402),
    PARTITION p202402 VALUES LESS THAN (202403),
    PARTITION p202403 VALUES LESS THAN (202404),
    PARTITION p202404 VALUES LESS THAN (MAXVALUE)
);

-- 查询时只扫描相关分区
SELECT * FROM orders
WHERE create_time >= '2024-01-01' AND create_time < '2024-02-01';
-- MySQL 会自动定位到 p202401 分区
```

**分区优势:**
- 查询只扫描相关分区,减少数据量
- 可以单独维护分区(删除历史分区、优化分区)
- 提高并发处理能力

---

#### 策略 3: 查询改写

**避免 SELECT *:**

```sql
-- 不推荐
SELECT * FROM orders WHERE id = 1001;

-- 推荐: 只查询需要的字段
SELECT id, user_id, total_amount, create_time
FROM orders WHERE id = 1001;
```

**避免子查询,改用 JOIN:**

某些情况下,JOIN 比子查询效率更高。

```sql
-- 不推荐: 子查询(MySQL 5.6 以前性能较差)
SELECT * FROM orders
WHERE user_id IN (SELECT id FROM users WHERE level = 'VIP');

-- 推荐: 改用 JOIN
SELECT o.* FROM orders o
INNER JOIN users u ON o.user_id = u.id
WHERE u.level = 'VIP';
```

**注意:** MySQL 8.0 对子查询优化已经很好,需根据实际情况选择。

---

#### 策略 4: 垂直拆分

将宽表拆分为多个表,减少单表字段数。

**场景:** 用户表有 50 个字段,但常用的只有 10 个。

```sql
-- 拆分前: 一个宽表
CREATE TABLE users (
    id INT PRIMARY KEY,
    username VARCHAR(50),
    password VARCHAR(255),
    email VARCHAR(100),
    phone VARCHAR(20),
    -- ... 还有 45 个字段(地址、偏好设置、扩展信息等)
);

-- 拆分后: 基础表 + 扩展表
-- 基础表(高频访问字段)
CREATE TABLE users_base (
    id INT PRIMARY KEY,
    username VARCHAR(50),
    password VARCHAR(255),
    email VARCHAR(100),
    phone VARCHAR(20),
    create_time DATETIME
);

-- 扩展表(低频访问字段)
CREATE TABLE users_profile (
    user_id INT PRIMARY KEY,
    address VARCHAR(200),
    birthday DATE,
    preferences JSON,
    FOREIGN KEY (user_id) REFERENCES users_base(id)
);
```

**优势:**
- 减少 I/O,提高查询效率
- 提高缓存命中率
- 减少锁竞争

---

#### 策略 5: 水平拆分(分库分表)

将数据按一定规则分散到多个表或多个数据库。

**分表示例:**

```sql
-- 原表: orders (1亿条数据)
-- 拆分为 10 个表: orders_0 ~ orders_9
-- 规则: user_id % 10

-- orders_0
CREATE TABLE orders_0 LIKE orders;

-- orders_1
CREATE TABLE orders_1 LIKE orders;
-- ...

-- 查询时路由到对应的表
-- user_id = 1001 → 1001 % 10 = 1 → orders_1
SELECT * FROM orders_1 WHERE user_id = 1001;
```

**分库示例:**

```
db_order_0: orders_0, orders_1
db_order_1: orders_2, orders_3
db_order_2: orders_4, orders_5
...
```

**工具推荐:**
- **ShardingSphere**: Apache 开源分库分表中间件
- **MyCAT**: 数据库分库分表中间件
- **TiDB**: 分布式数据库,自动分片

**注意事项:**
- 跨分片查询困难(需要应用层聚合)
- 全局唯一 ID 需要特殊处理(雪花算法、号段模式)
- 事务处理复杂(跨分片事务)
- 数据迁移和扩容复杂

---

#### 策略 6: 冷热数据分离

将历史数据(冷数据)归档到历史表,热表只保留近期数据。

**方案:**

```sql
-- 热表: 保留最近 3 个月数据
CREATE TABLE orders_hot (
    id BIGINT PRIMARY KEY,
    user_id INT,
    total_amount DECIMAL(10,2),
    create_time DATETIME,
    KEY idx_time(create_time)
);

-- 冷表: 存储 3 个月前的历史数据
CREATE TABLE orders_cold (
    id BIGINT PRIMARY KEY,
    user_id INT,
    total_amount DECIMAL(10,2),
    create_time DATETIME,
    KEY idx_time(create_time)
);

-- 定期归档(通过定时任务)
INSERT INTO orders_cold
SELECT * FROM orders_hot
WHERE create_time < DATE_SUB(NOW(), INTERVAL 3 MONTH);

DELETE FROM orders_hot
WHERE create_time < DATE_SUB(NOW(), INTERVAL 3 MONTH);
```

**查询层封装:**

应用层自动判断查询热表还是冷表:

```go
func QueryOrders(userID int, startTime time.Time) ([]Order, error) {
    threeMonthsAgo := time.Now().AddDate(0, -3, 0)

    if startTime.After(threeMonthsAgo) {
        // 查询热表
        return queryFromTable("orders_hot", userID, startTime)
    } else {
        // 查询冷表
        return queryFromTable("orders_cold", userID, startTime)
    }
}
```

**优势:**
- 热表数据量小,查询快
- 冷数据可以使用更低成本的存储
- 可以对冷表进行压缩

---

### 三、深分页问题

#### 1. 什么是深分页?

```sql
-- 浅分页(快)
SELECT * FROM orders ORDER BY id LIMIT 0, 20;   -- 0.01s

-- 深分页(慢)
SELECT * FROM orders ORDER BY id LIMIT 1000000, 20;  -- 5.2s
```

#### 2. 深分页为什么慢?

**执行过程:**
1. MySQL 需要扫描 1000020 行数据
2. 对这 1000020 行排序
3. 丢弃前 1000000 行
4. 返回后 20 行

**性能消耗:**
- 大量 I/O 读取
- 排序消耗 CPU 和内存
- 前面 100 万行数据全部浪费

#### 3. EXPLAIN 分析

```sql
EXPLAIN SELECT * FROM orders ORDER BY id LIMIT 1000000, 20;
```

```
type: ALL
rows: 5000000
Extra: Using filesort  -- 需要排序,性能差
```

---

### 四、深分页优化方案

#### 方案 1: 延迟关联(子查询优化)

**核心思想:** 先通过索引获取主键 ID,再回表查询完整数据。

**问题 SQL:**
```sql
SELECT * FROM orders ORDER BY id LIMIT 1000000, 20;
```

**优化后:**
```sql
SELECT o.* FROM orders o
INNER JOIN (
    SELECT id FROM orders ORDER BY id LIMIT 1000000, 20
) t ON o.id = t.id;
```

**原理:**
- 子查询只查询主键 id,使用覆盖索引,速度快
- 外层查询只需回表 20 次

**性能对比:**
- 优化前: 5.2s (扫描 1000020 行)
- 优化后: 0.8s (索引扫描 + 20 次回表)

**EXPLAIN 分析:**
```sql
-- 子查询
SELECT id FROM orders ORDER BY id LIMIT 1000000, 20;
```
```
type: index
key: PRIMARY
rows: 1000020
Extra: Using index  -- 覆盖索引,不需要回表
```

---

#### 方案 2: 游标分页(记录上次位置)

**核心思想:** 不使用 offset,而是记录上次查询的最后一个 ID。

**传统分页:**
```sql
-- 第 1 页
SELECT * FROM orders ORDER BY id LIMIT 0, 20;

-- 第 2 页
SELECT * FROM orders ORDER BY id LIMIT 20, 20;

-- 第 50000 页
SELECT * FROM orders ORDER BY id LIMIT 1000000, 20;  -- 慢!
```

**游标分页:**
```sql
-- 第 1 页
SELECT * FROM orders ORDER BY id LIMIT 20;
-- 假设最后一条的 id = 20

-- 第 2 页(记录上次的 id)
SELECT * FROM orders WHERE id > 20 ORDER BY id LIMIT 20;
-- 假设最后一条的 id = 40

-- 第 3 页
SELECT * FROM orders WHERE id > 40 ORDER BY id LIMIT 20;
```

**优势:**
- 始终只扫描 20 行,性能稳定
- 无论翻到第几页,速度都一样快

**局限性:**
- 无法跳页(只能上一页、下一页)
- 不适合需要随机跳转的场景
- 如果按非主键排序,实现复杂

**适用场景:**
- 时间线类应用(微博、朋友圈)
- Feed 流(新闻 feed、视频 feed)
- 移动端下拉刷新

**实现示例(Go):**

```go
type PageRequest struct {
    LastID int64  // 上次查询的最后一个 ID
    Size   int    // 每页数量
}

func GetOrdersByPage(req PageRequest) ([]Order, error) {
    query := "SELECT * FROM orders WHERE id > ? ORDER BY id LIMIT ?"

    var orders []Order
    err := db.Select(&orders, query, req.LastID, req.Size)
    return orders, err
}
```

**前端实现:**
```javascript
// 第一页
fetchOrders({ lastID: 0, size: 20 })
  .then(data => {
    const lastID = data[data.length - 1].id;  // 保存最后一个 ID
    // 下一页按钮点击时
    fetchOrders({ lastID: lastID, size: 20 });
  });
```

---

#### 方案 3: 基于索引的范围查询

如果按时间排序,可以使用时间范围查询。

**问题 SQL:**
```sql
SELECT * FROM orders
ORDER BY create_time DESC
LIMIT 1000000, 20;
```

**优化方案:**
```sql
-- 记录上次查询的最小时间
SELECT * FROM orders
WHERE create_time < '2024-01-15 10:30:00'  -- 上次最后一条的时间
ORDER BY create_time DESC
LIMIT 20;
```

**注意:** 需要在 create_time 上建立索引。

---

#### 方案 4: 使用搜索引擎(Elasticsearch)

对于复杂的搜索和分页场景,使用 Elasticsearch。

**优势:**
- 分页性能稳定(使用 search_after 方式)
- 支持复杂的全文搜索
- 支持聚合分析

**示例(ES search_after):**

```json
// 第一页
POST /orders/_search
{
  "size": 20,
  "sort": [
    { "id": "asc" }
  ]
}

// 返回结果中最后一个文档的 sort 值: [1000020]

// 下一页
POST /orders/_search
{
  "size": 20,
  "search_after": [1000020],  // 从上次位置继续
  "sort": [
    { "id": "asc" }
  ]
}
```

**优势:**
- 无论多深,性能都稳定
- 支持复杂查询

**局限性:**
- 增加系统复杂度
- 需要维护 MySQL 和 ES 的数据同步

---

#### 方案 5: 业务上避免深分页

**策略:**
1. **限制可查看的最大页数**
   - 例如: 只允许查看前 100 页
   - Google 搜索结果也有页数限制

2. **使用滚动加载代替分页**
   - 移动端常用方式
   - 只提供"加载更多"按钮

3. **提供更精准的筛选条件**
   - 引导用户使用时间范围、分类等过滤
   - 减少需要翻页的数据量

4. **使用缓存**
   - 对热门查询结果进行缓存
   - 使用 Redis 缓存分页结果

---

### 五、实战案例

#### 案例 1: 电商订单表优化

**背景:**
- 订单表 3000 万行,20GB
- 用户查询自己的订单列表响应慢(2-5 秒)

**问题 SQL:**
```sql
SELECT * FROM orders
WHERE user_id = 1001
ORDER BY create_time DESC
LIMIT 50, 20;
```

**EXPLAIN 分析:**
```
type: ref
key: idx_user_id
rows: 50000  -- 该用户有 5 万订单
Extra: Using filesort  -- 需要文件排序
```

**优化方案:**

```sql
-- 1. 创建联合索引(覆盖查询和排序)
ALTER TABLE orders ADD INDEX idx_user_time(user_id, create_time);

-- 2. 使用延迟关联优化深分页
SELECT o.* FROM orders o
INNER JOIN (
    SELECT id FROM orders
    WHERE user_id = 1001
    ORDER BY create_time DESC
    LIMIT 50, 20
) t ON o.id = t.id
ORDER BY o.create_time DESC;

-- 3. 更好的方案: 使用游标分页
SELECT * FROM orders
WHERE user_id = 1001
  AND create_time < '2024-01-20 12:00:00'  -- 上次最后一条的时间
ORDER BY create_time DESC
LIMIT 20;
```

**效果:**
- 响应时间: 2-5s → 0.05s
- 用户体验大幅提升

---

#### 案例 2: 日志表分区优化

**背景:**
- 系统日志表 1 亿行,50GB
- 查询最近 7 天的日志耗时 30 秒

**优化方案:**

```sql
-- 1. 将日志表改为分区表(按天分区)
ALTER TABLE system_logs
PARTITION BY RANGE (TO_DAYS(create_time)) (
    PARTITION p20240101 VALUES LESS THAN (TO_DAYS('2024-01-02')),
    PARTITION p20240102 VALUES LESS THAN (TO_DAYS('2024-01-03')),
    -- ... 每天一个分区
);

-- 2. 查询时只扫描相关分区
SELECT * FROM system_logs
WHERE create_time >= '2024-01-15'
  AND create_time < '2024-01-22';
-- MySQL 自动只扫描这 7 天的分区

-- 3. 定期删除历史分区(保留 30 天)
ALTER TABLE system_logs DROP PARTITION p20231215;
```

**效果:**
- 查询时间: 30s → 1.5s
- 历史数据清理从小时级降到秒级

---

### 六、优化决策树

```
大表查询慢?
├─ 是否全表扫描(type=ALL)?
│  ├─ 是 → 添加索引
│  └─ 否 → 继续分析
│
├─ 是否深分页(offset > 10000)?
│  ├─ 是
│  │  ├─ 能否使用游标分页? → 使用 WHERE id > last_id
│  │  ├─ 必须跳页? → 使用延迟关联
│  │  └─ 业务允许? → 限制最大页数
│  └─ 否 → 继续分析
│
├─ 数据量是否 > 1000 万?
│  ├─ 是
│  │  ├─ 历史数据查询少? → 冷热分离
│  │  ├─ 按时间/地区明显分段? → 分区表
│  │  └─ 数据持续增长? → 分库分表
│  └─ 否 → 优化索引和查询条件
│
└─ 是否复杂查询(多条件搜索/全文搜索)?
   └─ 是 → 考虑使用 Elasticsearch
```

---

### 七、注意事项

1. **在线 DDL 操作要谨慎**
   - 大表加字段、加索引可能锁表几小时
   - 使用 pt-online-schema-change 工具(Percona Toolkit)
   - MySQL 8.0+ 支持在线 DDL,但仍需注意影响

2. **分库分表不是银弹**
   - 增加系统复杂度
   - 跨分片查询困难
   - 优先考虑其他优化方案

3. **监控很重要**
   - 监控慢查询
   - 监控表大小增长趋势
   - 提前规划扩容

4. **定期维护**
   - 定期分析表: `ANALYZE TABLE orders;`
   - 定期优化表: `OPTIMIZE TABLE orders;` (回收碎片空间)
   - 定期检查索引使用情况

---

## 面试回答模板

**回答框架:**

"MySQL 大表查询和深分页优化,我从两个方面来回答:

**一、大表查询优化:**

1. **索引优化:** 首先使用 EXPLAIN 分析执行计划,确保关键字段有索引,避免全表扫描。使用覆盖索引减少回表。

2. **查询优化:** 避免 SELECT *,添加合理的查询条件限制范围,比如加上时间范围。

3. **表结构优化:**
   - **垂直拆分:** 将宽表拆分为基础表和扩展表
   - **水平拆分:** 数据量超过千万级考虑分库分表
   - **分区表:** 按时间或地区分区,查询时只扫描相关分区
   - **冷热分离:** 历史数据归档到冷表

**二、深分页问题优化:**

深分页慢的原因是 LIMIT 1000000, 20 需要扫描并丢弃前 100 万行数据。

**优化方案:**

1. **延迟关联:** 使用子查询先通过索引获取主键 ID,再回表查询完整数据
   ```sql
   SELECT o.* FROM orders o
   INNER JOIN (
       SELECT id FROM orders ORDER BY id LIMIT 1000000, 20
   ) t ON o.id = t.id;
   ```

2. **游标分页(推荐):** 记录上次查询的最后一个 ID,使用 WHERE id > last_id 代替 offset
   - 优势是无论多深,性能都稳定
   - 适用于时间线、feed 流等场景

3. **业务优化:** 限制最大可查看页数,或使用滚动加载代替分页

4. **使用 ES:** 复杂搜索场景可以使用 Elasticsearch,它的 search_after 机制天然支持深分页。

在我之前的项目中,优化过一个 3000 万行的订单表,通过添加联合索引和使用游标分页,将查询时间从 5 秒降到 50 毫秒。"
