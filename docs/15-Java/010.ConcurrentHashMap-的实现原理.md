---
title: ConcurrentHashMap 的实现原理
tags:
  - Java
status: robot
class: Java
slug: concurrenthashmap-implementation
ref:
---

## 核心要点

- **设计目标**：提供线程安全的哈希表，同时保持高并发性能
- **演进历程**：分段锁（JDK1.7）→ CAS+synchronized（JDK1.8+）
- **核心技术**：CAS无锁操作、volatile可见性、分段加锁策略
- **性能优化**：减少锁竞争、支持并发读写、动态扩容

## 详细解答

### 1. ConcurrentHashMap设计背景

在多线程环境下，普通的HashMap存在线程安全问题，而Hashtable虽然线程安全但性能较差（全表锁定）。ConcurrentHashMap应运而生，旨在提供既线程安全又高性能的并发哈希表。

**设计原则：**
- **线程安全**：保证多线程环境下的数据一致性
- **高并发**：支持多个线程同时读写操作
- **无锁读取**：读操作不需要加锁
- **分段加锁**：写操作只锁定相关部分

### 2. JDK 1.7 vs JDK 1.8+ 实现对比

#### JDK 1.7 - 分段锁实现

```java
// JDK 1.7 ConcurrentHashMap 简化结构
public class ConcurrentHashMap<K,V> {
    // 默认并发级别
    static final int DEFAULT_CONCURRENCY_LEVEL = 16;

    // 最大分段数
    static final int MAX_SEGMENTS = 1 << 16;

    // 分段数组
    final Segment<K,V>[] segments;

    // 构造函数
    public ConcurrentHashMap(int initialCapacity,
                           float loadFactor,
                           int concurrencyLevel) {
        // 计算分段数（2的幂）
        int ssize = 1;
        while (ssize < concurrencyLevel) {
            ssize <<= 1;
        }

        // 初始化分段数组
        this.segments = new Segment[ssize];

        // 初始化每个分段
        for (int i = 0; i < segments.length; i++) {
            segments[i] = new Segment<K,V>(loadFactor);
        }
    }
}

// 分段类，继承ReentrantLock
static final class Segment<K,V> extends ReentrantLock {
    // 该分段的哈希表
    volatile HashEntry<K,V>[] table;

    // 元素数量
    int count;

    // 修改次数
    int modCount;

    // 扩容阈值
    int threshold;

    // 负载因子
    final float loadFactor;
}

// 哈希桶中的节点
static final class HashEntry<K,V> {
    final int hash;
    final K key;
    volatile V value;
    volatile HashEntry<K,V> next;
}
```

#### JDK 1.8+ - CAS + synchronized实现

```java
// JDK 1.8+ ConcurrentHashMap 简化结构
public class ConcurrentHashMap<K,V> {
    // 节点数组
    volatile Node<K,V>[] table;

    // 扩容时的新数组
    private volatile Node<K,V>[] nextTable;

    // 基础计数器
    private volatile long baseCount;

    // 计数器数组
    private volatile CounterCell[] counterCells;

    // 扩容控制标识
    private volatile int sizeCtl;

    // 转移索引
    private volatile int transferIndex;
}

// 普通节点
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V value;
    volatile Node<K,V> next;
}

// 红黑树节点
static final class TreeNode<K,V> extends Node<K,V> {
    TreeNode<K,V> parent;
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;
    boolean red;
}

// 转发节点（扩容时使用）
static final class ForwardingNode<K,V> extends Node<K,V> {
    final Node<K,V>[] nextTable;

    ForwardingNode(Node<K,V>[] tab) {
        super(MOVED, null, null, null);  // hash = MOVED = -1
        this.nextTable = tab;
    }
}
```

### 3. JDK 1.7 分段锁机制

#### 分段锁原理
```java
// 分段锁的核心思想
public class SegmentLockDemo {
    public static void main(String[] args) {
        // 假设有16个分段，支持最多16个线程并发写入
        // 每个分段独立加锁，互不影响

        // 计算key所属的分段
        int hash = key.hashCode();
        int segmentIndex = (hash >>> segmentShift) & segmentMask;
        Segment<K,V> segment = segments[segmentIndex];

        // 只对该分段加锁
        segment.lock();
        try {
            // 在该分段内进行操作
            segment.put(key, value);
        } finally {
            segment.unlock();
        }
    }
}
```

#### 分段锁的put操作
```java
// JDK 1.7 put操作的简化实现
public V put(K key, V value) {
    Segment<K,V> s;
    if (value == null)
        throw new NullPointerException();

    int hash = hash(key);
    // 定位到具体分段
    int j = (hash >>> segmentShift) & segmentMask;

    if ((s = (Segment<K,V>)UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null)
        s = ensureSegment(j);

    return s.put(key, hash, value, false);
}

// Segment的put方法
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
    V oldValue;

    try {
        HashEntry<K,V>[] tab = table;
        int index = (tab.length - 1) & hash;
        HashEntry<K,V> first = entryAt(tab, index);

        for (HashEntry<K,V> e = first;;) {
            if (e != null) {
                K k;
                if ((k = e.key) == key || (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            } else {
                // 插入新节点
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);

                int c = count + 1;
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    rehash(node);  // 分段扩容
                else
                    setEntryAt(tab, index, node);

                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        unlock();
    }
    return oldValue;
}
```

#### 分段锁的get操作
```java
// JDK 1.7 get操作（无锁）
public V get(Object key) {
    Segment<K,V> s;
    HashEntry<K,V>[] tab;
    int h = hash(key);

    // 定位分段
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;

    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
        (tab = s.table) != null) {

        // 在分段中查找
        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile
                 (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
             e != null; e = e.next) {

            K k;
            if ((k = e.key) == key || (e.hash == h && key.equals(k)))
                return e.value;
        }
    }
    return null;
}
```

### 4. JDK 1.8+ CAS + synchronized机制

#### 无锁化改进
```java
// JDK 1.8+ 的核心改进点
public class JDK8Improvements {
    // 1. 放弃分段锁，改用CAS + synchronized
    // 2. 锁粒度更细：锁定单个桶的首节点
    // 3. 读操作完全无锁
    // 4. 引入红黑树优化长链表
    // 5. 并发扩容，多线程协助
}
```

#### CAS操作的应用
```java
// 关键的CAS操作
public class CASOperations {

    // 比较并设置数组元素
    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
                                       Node<K,V> c, Node<K,V> v) {
        return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
    }

    // 获取数组元素（volatile读）
    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int index) {
        return (Node<K,V>)U.getObjectVolatile(tab, ((long)index << ASHIFT) + ABASE);
    }

    // 设置数组元素（volatile写）
    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
        U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
    }
}
```

#### put操作实现
```java
// JDK 1.8+ put操作的简化实现
public V put(K key, V value) {
    return putVal(key, value, false);
}

final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();

    int hash = spread(key.hashCode());
    int binCount = 0;

    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;

        // 1. 如果表为空，进行初始化
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();

        // 2. 如果桶为空，使用CAS插入
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null)))
                break;
        }

        // 3. 如果正在扩容，协助扩容
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);

        // 4. 如果桶不为空，使用synchronized
        else {
            V oldVal = null;
            synchronized (f) {  // 锁定首节点
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {  // 链表节点
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 找到相同的key，更新value
                            if (e.hash == hash && ((ek = e.key) == key ||
                                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.value;
                                if (!onlyIfAbsent)
                                    e.value = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            // 到达链表尾部，插入新节点
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key, value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {  // 红黑树节点
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
                            oldVal = p.value;
                            if (!onlyIfAbsent)
                                p.value = value;
                        }
                    }
                }
            }

            if (binCount != 0) {
                // 如果链表长度达到阈值，转换为红黑树
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }

    // 增加元素计数
    addCount(1L, binCount);
    return null;
}
```

#### get操作实现
```java
// JDK 1.8+ get操作（完全无锁）
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    int h = spread(key.hashCode());

    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {

        // 检查首节点
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.value;
        }
        // 如果首节点hash值为负，说明是特殊节点
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.value : null;

        // 遍历链表
        while ((e = e.next) != null) {
            if (e.hash == h && ((ek = e.key) == key ||
                              (ek != null && key.equals(ek))))
                return e.value;
        }
    }
    return null;
}
```

### 5. 并发扩容机制

#### 扩容触发条件
```java
// 扩容触发机制
private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;

    // 尝试更新baseCount
    if ((as = counterCells) != null ||
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {

        CounterCell a; long v; int m;
        boolean uncontended = true;

        // 如果更新失败，使用CounterCell数组
        if (as == null || (m = as.length - 1) < 0 ||
            (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
            !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            fullAddCount(x, uncontended);
            return;
        }

        if (check <= 1)
            return;
        s = sumCount();
    }

    // 检查是否需要扩容
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
               (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);

            if (sc < 0) {
                // 已经在扩容，协助扩容
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex <= 0)
                    break;

                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            // 开始扩容
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                       (rs << RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
```

#### 多线程协助扩容
```java
// 扩容数据迁移
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    int n = tab.length, stride;

    // 计算每个线程处理的桶数量
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE;

    // 初始化新表
    if (nextTab == null) {
        try {
            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
            nextTab = nt;
        } catch (Throwable ex) {
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;
        transferIndex = n;
    }

    int nextn = nextTab.length;
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    boolean advance = true;
    boolean finishing = false;

    for (int i = 0, bound = 0;;) {
        Node<K,V> f; int fh;

        // 获取下一个要处理的桶
        while (advance) {
            int nextIndex, nextBound;
            if (--i >= bound || finishing)
                advance = false;
            else if ((nextIndex = transferIndex) <= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex,
                                       nextBound = (nextIndex > stride ?
                                                  nextIndex - stride : 0))) {
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }

        // 处理单个桶的迁移
        if (i < 0 || i >= n || i + n >= nextn) {
            // 完成扩容
            if (finishing) {
                nextTable = null;
                table = nextTab;
                sizeCtl = (n << 1) - (n >>> 1);
                return;
            }
            // ... 其他完成逻辑
        }
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        else if ((fh = f.hash) == MOVED)
            advance = true; // 已经被处理
        else {
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    Node<K,V> ln, hn;
                    if (fh >= 0) {
                        // 处理链表
                        int runBit = fh & n;
                        Node<K,V> lastRun = f;
                        for (Node<K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash & n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        } else {
                            hn = lastRun;
                            ln = null;
                        }
                        // 分离链表
                        for (Node<K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.value;
                            if ((ph & n) == 0)
                                ln = new Node<K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node<K,V>(ph, pk, pv, hn);
                        }
                        // 放入新表
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        // 处理红黑树
                        TreeBin<K,V> t = (TreeBin<K,V>)f;
                        TreeNode<K,V> lo = null, loTail = null;
                        TreeNode<K,V> hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        // ... 红黑树分离逻辑
                    }
                }
            }
        }
    }
}
```

### 6. 计数机制

#### 分布式计数器
```java
// CounterCell - 分布式计数单元
static final class CounterCell {
    volatile long value;
    CounterCell(long x) { value = x; }
}

// 计算总数
final long sumCount() {
    CounterCell[] as = counterCells; CounterCell a;
    long sum = baseCount;
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}

// size方法实现
public int size() {
    long n = sumCount();
    return ((n < 0L) ? 0 :
            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}
```

### 7. 性能对比分析

#### JDK 1.7 vs JDK 1.8 性能对比
```java
public class PerformanceComparison {

    // JDK 1.7 分段锁的优缺点
    static class JDK7Analysis {
        // 优点：
        // 1. 并发度固定，可预测
        // 2. 读写分离明确
        // 3. 锁竞争相对较少

        // 缺点：
        // 1. 并发度受限于分段数
        // 2. 内存占用较大（每个分段都是独立的哈希表）
        // 3. 分段分布不均可能导致性能瓶颈
        // 4. size()计算复杂，需要多次加锁
    }

    // JDK 1.8+ CAS+synchronized的优缺点
    static class JDK8Analysis {
        // 优点：
        // 1. 并发度更高，理论上无限制
        // 2. 内存利用率更高
        // 3. 锁粒度更细，减少竞争
        // 4. 支持红黑树优化
        // 5. 并发扩容，性能更好

        // 缺点：
        // 1. 实现复杂度较高
        // 2. CAS操作在高竞争时性能可能下降
    }

    public static void main(String[] args) {
        // 性能测试示例
        testConcurrentPerformance();
    }

    static void testConcurrentPerformance() {
        int threadCount = 16;
        int operationsPerThread = 100000;

        ConcurrentHashMap<Integer, String> map = new ConcurrentHashMap<>();

        long startTime = System.currentTimeMillis();

        // 创建多个线程并发操作
        Thread[] threads = new Thread[threadCount];
        for (int i = 0; i < threadCount; i++) {
            final int threadId = i;
            threads[i] = new Thread(() -> {
                for (int j = 0; j < operationsPerThread; j++) {
                    int key = threadId * operationsPerThread + j;
                    map.put(key, "value" + key);
                    map.get(key);
                }
            });
            threads[i].start();
        }

        // 等待所有线程完成
        for (Thread thread : threads) {
            try {
                thread.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        long endTime = System.currentTimeMillis();
        System.out.println("并发操作耗时: " + (endTime - startTime) + "ms");
        System.out.println("最终大小: " + map.size());
    }
}
```

### 8. 关键特性深入

#### volatile关键字的使用
```java
// ConcurrentHashMap中的volatile使用
public class VolatileUsage {

    // 1. table数组使用volatile保证可见性
    volatile Node<K,V>[] table;

    // 2. Node节点的value和next使用volatile
    static class Node<K,V> {
        final int hash;
        final K key;
        volatile V value;  // 保证value的可见性
        volatile Node<K,V> next;  // 保证链表结构的可见性
    }

    // 3. 控制变量使用volatile
    private volatile int sizeCtl;  // 扩容控制
    private volatile long baseCount;  // 基础计数

    // volatile的作用：
    // 1. 保证可见性：一个线程的修改立即被其他线程看到
    // 2. 禁止重排序：防止指令重排序导致的问题
    // 3. 不保证原子性：需要配合CAS操作保证原子性
}
```

#### 弱一致性迭代器
```java
// ConcurrentHashMap的迭代器特性
public class WeakConsistencyIterator {

    public static void main(String[] args) {
        ConcurrentHashMap<String, String> map = new ConcurrentHashMap<>();
        map.put("key1", "value1");
        map.put("key2", "value2");
        map.put("key3", "value3");

        // 弱一致性迭代器
        Iterator<Map.Entry<String, String>> iterator = map.entrySet().iterator();

        // 在迭代过程中修改map
        new Thread(() -> {
            map.put("key4", "value4");  // 可能在迭代中看到
            map.remove("key2");         // 可能在迭代中看到
        }).start();

        // 迭代输出
        while (iterator.hasNext()) {
            Map.Entry<String, String> entry = iterator.next();
            System.out.println(entry.getKey() + " = " + entry.getValue());

            try {
                Thread.sleep(100);  // 模拟处理时间
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        // 弱一致性的特点：
        // 1. 不会抛出ConcurrentModificationException
        // 2. 可能看到迭代开始后的修改
        // 3. 不保证看到所有修改
        // 4. 保证最终一致性
    }
}
```

### 9. 使用场景和最佳实践

#### 适用场景
```java
public class UsageScenarios {

    // 1. 高并发读写场景
    public void highConcurrencyScenario() {
        ConcurrentHashMap<String, UserSession> sessionMap = new ConcurrentHashMap<>();

        // 多个线程同时读写用户会话
        // 读多写少的场景，性能优异
    }

    // 2. 缓存实现
    public void cacheImplementation() {
        ConcurrentHashMap<String, Object> cache = new ConcurrentHashMap<>();

        // 使用computeIfAbsent实现缓存
        public Object getCachedValue(String key) {
            return cache.computeIfAbsent(key, k -> {
                // 昂贵的计算或I/O操作
                return expensiveOperation(k);
            });
        }
    }

    // 3. 计数器实现
    public void counterImplementation() {
        ConcurrentHashMap<String, AtomicLong> counters = new ConcurrentHashMap<>();

        public void increment(String category) {
            counters.computeIfAbsent(category, k -> new AtomicLong(0))
                   .incrementAndGet();
        }
    }

    // 4. 生产者-消费者缓冲区
    public void producerConsumerBuffer() {
        ConcurrentHashMap<String, BlockingQueue<Task>> taskQueues =
            new ConcurrentHashMap<>();

        // 按类型分组的任务队列
        public void addTask(String type, Task task) {
            taskQueues.computeIfAbsent(type,
                k -> new LinkedBlockingQueue<>()).offer(task);
        }
    }
}
```

#### 性能优化建议
```java
public class OptimizationTips {

    // 1. 合理设置初始容量
    public void initialCapacityOptimization() {
        // 避免频繁扩容
        int expectedSize = 10000;
        int initialCapacity = (int)(expectedSize / 0.75f) + 1;
        ConcurrentHashMap<String, String> map =
            new ConcurrentHashMap<>(initialCapacity);
    }

    // 2. 使用computeIfAbsent避免竞争
    public void computeIfAbsentOptimization() {
        ConcurrentHashMap<String, List<String>> map = new ConcurrentHashMap<>();

        // 错误做法：可能创建多个List实例
        // if (!map.containsKey(key)) {
        //     map.put(key, new ArrayList<>());
        // }

        // 正确做法：原子操作
        map.computeIfAbsent("key", k -> new ArrayList<>()).add("value");
    }

    // 3. 避免在高并发环境下使用size()
    public void avoidSizeInHighConcurrency() {
        ConcurrentHashMap<String, String> map = new ConcurrentHashMap<>();

        // size()方法需要遍历所有分段，在高并发环境下性能较差
        // 如果需要精确计数，考虑使用AtomicLong单独维护
        AtomicLong count = new AtomicLong(0);

        public void put(String key, String value) {
            if (map.put(key, value) == null) {
                count.incrementAndGet();
            }
        }

        public long getCount() {
            return count.get();  // 比map.size()性能更好
        }
    }

    // 4. 批量操作优化
    public void batchOperationOptimization() {
        ConcurrentHashMap<String, String> map = new ConcurrentHashMap<>();

        // 使用putAll进行批量插入
        Map<String, String> batch = new HashMap<>();
        for (int i = 0; i < 1000; i++) {
            batch.put("key" + i, "value" + i);
        }
        map.putAll(batch);  // 比逐个put性能更好
    }
}
```

### 10. 总结

ConcurrentHashMap的演进体现了Java并发编程的发展历程：

**JDK 1.7的分段锁：**
- 将大锁分解为小锁，提高并发度
- 读写分离，读操作基本无锁
- 并发度受限于分段数

**JDK 1.8+的CAS+synchronized：**
- 更细粒度的锁定策略
- 无锁化的CAS操作
- 动态的并发扩容
- 红黑树优化长链表

ConcurrentHashMap是高并发场景下的理想选择，其设计思想和实现技巧为其他并发数据结构的设计提供了重要参考。理解其实现原理有助于编写高性能的并发程序和正确使用并发工具。
