---
title: Kubernetes 的资源限制（requests、limits）
tags:
  - Kubernetes
status: robot
class: Kubernetes
slug: kubernetes-resource-requests-limits
ref:
---

## 核心要点

- **requests**：Pod 调度的最低资源保证，调度器基于此分配节点，容器实际可用资源的下限
- **limits**：Pod 运行的资源上限，超过 CPU limits 会被限流，超过内存 limits 会被 OOMKilled
- **QoS 分类**：根据 requests/limits 配置，Pod 分为 Guaranteed、Burstable、BestEffort 三个等级
- **生产原则**：requests 设置为正常负载值，limits 设置为峰值负载值，避免资源超卖和节点雪崩

## 详细解答

### 一、资源限制的核心概念

#### 1. requests 与 limits 的本质区别

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
  - name: app
    image: nginx:latest
    resources:
      requests:           # 调度阶段的资源预留
        cpu: 500m         # 0.5 个 CPU 核心（millicore）
        memory: 256Mi     # 256 MiB 内存
      limits:             # 运行阶段的资源上限
        cpu: 1000m        # 1 个 CPU 核心
        memory: 512Mi     # 512 MiB 内存
```

**关键理解：**

| 维度 | requests | limits |
|------|----------|--------|
| **作用阶段** | 调度时（Scheduling） | 运行时（Runtime） |
| **保证性** | 硬保证（节点必须有足够资源） | 软限制（允许超额分配） |
| **调度依据** | 调度器基于 requests 选择节点 | 不影响调度决策 |
| **超出行为** | 不会发生（已预留） | CPU 限流，内存 OOM |
| **成本影响** | 直接影响节点利用率和集群成本 | 仅影响运行时稳定性 |

#### 2. CPU 与内存的差异行为

**CPU（可压缩资源 - Compressible）：**
- 超过 limits 时被**限流**（throttling），Pod 变慢但不会被杀死
- 通过 CFS（Completely Fair Scheduler）配额实现
- `cpu.cfs_period_us`（默认 100ms）和 `cpu.cfs_quota_us`（配额）控制

**内存（不可压缩资源 - Incompressible）：**
- 超过 limits 时触发 **OOMKilled**，Pod 被强制终止
- 内核 OOM Killer 选择优先级最低的容器杀死
- 重启策略（restartPolicy）决定是否自动重启

**实际案例：**
```bash
# CPU 超限的表现（查看限流次数）
kubectl top pod <pod-name>
# 如果 CPU 使用率接近 100%（limits 值），检查 throttling
kubectl exec <pod-name> -- cat /sys/fs/cgroup/cpu/cpu.stat
# nr_throttled: 被限流的次数
# throttled_time: 总限流时间（纳秒）

# 内存超限的表现
kubectl describe pod <pod-name>
# 输出显示：Last State: Terminated, Reason: OOMKilled, Exit Code: 137
```

### 二、QoS（Quality of Service）分类

Kubernetes 根据 Pod 的资源配置自动分配 QoS 等级，决定资源竞争时的优先级和驱逐顺序。

#### 1. Guaranteed（最高优先级）

**条件：**
- **所有容器**都设置了 CPU 和内存的 requests 和 limits
- 每个容器的 `requests == limits`

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: guaranteed-pod
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: 1000m
        memory: 512Mi
      limits:
        cpu: 1000m      # 与 requests 相同
        memory: 512Mi   # 与 requests 相同
```

**特性：**
- 资源完全预留，性能最稳定
- 节点资源不足时**最后被驱逐**
- 适用场景：数据库、关键业务服务、有状态应用

#### 2. Burstable（中等优先级）

**条件：**
- 至少一个容器设置了 requests 或 limits
- 不满足 Guaranteed 条件（requests ≠ limits）

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: 500m
        memory: 256Mi
      limits:
        cpu: 2000m      # 允许突发到 2 核
        memory: 1Gi     # 允许突发到 1GB
```

**特性：**
- 正常情况下保证 requests 资源，可临时使用更多（burst）
- 节点资源不足时，优先驱逐**内存使用超过 requests 最多**的 Pod
- 适用场景：Web 应用、API 服务、大部分无状态应用

#### 3. BestEffort（最低优先级）

**条件：**
- **所有容器都没有**设置 requests 和 limits

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: besteffort-pod
spec:
  containers:
  - name: app
    image: nginx
    # 未设置 resources
```

**特性：**
- 不保证任何资源，可以使用节点所有空闲资源
- 节点资源不足时**第一个被驱逐**
- 适用场景：批处理任务、低优先级任务、测试环境

#### 4. QoS 驱逐优先级

```
节点资源不足时的驱逐顺序：
BestEffort（先驱逐） > Burstable（按超额使用排序） > Guaranteed（最后驱逐）
```

**驱逐示例场景：**
节点内存 16GB，已调度 Pod：
- `pod-guaranteed`（Guaranteed，8GB requests/limits）
- `pod-burstable`（Burstable，4GB requests，8GB limits，实际使用 6GB）
- `pod-besteffort`（BestEffort，实际使用 3GB）

内存不足时驱逐顺序：
1. **pod-besteffort**（BestEffort 等级）
2. **pod-burstable**（已超出 requests 50%）
3. **pod-guaranteed**（最后选项）

### 三、资源配置最佳实践

#### 1. 正确设置 requests 的原则

**方法一：压测法（推荐）**
```bash
# 1. 不设置 requests/limits，模拟真实负载压测
kubectl run load-test --image=busybox -- /bin/sh -c "while true; do wget -q -O- http://my-service; done"

# 2. 观察 Pod 资源使用
kubectl top pod <pod-name> --containers

# 3. 分析 Prometheus 监控数据
# 查询 P99 CPU 使用率
histogram_quantile(0.99, rate(container_cpu_usage_seconds_total[5m]))

# 查询 P99 内存使用
histogram_quantile(0.99, container_memory_working_set_bytes)

# 4. 设置 requests
# CPU: P50 使用量 × 1.2（20% 余量）
# 内存: P90 使用量 × 1.3（30% 余量）
```

**方法二：VPA（Vertical Pod Autoscaler）自动推荐**
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: my-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  updatePolicy:
    updateMode: "Off"  # 仅推荐，不自动更新
```

查看 VPA 推荐值：
```bash
kubectl describe vpa my-app-vpa
# 输出：
# Recommendation:
#   Container Recommendations:
#     Container Name: app
#     Lower Bound:     cpu: 250m, memory: 262144k
#     Target:          cpu: 500m, memory: 524288k  # 使用此值
#     Upper Bound:     cpu: 1000m, memory: 1048576k
```

#### 2. 正确设置 limits 的原则

**CPU limits 设置策略：**
```yaml
# 方案1：限制峰值（推荐用于共享节点）
requests:
  cpu: 500m    # 正常负载
limits:
  cpu: 2000m   # 允许突发，但不影响其他 Pod

# 方案2：不设置 limits（推荐用于性能敏感应用）
requests:
  cpu: 2000m
# 不设置 limits，避免 CPU 限流影响性能
```

**内存 limits 设置策略：**
```yaml
# 原则：limits = requests × 1.5 ~ 2
requests:
  memory: 512Mi   # 正常负载
limits:
  memory: 1Gi     # 允许 100% 突发，防止内存泄漏影响节点
```

#### 3. 常见错误配置及后果

**错误1：requests 设置过高**
```yaml
resources:
  requests:
    cpu: 4000m      # 过高
    memory: 8Gi     # 过高
  limits:
    cpu: 4000m
    memory: 8Gi
```
**后果：**
- 节点资源利用率低（实际使用 < 50%，但已满载）
- Pod 调度失败（明明节点空闲，但无法调度）
- 成本浪费（需要更多节点）

**错误2：requests 设置过低**
```yaml
resources:
  requests:
    cpu: 100m       # 过低
    memory: 64Mi    # 过低
  limits:
    cpu: 2000m
    memory: 2Gi
```
**后果：**
- 节点资源超卖（调度器认为节点可用，实际已过载）
- 所有 Pod 性能下降（CPU 争抢，内存 OOM）
- 节点雪崩（系统组件被驱逐，节点 NotReady）

**错误3：不设置 limits**
```yaml
resources:
  requests:
    cpu: 500m
    memory: 512Mi
  # 未设置 limits
```
**后果：**
- CPU：好处是避免限流，坏处是可能占满节点 CPU
- 内存：**高危**！内存泄漏可能耗尽节点内存，导致节点崩溃

#### 4. 生产环境推荐配置模板

**Web 应用（无状态）：**
```yaml
resources:
  requests:
    cpu: 200m        # 正常请求处理能力
    memory: 256Mi    # 正常内存占用
  limits:
    cpu: 1000m       # 允许突发到 5 倍
    memory: 512Mi    # 允许突发到 2 倍
```

**数据库（有状态）：**
```yaml
resources:
  requests:
    cpu: 2000m       # 保证性能
    memory: 4Gi      # 保证缓存命中率
  limits:
    cpu: 2000m       # 与 requests 相同（Guaranteed）
    memory: 4Gi      # 严格限制，避免 OOM
```

**批处理任务：**
```yaml
resources:
  requests:
    cpu: 500m
    memory: 1Gi
  limits:
    cpu: 4000m       # 允许使用更多 CPU 加速
    memory: 2Gi      # 适度限制内存
```

### 四、节点资源分配机制

#### 1. 节点可分配资源计算

```
可分配资源（Allocatable）= 节点总容量 - 系统预留 - kubelet 预留 - 驱逐阈值

示例（16核 32GB 节点）：
CPU Allocatable = 16000m - 100m（系统） - 100m（kubelet） = 15800m
Memory Allocatable = 32Gi - 1Gi（系统） - 1Gi（kubelet） - 1Gi（驱逐） = 29Gi
```

**查看节点可分配资源：**
```bash
kubectl describe node <node-name>
# 输出：
# Capacity:
#   cpu:     16
#   memory:  32Gi
# Allocatable:
#   cpu:     15800m
#   memory:  29Gi
# Allocated resources:
#   cpu requests:     8500m (53%)
#   cpu limits:       20000m (126%)  # 允许超额
#   memory requests:  15Gi (51%)
#   memory limits:    25Gi (86%)
```

#### 2. 资源超卖（Overcommit）

Kubernetes 允许 limits 总和超过节点容量：

```
节点 CPU 容量：16 核
已调度 Pod 的 CPU limits 总和：32 核（200% 超卖）

只要 requests 总和 ≤ Allocatable，调度就会成功
```

**风险与应对：**
- **风险**：所有 Pod 同时达到 limits 时，节点 CPU 100%，所有容器被限流
- **应对**：
  1. 限制超卖比例（limits 总和 ≤ 容量 × 150%）
  2. 使用 PodDisruptionBudget 保证最少可用副本
  3. 监控节点 CPU 使用率，超过 80% 告警

### 五、常见问题与排查

#### Q1：Pod 一直 Pending，无法调度？

**排查步骤：**
```bash
# 1. 查看 Pod 事件
kubectl describe pod <pod-name>
# 常见原因：
# - Insufficient cpu: 节点 CPU requests 已满
# - Insufficient memory: 节点内存 requests 已满

# 2. 查看节点资源
kubectl top nodes
kubectl describe node <node-name> | grep -A 5 "Allocated resources"

# 3. 解决方案
# - 降低 Pod 的 requests
# - 增加集群节点
# - 清理不必要的 Pod
```

#### Q2：Pod 频繁 OOMKilled？

**排查步骤：**
```bash
# 1. 确认是内存 limits 导致
kubectl describe pod <pod-name> | grep -A 5 "Last State"
# 输出：Reason: OOMKilled, Exit Code: 137

# 2. 查看实际内存使用
kubectl top pod <pod-name> --containers

# 3. 查看容器日志（可能有内存泄漏）
kubectl logs <pod-name> --previous

# 4. 解决方案
# - 提高 memory limits
# - 修复内存泄漏
# - 优化应用内存使用
```

#### Q3：CPU 使用率低，但 Pod 响应慢？

**可能原因：CPU 限流（throttling）**

```bash
# 检查 CPU 限流情况
kubectl exec <pod-name> -- cat /sys/fs/cgroup/cpu/cpu.stat | grep throttled

# 输出：
# nr_throttled: 15234        # 被限流次数
# throttled_time: 3600000000 # 总限流时间（3.6 秒）

# 解决方案：
# - 提高 CPU limits
# - 考虑不设置 CPU limits（性能优先场景）
# - 优化代码性能
```

### 六、监控与告警

**关键监控指标：**
```promql
# Pod CPU 使用率 vs requests
sum(rate(container_cpu_usage_seconds_total[5m])) by (pod)
/
sum(kube_pod_container_resource_requests{resource="cpu"}) by (pod)

# Pod 内存使用率 vs requests
sum(container_memory_working_set_bytes) by (pod)
/
sum(kube_pod_container_resource_requests{resource="memory"}) by (pod)

# CPU 限流次数
rate(container_cpu_cfs_throttled_seconds_total[5m])

# 节点资源利用率
sum(kube_pod_container_resource_requests{resource="cpu"})
/
sum(kube_node_status_allocatable{resource="cpu"})
```

**告警规则示例：**
```yaml
- alert: PodMemoryNearLimit
  expr: |
    container_memory_working_set_bytes
    /
    container_spec_memory_limit_bytes > 0.9
  for: 5m
  annotations:
    summary: "Pod {{ $labels.pod }} 内存使用接近 limits"

- alert: CPUThrottlingHigh
  expr: |
    rate(container_cpu_cfs_throttled_seconds_total[5m]) > 0.3
  for: 10m
  annotations:
    summary: "Pod {{ $labels.pod }} CPU 限流严重（> 30%）"
```

### 七、进阶技巧

#### 1. LimitRange：命名空间级别默认值

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: default-limits
  namespace: production
spec:
  limits:
  - default:           # 默认 limits
      cpu: 1000m
      memory: 512Mi
    defaultRequest:    # 默认 requests
      cpu: 200m
      memory: 256Mi
    max:               # 单个 Pod 最大值
      cpu: 4000m
      memory: 8Gi
    min:               # 单个 Pod 最小值
      cpu: 50m
      memory: 64Mi
    type: Container
```

#### 2. ResourceQuota：命名空间资源配额

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: team-quota
  namespace: team-a
spec:
  hard:
    requests.cpu: "20"        # 命名空间总 CPU requests 上限
    requests.memory: 40Gi     # 命名空间总内存 requests 上限
    limits.cpu: "40"          # 命名空间总 CPU limits 上限
    limits.memory: 80Gi       # 命名空间总内存 limits 上限
    pods: "50"                # 最多 50 个 Pod
```

#### 3. PriorityClass：Pod 优先级

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000          # 优先级分数（越高越优先）
globalDefault: false
description: "关键业务服务"
---
apiVersion: v1
kind: Pod
metadata:
  name: critical-app
spec:
  priorityClassName: high-priority  # 使用高优先级
  containers:
  - name: app
    image: nginx
```

**抢占（Preemption）机制：**
- 高优先级 Pod 调度失败时，可以驱逐低优先级 Pod
- 配合 QoS 使用，实现精细化资源管理
