---
title: Kubernetes 的 HPA（水平自动扩缩容）
tags:
  - Kubernetes
status: robot
class: Kubernetes
slug: kubernetes-hpa-horizontal-autoscaling
ref:
---

## 核心要点

- **HPA 原理**：基于观测到的 CPU、内存或自定义指标，自动调整 Pod 副本数量
- **工作机制**：Metrics Server 收集指标 → HPA 控制器计算目标副本数 → 调整 Deployment/ReplicaSet
- **扩缩容算法**：期望副本数 = ceil[当前副本数 × (当前指标值 / 目标指标值)]
- **生产关键**：合理设置资源请求值、配置冷却时间、避免指标抖动

## 详细解答

### 一、HPA（Horizontal Pod Autoscaler）深度解析

#### 1. 什么是 HPA

HPA 是 Kubernetes 的自动扩缩容控制器，通过**水平扩展**（增加/减少 Pod 数量）的方式，根据实际负载自动调整应用副本数，与垂直扩展（VPA，调整单个 Pod 资源）形成互补。

**典型应用场景：**
- Web 应用根据流量自动扩容
- API 服务根据请求延迟调整副本
- 消息队列消费者根据队列长度扩缩容
- 机器学习推理服务根据 GPU 利用率扩展

#### 2. HPA 架构与工作流程

```
┌─────────────────────────────────────────────────┐
│  1. Metrics Server/Prometheus Adapter 收集指标  │
└────────────────┬────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────┐
│  2. HPA Controller 每 15s 查询指标并计算         │
│     期望副本数 = ceil[当前副本数 × (当前/目标)]  │
└────────────────┬────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────┐
│  3. 调整 Deployment/ReplicaSet 的 replicas      │
└────────────────┬────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────┐
│  4. Deployment Controller 创建/删除 Pod          │
└─────────────────────────────────────────────────┘
```

**关键组件：**
- **Metrics Server**：提供核心指标（CPU、内存）
- **Prometheus Adapter**：提供自定义指标（QPS、延迟等）
- **HPA Controller**：计算并执行扩缩容决策

### 二、HPA 配置详解

#### 1. 基于 CPU 的基础配置

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
  namespace: production
spec:
  # 目标工作负载
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  # 副本数范围
  minReplicas: 2
  maxReplicas: 10
  # 指标配置
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # 目标 CPU 使用率 70%
  # 扩缩容行为控制
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 缩容稳定窗口 5 分钟
      policies:
      - type: Percent
        value: 50        # 每次最多缩容 50%
        periodSeconds: 60
      - type: Pods
        value: 2         # 每次最多缩容 2 个 Pod
        periodSeconds: 60
      selectPolicy: Min  # 选择最保守的策略
    scaleUp:
      stabilizationWindowSeconds: 0  # 扩容立即生效
      policies:
      - type: Percent
        value: 100       # 每次最多扩容 100%（翻倍）
        periodSeconds: 15
      - type: Pods
        value: 4         # 每次最多扩容 4 个 Pod
        periodSeconds: 15
      selectPolicy: Max  # 选择最激进的策略
```

**重要说明：**
- `averageUtilization: 70` 表示所有 Pod 的平均 CPU 使用率达到**请求值的 70%** 时触发扩容
- **必须设置 `resources.requests`**，否则 HPA 无法计算使用率

#### 2. 多指标混合配置

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  # 指标1：CPU 使用率
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 80
  # 指标2：内存使用率
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 85
  # 指标3：自定义指标（每秒请求数）
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"  # 每个 Pod 处理 1000 RPS
  # 指标4：外部指标（SQS 队列长度）
  - type: External
    external:
      metric:
        name: sqs_queue_length
        selector:
          matchLabels:
            queue_name: task_queue
      target:
        type: AverageValue
        averageValue: "30"  # 每个 Pod 处理 30 条消息
```

**多指标决策逻辑：**
HPA 为**每个指标**单独计算期望副本数，然后取**最大值**作为最终副本数（保守策略，确保所有指标都满足）。

### 三、HPA 扩缩容算法详解

#### 1. 核心计算公式

```
期望副本数 = ceil[ 当前副本数 × (当前指标值 / 目标指标值) ]
```

**实际案例计算：**

假设当前有 4 个 Pod，每个 Pod 的 CPU 请求值为 200m，目标使用率 70%：
- **当前总 CPU 使用**：400m（4 个 Pod × 100m）
- **目标总 CPU 使用**：560m（4 个 Pod × 200m × 70%）
- **当前指标值**：400m / (4 × 200m) = 50%
- **期望副本数**：ceil[4 × (50% / 70%)] = ceil[2.86] = **3 个 Pod**（缩容）

如果流量突增，当前总 CPU 使用变为 800m：
- **当前指标值**：800m / (4 × 200m) = 100%
- **期望副本数**：ceil[4 × (100% / 70%)] = ceil[5.71] = **6 个 Pod**（扩容）

#### 2. 容忍度机制（Tolerance）

为了避免指标轻微抖动导致频繁扩缩容，HPA 内置 **10% 的容忍度**：

```
只有当 |当前指标值 - 目标指标值| / 目标指标值 > 0.1 时才触发扩缩容
```

**示例：**
- 目标 CPU 使用率：70%
- 实际使用率在 63%-77% 之间（70% ± 10%）时，**不触发**扩缩容
- 使用率 < 63% 时触发缩容，> 77% 时触发扩容

### 四、生产环境最佳实践

#### 1. 资源请求值设置

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: web-app:v1.0
        resources:
          requests:
            cpu: 200m      # 必须设置！HPA 基于此计算使用率
            memory: 256Mi
          limits:
            cpu: 500m      # 限制峰值，避免资源争抢
            memory: 512Mi
```

**关键原则：**
- `requests` 设置为**正常负载**下的资源需求
- `limits` 设置为**峰值负载**下的资源上限
- CPU `requests` 过低会导致频繁扩容，过高会导致扩容不及时

#### 2. 扩缩容速率控制

```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: 300  # 缩容前观察 5 分钟，避免流量波动误判
    policies:
    - type: Pods
      value: 1           # 每分钟最多缩容 1 个 Pod（保守）
      periodSeconds: 60
  scaleUp:
    stabilizationWindowSeconds: 0    # 扩容立即响应
    policies:
    - type: Percent
      value: 50          # 每 30 秒最多扩容 50%
      periodSeconds: 30
```

**生产建议：**
- **扩容快、缩容慢**：快速响应流量高峰，避免过早回收资源
- **设置稳定窗口**：缩容前观察一段时间，确保负载真正下降
- **限制缩容速度**：避免大规模缩容导致剩余 Pod 过载

#### 3. 自定义指标配置（Prometheus）

**部署 Prometheus Adapter：**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: monitoring
data:
  config.yaml: |
    rules:
    - seriesQuery: 'http_requests_total{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)_total"
        as: "${1}_per_second"
      metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[2m])) by (<<.GroupBy>>)'
```

**使用自定义指标的 HPA：**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: custom-metrics-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-service
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "500"  # 每个 Pod 处理 500 RPS
```

### 五、常见问题与排查

#### Q1：HPA 不生效，Pod 数量不变？

**排查步骤：**
```bash
# 1. 检查 HPA 状态
kubectl get hpa -n <namespace>
kubectl describe hpa <hpa-name> -n <namespace>

# 2. 查看事件日志
kubectl get events --sort-by='.lastTimestamp' | grep HPA

# 3. 检查 Metrics Server
kubectl top pods -n <namespace>
kubectl top nodes
```

**常见原因：**
- Metrics Server 未安装或异常
- Deployment 未设置 `resources.requests`
- 指标名称拼写错误
- 当前指标在容忍度范围内（10%）

#### Q2：HPA 频繁扩缩容（抖动）？

**解决方案：**
1. 增加 `stabilizationWindowSeconds`（缩容稳定窗口）
2. 调整目标指标值，增大容忍度
3. 使用多指标混合，避免单一指标误判
4. 限制 `scaleDown.policies`，减慢缩容速度

#### Q3：扩容速度不够快，业务已经过载？

**优化方案：**
1. 降低 `scaleUp.policies.periodSeconds`（缩短评估周期）
2. 提高 `scaleUp.policies.value`（增大单次扩容幅度）
3. 设置 `scaleUp.stabilizationWindowSeconds: 0`（立即扩容）
4. 配合 **Cluster Autoscaler** 自动扩展节点
5. 使用 **KEDA**（Kubernetes Event-Driven Autoscaling）实现事件驱动扩容

#### Q4：如何避免缩容到 0？

设置 `minReplicas` 为至少 1：
```yaml
spec:
  minReplicas: 1  # 保证至少有 1 个 Pod 运行
```

若需要缩容到 0，使用 **Knative** 或 **KEDA** 的 Scale-to-Zero 功能。

### 六、HPA vs VPA vs Cluster Autoscaler

| 维度 | HPA | VPA | Cluster Autoscaler |
|------|-----|-----|--------------------|
| **扩展方式** | 水平扩展（增加 Pod） | 垂直扩展（调整资源） | 节点级扩展（增加 Node） |
| **适用场景** | 无状态应用、流量波动大 | 单 Pod 应用、资源需求变化 | 节点资源不足 |
| **扩容速度** | 快（秒级） | 慢（需重启 Pod） | 最慢（分钟级） |
| **成本** | 按需增加，成本可控 | 按需调整，成本灵活 | 按需增加节点，成本较高 |
| **限制** | 需应用支持水平扩展 | 不适合频繁变化的负载 | 依赖云厂商 API |

**组合使用建议：**
- **HPA + Cluster Autoscaler**：Pod 不足时 HPA 扩容，节点不足时 CA 扩容
- **HPA + VPA**：HPA 处理短期波动，VPA 优化长期资源配置（需避免冲突）

### 七、监控与告警

**关键指标：**
```promql
# HPA 当前副本数
kube_horizontalpodautoscaler_status_current_replicas

# HPA 期望副本数
kube_horizontalpodautoscaler_status_desired_replicas

# HPA 达到最大副本数的次数
increase(kube_horizontalpodautoscaler_status_desired_replicas{current_replicas=max_replicas}[5m]) > 0

# 扩缩容事件频率
rate(kube_horizontalpodautoscaler_spec_target_metric[5m])
```

**告警规则示例：**
```yaml
- alert: HPAMaxedOut
  expr: |
    kube_horizontalpodautoscaler_status_current_replicas
    ==
    kube_horizontalpodautoscaler_spec_max_replicas
  for: 10m
  annotations:
    summary: "HPA {{ $labels.hpa }} 已达到最大副本数"
    description: "可能需要提高 maxReplicas 或优化应用性能"
```
