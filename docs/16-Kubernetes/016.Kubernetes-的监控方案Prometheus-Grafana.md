---
title: Kubernetes 的监控方案（Prometheus、Grafana）
tags:
  - Kubernetes
status: robot
class: Kubernetes
slug: kubernetes-monitoring-prometheus-grafana
ref:
---

## 核心要点

- **Prometheus**: 拉取式监控系统,通过服务发现自动采集 K8s 指标
- **核心组件**: Prometheus Server(存储+查询)、Exporters(指标暴露)、Alertmanager(告警)
- **监控层次**: 集群层(节点/API Server) → 应用层(Pod/容器) → 业务层(自定义指标)
- **Grafana**: 可视化平台,通过 PromQL 查询展示监控数据
- **生态优势**: 云原生标准、动态服务发现、多维度数据模型

---

## 详细回答

### 一、为什么选择 Prometheus + Grafana

在 Kubernetes 环境中,传统监控系统面临三大挑战:
1. **动态性**: Pod IP 频繁变化,无法静态配置监控目标
2. **规模性**: 数千个容器需要高效采集和存储
3. **云原生**: 需要理解 K8s 的 Service、Namespace 等概念

Prometheus 作为 CNCF 毕业项目,天然适配 K8s:
- **服务发现**: 自动发现 Pod、Service、Node 等资源
- **拉取模型**: 主动抓取指标,无需在每个 Pod 配置推送
- **时序数据库**: 高效存储带标签的时间序列数据
- **强大查询语言**: PromQL 支持聚合、计算、告警规则

Grafana 则提供了企业级的可视化能力,支持多数据源整合。

---

### 二、架构设计与核心组件

#### 1. Prometheus 架构

```
┌─────────────────────────────────────────────┐
│         Kubernetes Cluster                  │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  │
│  │  Pod A   │  │  Pod B   │  │  Node    │  │
│  │ :2112/   │  │ :8080/   │  │ Exporter │  │
│  │ metrics  │  │ metrics  │  │          │  │
│  └────▲─────┘  └────▲─────┘  └────▲─────┘  │
│       │             │             │         │
│       └─────────────┼─────────────┘         │
│                     │                       │
└─────────────────────┼───────────────────────┘
                      │ Pull (HTTP)
              ┌───────▼────────┐
              │   Prometheus   │
              │     Server     │
              │  ┌──────────┐  │
              │  │ TSDB     │  │ ← 本地时序数据库
              │  │ Storage  │  │
              │  └──────────┘  │
              │  ┌──────────┐  │
              │  │ Alert    │  │ → Alertmanager
              │  │ Rules    │  │
              │  └──────────┘  │
              └────────────────┘
                      │
                      │ PromQL Query
              ┌───────▼────────┐
              │    Grafana     │
              │   Dashboard    │
              └────────────────┘
```

#### 2. 核心组件详解

**① Prometheus Server**
- **Retrieval**: 通过 K8s API 实现服务发现,定期抓取目标指标
- **TSDB**: 本地存储时序数据(默认保留 15 天)
- **HTTP Server**: 提供 PromQL 查询接口和 Web UI

**② Exporters(指标导出器)**
- **Node Exporter**: 采集节点级指标(CPU、内存、磁盘、网络)
- **kube-state-metrics**: 采集 K8s 资源状态(Deployment 副本数、Pod 状态)
- **cAdvisor**: 内置于 Kubelet,采集容器资源使用情况
- **应用自定义 Exporter**: 业务指标(如 HTTP 请求数、订单量)

**③ Alertmanager**
- 接收 Prometheus 告警
- 分组、去重、抑制、静默
- 路由到不同通知渠道(邮件、Slack、钉钉、PagerDuty)

**④ Grafana**
- 连接 Prometheus 数据源
- 可视化面板(折线图、热力图、仪表盘)
- 模板变量(动态切换 Namespace、Pod)
- 告警可视化

---

### 三、部署实践(使用 Prometheus Operator)

#### 1. 快速部署

推荐使用 **kube-prometheus** 项目(包含 Prometheus Operator):

```bash
# 1. 克隆仓库
git clone https://github.com/prometheus-operator/kube-prometheus.git
cd kube-prometheus

# 2. 创建命名空间和 CRD
kubectl create -f manifests/setup

# 3. 部署完整监控栈
kubectl create -f manifests/

# 等待所有 Pod 运行
kubectl -n monitoring get pods
```

部署后会创建:
- Prometheus StatefulSet(双副本高可用)
- Grafana Deployment
- Alertmanager StatefulSet
- Node Exporter DaemonSet(每个节点一个)
- kube-state-metrics Deployment

#### 2. 核心 CRD(自定义资源)

**① ServiceMonitor**: 定义如何抓取 Service 的指标

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: my-app-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: my-app  # 选择带此标签的 Service
  endpoints:
  - port: metrics    # Service 的端口名称
    interval: 30s    # 抓取间隔
    path: /metrics   # 指标路径
```

**② PodMonitor**: 直接抓取 Pod(无需 Service)

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: redis-monitor
spec:
  selector:
    matchLabels:
      app: redis
  podMetricsEndpoints:
  - port: metrics
    interval: 15s
```

**③ PrometheusRule**: 定义告警规则

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: app-alerts
spec:
  groups:
  - name: app.rules
    interval: 30s
    rules:
    - alert: HighErrorRate
      expr: |
        rate(http_requests_total{status=~"5.."}[5m]) > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "应用错误率过高"
        description: "{{ $labels.instance }} 错误率 {{ $value }}"
```

---

### 四、监控层次与关键指标

#### 1. 集群基础设施层

**节点监控**(Node Exporter)
```promql
# CPU 使用率
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# 内存使用率
(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100

# 磁盘使用率
(node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes * 100
```

**K8s 组件监控**
- API Server 请求延迟、错误率
- etcd 磁盘写入延迟、Leader 选举
- Scheduler 调度延迟
- Controller Manager 工作队列深度

#### 2. 容器与 Pod 层

**资源使用**(cAdvisor)
```promql
# Pod CPU 使用率
sum(rate(container_cpu_usage_seconds_total{pod="my-app-xxx"}[5m])) by (pod)

# Pod 内存使用
sum(container_memory_working_set_bytes{pod="my-app-xxx"}) by (pod)

# 网络流量
rate(container_network_receive_bytes_total[5m])
```

**Pod 状态**(kube-state-metrics)
```promql
# Pending 的 Pod 数量
count(kube_pod_status_phase{phase="Pending"})

# 重启次数
sum(kube_pod_container_status_restarts_total) by (pod)

# Deployment 可用副本
kube_deployment_status_replicas_available{deployment="my-app"}
```

#### 3. 应用与业务层

**自定义指标**(需应用暴露)
```go
// Go 应用示例
import "github.com/prometheus/client_golang/prometheus"

var httpRequestsTotal = prometheus.NewCounterVec(
    prometheus.CounterOpts{
        Name: "http_requests_total",
        Help: "Total HTTP requests",
    },
    []string{"method", "status"},
)

// 在 HTTP handler 中
httpRequestsTotal.WithLabelValues("GET", "200").Inc()
```

```promql
# QPS
rate(http_requests_total[1m])

# 错误率
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])

# P95 延迟(需要 Histogram)
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

---

### 五、Grafana 可视化最佳实践

#### 1. 配置 Prometheus 数据源

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
data:
  prometheus.yaml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      url: http://prometheus-k8s.monitoring:9090
      access: proxy
      isDefault: true
```

#### 2. 推荐 Dashboard

导入社区 Dashboard(通过 ID):
- **3119**: Kubernetes Cluster Monitoring(集群概览)
- **6417**: Kubernetes Deployment Statefulset Daemonset Metrics
- **1860**: Node Exporter Full(节点详细指标)
- **7249**: Kubernetes Pod Resources

#### 3. 创建业务 Dashboard

```json
{
  "dashboard": {
    "title": "应用监控",
    "panels": [
      {
        "title": "QPS",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[1m]))"
          }
        ],
        "type": "graph"
      },
      {
        "title": "错误率",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))"
          }
        ],
        "type": "gauge",
        "thresholds": "0.01,0.05"  // 黄色、红色阈值
      }
    ]
  }
}
```

#### 4. 模板变量(动态切换)

```
变量名: namespace
类型: Query
查询: label_values(kube_pod_info, namespace)

面板查询使用:
sum(rate(http_requests_total{namespace="$namespace"}[5m]))
```

---

### 六、告警配置示例

#### 1. Prometheus 告警规则

```yaml
groups:
- name: kubernetes.rules
  interval: 30s
  rules:
  # 节点 NotReady
  - alert: NodeNotReady
    expr: kube_node_status_condition{condition="Ready",status="true"} == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "节点 {{ $labels.node }} 不可用"

  # Pod CPU 超限
  - alert: PodCPUThrottling
    expr: |
      rate(container_cpu_cfs_throttled_seconds_total[5m]) > 0.3
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Pod {{ $labels.pod }} CPU 限流严重"

  # Deployment 副本数不足
  - alert: DeploymentReplicasMismatch
    expr: |
      kube_deployment_status_replicas_available != kube_deployment_spec_replicas
    for: 15m
    labels:
      severity: warning
```

#### 2. Alertmanager 配置

```yaml
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'cluster']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
  - match:
      severity: critical
    receiver: 'pagerduty'
  - match:
      severity: warning
    receiver: 'slack'

receivers:
- name: 'default'
  webhook_configs:
  - url: 'http://alertmanager-webhook:8080/alerts'

- name: 'slack'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/xxx'
    channel: '#alerts'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

- name: 'pagerduty'
  pagerduty_configs:
  - service_key: 'xxx'
```

---

### 七、生产环境优化建议

#### 1. 高可用架构

```yaml
# Prometheus 多副本(通过 Thanos 实现)
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
spec:
  replicas: 2
  thanos:
    image: quay.io/thanos/thanos:v0.31.0
    objectStorageConfig:  # 长期存储到对象存储
      key: thanos.yaml
      name: thanos-objstore-config
```

#### 2. 数据持久化

```yaml
spec:
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 100Gi  # 根据数据量调整
```

#### 3. 资源限制

```yaml
spec:
  resources:
    requests:
      memory: 4Gi
      cpu: 2
    limits:
      memory: 8Gi
      cpu: 4
  retention: 30d          # 本地保留 30 天
  retentionSize: 90GB     # 磁盘限制
```

#### 4. 采集优化

```yaml
# 调整抓取间隔
spec:
  scrapeInterval: 30s      # 默认抓取间隔
  evaluationInterval: 30s  # 告警规则评估间隔

  # 限制采集目标
  serviceMonitorSelector:
    matchLabels:
      prometheus: main     # 只采集带此标签的 ServiceMonitor
```

---

### 八、常见问题与排查

#### 1. Target 无法被发现

```bash
# 检查 ServiceMonitor 是否被识别
kubectl -n monitoring get servicemonitor

# 查看 Prometheus 配置
kubectl -n monitoring exec -it prometheus-k8s-0 -- cat /etc/prometheus/config_out/prometheus.env.yaml

# 检查 RBAC 权限
kubectl get clusterrole prometheus-k8s -o yaml
```

#### 2. 指标采集失败

访问 Prometheus UI → Status → Targets,检查:
- **UP**: 采集正常
- **DOWN**: 网络不通或端口错误
- **UNKNOWN**: 初始化中

常见原因:
- Pod 未暴露 `/metrics` 端点
- Service 端口名不匹配
- 网络策略(NetworkPolicy)阻止

#### 3. 查询性能差

```promql
# 避免高基数标签(如 user_id)
# 错误示例
http_requests_total{user_id="12345"}

# 正确做法:使用聚合
sum(rate(http_requests_total[5m])) by (status)

# 使用 recording rules 预计算
- record: job:http_requests:rate5m
  expr: sum(rate(http_requests_total[5m])) by (job)
```

---

### 九、总结

Prometheus + Grafana 是 K8s 监控的事实标准,核心优势在于:

1. **原生集成**: 通过服务发现自动适配 K8s 动态环境
2. **灵活强大**: PromQL 支持复杂查询和聚合
3. **生态丰富**: 数千个 Exporter 覆盖各类组件
4. **可扩展性**: Thanos/Cortex 实现长期存储和联邦查询

面试建议关注:
- 理解拉取式 vs 推送式监控的优劣
- 掌握关键 PromQL 查询(rate、histogram_quantile)
- 熟悉生产环境高可用配置(多副本、持久化、告警)
- 能结合实际案例讲解监控分层和指标选择
