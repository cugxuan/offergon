---
title: Kubernetes 的 DaemonSet 和 Job
tags:
  - Kubernetes
status: robot
class: Kubernetes
slug: kubernetes-daemonset-vs-job
ref:
---

## 核心要点

- **DaemonSet**：在每个节点上运行一个 Pod 副本，适用于日志收集、监控、网络代理等节点级服务
- **Job**：执行一次性任务直到成功完成，适用于批处理、数据迁移、定时任务等场景
- **CronJob**：基于时间调度的 Job，实现定时任务功能

## 详细解答

### 一、DaemonSet 深度解析

#### 1. 什么是 DaemonSet

DaemonSet 是 Kubernetes 的工作负载控制器，确保集群中**每个节点（或指定节点子集）上运行一个 Pod 副本**。当节点加入集群时，Pod 自动创建；节点移除时，Pod 自动回收。

**典型应用场景：**
- **日志收集**：fluentd、logstash 等日志代理
- **监控系统**：node-exporter、cAdvisor 等节点监控
- **网络组件**：kube-proxy、CNI 插件（如 Calico、Flannel）
- **存储服务**：Ceph、GlusterFS 等分布式存储客户端

#### 2. DaemonSet 核心特性

**自动调度策略：**
```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      # 节点选择器：仅在特定节点运行
      nodeSelector:
        logging: enabled
      # 容忍度配置：可在 Master 节点运行
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd-elasticsearch
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
```

**更新策略：**
- **RollingUpdate（默认）**：逐个节点滚动更新，通过 `maxUnavailable` 控制更新速度
- **OnDelete**：手动删除 Pod 后才使用新模板创建

```yaml
spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # 同时更新的最大 Pod 数
```

#### 3. 节点选择与亲和性

```yaml
spec:
  template:
    spec:
      # 方式1：简单的 nodeSelector
      nodeSelector:
        disktype: ssd

      # 方式2：强大的节点亲和性
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - worker-node-1
                - worker-node-2
```

### 二、Job 与 CronJob 深度解析

#### 1. Job 的工作原理

Job 创建一个或多个 Pod，并确保指定数量的 Pod 成功完成。与 Deployment 不同，**Job 在任务完成后不会重启 Pod**。

**核心参数：**
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: data-migration
spec:
  # 完成次数：需要成功完成的 Pod 数量
  completions: 5
  # 并行度：同时运行的 Pod 数
  parallelism: 2
  # 重试次数：失败后最多重试次数
  backoffLimit: 3
  # 超时时间：Job 运行的最大时长
  activeDeadlineSeconds: 600
  template:
    spec:
      restartPolicy: OnFailure  # Job 必须设置为 Never 或 OnFailure
      containers:
      - name: migration
        image: migration-tool:v1.0
        command: ["./migrate.sh"]
```

**工作模式详解：**

| 配置 | completions | parallelism | 行为 |
|------|-------------|-------------|------|
| 单任务 | 1（默认） | 1（默认） | 运行 1 个 Pod 直到成功 |
| 固定完成次数 | N | 1 | 串行运行 N 个 Pod |
| 并行处理 | N | M | 同时运行 M 个 Pod，直到 N 个成功 |
| 工作队列 | 不设置 | M | 多个 Pod 从队列获取任务，直到队列为空 |

#### 2. 实际应用示例

**批量数据处理 Job：**
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-processor
spec:
  completions: 10      # 处理 10 批数据
  parallelism: 3       # 并行 3 个 Pod
  backoffLimit: 2      # 失败重试 2 次
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: processor
        image: data-processor:latest
        env:
        - name: BATCH_SIZE
          value: "1000"
        command: ["python", "process.py"]
```

#### 3. CronJob：定时任务调度器

CronJob 按照 Cron 表达式定时创建 Job，实现周期性任务。

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
spec:
  # Cron 表达式：每天凌晨 2 点执行
  schedule: "0 2 * * *"
  # 时区设置（需要 K8s 1.25+）
  timeZone: "Asia/Shanghai"
  # 并发策略
  concurrencyPolicy: Forbid  # Allow | Forbid | Replace
  # 保留成功的 Job 数量
  successfulJobsHistoryLimit: 3
  # 保留失败的 Job 数量
  failedJobsHistoryLimit: 1
  # 启动期限：错过调度后的有效时间
  startingDeadlineSeconds: 300
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: backup
            image: mysql-backup:v1.0
            command: ["/bin/bash", "-c"]
            args:
            - |
              mysqldump -h $DB_HOST -u $DB_USER -p$DB_PASS db_name > /backup/backup-$(date +%Y%m%d).sql
              echo "Backup completed at $(date)"
```

**并发策略说明：**
- **Allow（默认）**：允许多个 Job 同时运行
- **Forbid**：不允许并发，上一个 Job 未完成时跳过本次调度
- **Replace**：取消当前运行的 Job，启动新 Job

### 三、DaemonSet 与 Job 的核心区别

| 维度 | DaemonSet | Job |
|------|-----------|-----|
| **运行模式** | 持续运行，永不结束 | 运行到完成后退出 |
| **副本策略** | 每节点一个 Pod | 指定完成次数的 Pod |
| **调度策略** | 基于节点分布 | 基于资源可用性 |
| **更新策略** | 滚动更新 | 不支持更新（需创建新 Job） |
| **适用场景** | 系统守护进程、节点级服务 | 批处理任务、一次性操作 |
| **失败处理** | 自动重启 | 重试直到成功或达到上限 |

### 四、面试常见问题

**Q1：DaemonSet 如何保证每个节点只有一个 Pod？**

A：DaemonSet 控制器通过 **NodeName 字段直接绑定**实现。创建 Pod 时直接指定 `spec.nodeName`，绕过默认调度器，确保：
- 新节点加入时立即调度 Pod
- 节点移除时自动清理 Pod
- 不受 Pod 数量限制影响

**Q2：Job 失败后如何控制重试行为？**

A：通过三个参数控制：
- `backoffLimit`：最大失败重试次数（默认 6）
- `restartPolicy`：Pod 级别重启策略（OnFailure：容器失败重启；Never：Pod 失败重建）
- `activeDeadlineSeconds`：Job 运行的最大时长，超时后终止所有 Pod

**Q3：如何确保 CronJob 不会重复执行？**

A：
1. 设置 `concurrencyPolicy: Forbid` 禁止并发
2. 在任务内部实现**分布式锁**（Redis、etcd）
3. 任务开始前检查上次执行状态
4. 合理设置 `startingDeadlineSeconds` 避免堆积过多错过的调度

**Q4：DaemonSet 能否在 Master 节点运行？**

A：默认不可以，因为 Master 节点有 `NoSchedule` 污点。需要添加容忍度：
```yaml
tolerations:
- key: node-role.kubernetes.io/master
  effect: NoSchedule
- key: node-role.kubernetes.io/control-plane
  effect: NoSchedule
```

### 五、生产实践建议

1. **资源限制**：DaemonSet 必须设置 `resources.requests` 和 `limits`，避免节点资源耗尽
2. **健康检查**：配置 `livenessProbe` 和 `readinessProbe`，及时发现异常
3. **日志管理**：Job 完成后 Pod 不会自动删除，需定期清理或设置 TTL（`ttlSecondsAfterFinished`）
4. **监控告警**：监控 DaemonSet 的 `desiredNumberScheduled` vs `numberReady`，Job 的成功率和执行时长
5. **灰度发布**：DaemonSet 更新时使用 `maxUnavailable: 1` 逐个节点验证，避免全局故障
