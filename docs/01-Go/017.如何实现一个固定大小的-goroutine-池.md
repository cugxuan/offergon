---
title: 如何实现一个固定大小的 goroutine 池？
tags:
  - Go
  - 并发
status: robot
class: Go
ref:
---

## 要点精炼

1. **核心思想**：预先创建固定数量的 worker goroutine，通过 channel 分发任务，避免无限制创建 goroutine
2. **关键组件**：任务队列（channel）、worker 池、任务分发机制、优雅关闭
3. **优势**：控制并发数量、减少 goroutine 创建销毁开销、防止资源耗尽、提高系统稳定性
4. **应用场景**：HTTP 请求处理、数据库批量操作、文件处理、爬虫任务等高并发场景

## 详细回答

### Goroutine 池的必要性

#### 为什么需要 Goroutine 池

虽然 goroutine 很轻量（初始栈仅 2KB），但无限制创建仍有问题：

```go
// 危险！可能创建百万个 goroutine
func processRequests(requests []Request) {
    for _, req := range requests {
        go handleRequest(req)  // 可能导致 OOM
    }
}

// 改进：使用 goroutine 池限制并发数
func processRequestsWithPool(requests []Request) {
    pool := NewPool(100)  // 最多 100 个 worker
    for _, req := range requests {
        pool.Submit(func() {
            handleRequest(req)
        })
    }
}
```

优势：
1. **资源控制**：限制最大并发数
2. **性能提升**：复用 goroutine，减少创建销毁
3. **系统稳定**：避免 goroutine 爆炸导致崩溃

### 基础实现：简单 Worker Pool

```go
package pool

import (
    "sync"
)

// Task 表示一个任务
type Task func()

// Pool 是 goroutine 池
type Pool struct {
    workers   int           // worker 数量
    tasks     chan Task     // 任务队列
    wg        sync.WaitGroup
    quit      chan struct{} // 关闭信号
}

// NewPool 创建一个新的 goroutine 池
func NewPool(workerCount int) *Pool {
    pool := &Pool{
        workers: workerCount,
        tasks:   make(chan Task, workerCount*2), // 任务队列容量
        quit:    make(chan struct{}),
    }

    // 启动 workers
    for i := 0; i < workerCount; i++ {
        pool.wg.Add(1)
        go pool.worker(i)
    }

    return pool
}

// worker 是工作 goroutine
func (p *Pool) worker(id int) {
    defer p.wg.Done()

    for {
        select {
        case task := <-p.tasks:
            task()  // 执行任务
        case <-p.quit:
            return  // 接收到关闭信号，退出
        }
    }
}

// Submit 提交任务到池
func (p *Pool) Submit(task Task) {
    select {
    case p.tasks <- task:
        // 任务已提交
    case <-p.quit:
        // 池已关闭，拒绝任务
    }
}

// Close 关闭池，等待所有任务完成
func (p *Pool) Close() {
    close(p.quit)    // 发送关闭信号
    p.wg.Wait()      // 等待所有 worker 退出
    close(p.tasks)   // 关闭任务队列
}

// 使用示例
func Example() {
    pool := NewPool(10)
    defer pool.Close()

    for i := 0; i < 100; i++ {
        taskID := i
        pool.Submit(func() {
            fmt.Printf("Task %d executed\n", taskID)
        })
    }
}
```

### 增强版：支持返回结果

```go
package pool

import (
    "context"
    "errors"
    "sync"
)

// Result 表示任务结果
type Result struct {
    Value interface{}
    Err   error
}

// Job 表示带返回值的任务
type Job func() (interface{}, error)

// AdvancedPool 是增强版 goroutine 池
type AdvancedPool struct {
    workers   int
    tasks     chan Job
    results   chan Result
    wg        sync.WaitGroup
    ctx       context.Context
    cancel    context.CancelFunc
}

func NewAdvancedPool(workerCount int) *AdvancedPool {
    ctx, cancel := context.WithCancel(context.Background())

    pool := &AdvancedPool{
        workers: workerCount,
        tasks:   make(chan Job, workerCount*2),
        results: make(chan Result, workerCount*2),
        ctx:     ctx,
        cancel:  cancel,
    }

    for i := 0; i < workerCount; i++ {
        pool.wg.Add(1)
        go pool.worker()
    }

    return pool
}

func (p *AdvancedPool) worker() {
    defer p.wg.Done()

    for {
        select {
        case job := <-p.tasks:
            value, err := job()
            // 尝试发送结果
            select {
            case p.results <- Result{Value: value, Err: err}:
            case <-p.ctx.Done():
                return
            }
        case <-p.ctx.Done():
            return
        }
    }
}

// Submit 提交任务并返回结果 channel
func (p *AdvancedPool) Submit(job Job) error {
    select {
    case p.tasks <- job:
        return nil
    case <-p.ctx.Done():
        return errors.New("pool is closed")
    }
}

// Results 返回结果 channel
func (p *AdvancedPool) Results() <-chan Result {
    return p.results
}

// Close 关闭池
func (p *AdvancedPool) Close() {
    p.cancel()
    p.wg.Wait()
    close(p.tasks)
    close(p.results)
}

// 使用示例
func ExampleAdvanced() {
    pool := NewAdvancedPool(5)
    defer pool.Close()

    // 提交任务
    for i := 0; i < 20; i++ {
        taskID := i
        pool.Submit(func() (interface{}, error) {
            return taskID * 2, nil
        })
    }

    // 收集结果
    for i := 0; i < 20; i++ {
        result := <-pool.Results()
        if result.Err != nil {
            fmt.Printf("Error: %v\n", result.Err)
        } else {
            fmt.Printf("Result: %v\n", result.Value)
        }
    }
}
```

### 完整功能版：限流、超时、错误处理

```go
package pool

import (
    "context"
    "fmt"
    "sync"
    "time"
)

// Task 接口
type Task interface {
    Execute() error
}

// WorkerPool 功能完整的 goroutine 池
type WorkerPool struct {
    workers    int
    taskQueue  chan Task
    results    chan error
    wg         sync.WaitGroup
    ctx        context.Context
    cancel     context.CancelFunc
    timeout    time.Duration
    panicHandler func(interface{})
}

// Config 池配置
type Config struct {
    Workers      int
    QueueSize    int
    Timeout      time.Duration
    PanicHandler func(interface{})
}

func NewWorkerPool(cfg Config) *WorkerPool {
    if cfg.Workers <= 0 {
        cfg.Workers = 10
    }
    if cfg.QueueSize <= 0 {
        cfg.QueueSize = cfg.Workers * 2
    }

    ctx, cancel := context.WithCancel(context.Background())

    pool := &WorkerPool{
        workers:      cfg.Workers,
        taskQueue:    make(chan Task, cfg.QueueSize),
        results:      make(chan error, cfg.QueueSize),
        ctx:          ctx,
        cancel:       cancel,
        timeout:      cfg.Timeout,
        panicHandler: cfg.PanicHandler,
    }

    pool.start()
    return pool
}

func (p *WorkerPool) start() {
    for i := 0; i < p.workers; i++ {
        p.wg.Add(1)
        go p.worker(i)
    }
}

func (p *WorkerPool) worker(id int) {
    defer p.wg.Done()

    for {
        select {
        case task := <-p.taskQueue:
            p.executeTask(id, task)
        case <-p.ctx.Done():
            fmt.Printf("Worker %d shutting down\n", id)
            return
        }
    }
}

func (p *WorkerPool) executeTask(workerID int, task Task) {
    // panic 恢复
    defer func() {
        if r := recover(); r != nil {
            if p.panicHandler != nil {
                p.panicHandler(r)
            } else {
                fmt.Printf("Worker %d panic: %v\n", workerID, r)
            }
        }
    }()

    // 执行任务（带超时）
    var err error
    done := make(chan struct{})

    go func() {
        err = task.Execute()
        close(done)
    }()

    if p.timeout > 0 {
        select {
        case <-done:
            p.sendResult(err)
        case <-time.After(p.timeout):
            p.sendResult(fmt.Errorf("task timeout after %v", p.timeout))
        case <-p.ctx.Done():
            return
        }
    } else {
        select {
        case <-done:
            p.sendResult(err)
        case <-p.ctx.Done():
            return
        }
    }
}

func (p *WorkerPool) sendResult(err error) {
    select {
    case p.results <- err:
    default:
        // 结果队列满，丢弃
    }
}

// Submit 提交任务（阻塞）
func (p *WorkerPool) Submit(task Task) error {
    select {
    case p.taskQueue <- task:
        return nil
    case <-p.ctx.Done():
        return fmt.Errorf("pool is closed")
    }
}

// TrySubmit 提交任务（非阻塞）
func (p *WorkerPool) TrySubmit(task Task) bool {
    select {
    case p.taskQueue <- task:
        return true
    default:
        return false
    }
}

// SubmitWithTimeout 提交任务（带超时）
func (p *WorkerPool) SubmitWithTimeout(task Task, timeout time.Duration) error {
    select {
    case p.taskQueue <- task:
        return nil
    case <-time.After(timeout):
        return fmt.Errorf("submit timeout")
    case <-p.ctx.Done():
        return fmt.Errorf("pool is closed")
    }
}

// Results 返回结果 channel
func (p *WorkerPool) Results() <-chan error {
    return p.results
}

// Shutdown 优雅关闭
func (p *WorkerPool) Shutdown() {
    p.cancel()
    p.wg.Wait()
    close(p.taskQueue)
    close(p.results)
}

// ForceShutdown 强制关闭
func (p *WorkerPool) ForceShutdown() {
    p.cancel()
}

// 使用示例
type MyTask struct {
    ID int
}

func (t *MyTask) Execute() error {
    fmt.Printf("Executing task %d\n", t.ID)
    time.Sleep(100 * time.Millisecond)
    return nil
}

func ExampleWorkerPool() {
    pool := NewWorkerPool(Config{
        Workers:   5,
        QueueSize: 20,
        Timeout:   5 * time.Second,
        PanicHandler: func(r interface{}) {
            fmt.Printf("Panic recovered: %v\n", r)
        },
    })
    defer pool.Shutdown()

    // 提交任务
    for i := 0; i < 50; i++ {
        task := &MyTask{ID: i}
        if err := pool.Submit(task); err != nil {
            fmt.Printf("Failed to submit task %d: %v\n", i, err)
        }
    }

    // 等待所有任务完成
    time.Sleep(10 * time.Second)
}
```

### 实际应用案例

#### 案例 1：HTTP 请求批量处理

```go
type HTTPTask struct {
    URL string
}

func (t *HTTPTask) Execute() error {
    resp, err := http.Get(t.URL)
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return err
    }

    fmt.Printf("Fetched %s: %d bytes\n", t.URL, len(body))
    return nil
}

func batchFetchURLs(urls []string) {
    pool := NewWorkerPool(Config{
        Workers:   10,
        QueueSize: 100,
        Timeout:   30 * time.Second,
    })
    defer pool.Shutdown()

    for _, url := range urls {
        pool.Submit(&HTTPTask{URL: url})
    }
}
```

#### 案例 2：数据库批量操作

```go
type DBTask struct {
    DB   *sql.DB
    SQL  string
    Args []interface{}
}

func (t *DBTask) Execute() error {
    _, err := t.DB.Exec(t.SQL, t.Args...)
    return err
}

func batchInsert(db *sql.DB, records []Record) error {
    pool := NewWorkerPool(Config{
        Workers:   20,
        QueueSize: 100,
    })
    defer pool.Shutdown()

    var wg sync.WaitGroup
    errChan := make(chan error, len(records))

    for _, record := range records {
        wg.Add(1)
        task := &DBTask{
            DB:   db,
            SQL:  "INSERT INTO records (data) VALUES (?)",
            Args: []interface{}{record.Data},
        }

        go func() {
            defer wg.Done()
            if err := pool.Submit(task); err != nil {
                errChan <- err
            }
        }()
    }

    wg.Wait()
    close(errChan)

    for err := range errChan {
        if err != nil {
            return err
        }
    }

    return nil
}
```

#### 案例 3：文件批量处理

```go
type FileTask struct {
    FilePath string
    Handler  func(string) error
}

func (t *FileTask) Execute() error {
    return t.Handler(t.FilePath)
}

func processFiles(dir string) error {
    pool := NewWorkerPool(Config{
        Workers:   5,
        QueueSize: 50,
    })
    defer pool.Shutdown()

    files, err := filepath.Glob(filepath.Join(dir, "*.txt"))
    if err != nil {
        return err
    }

    for _, file := range files {
        task := &FileTask{
            FilePath: file,
            Handler: func(path string) error {
                data, err := os.ReadFile(path)
                if err != nil {
                    return err
                }
                // 处理文件内容
                fmt.Printf("Processed %s: %d bytes\n", path, len(data))
                return nil
            },
        }
        pool.Submit(task)
    }

    return nil
}
```

### 第三方库推荐

#### 1. ants（推荐）

```go
import "github.com/panjf2000/ants/v2"

func useAnts() {
    defer ants.Release()

    // 创建池
    pool, _ := ants.NewPool(10)
    defer pool.Release()

    // 提交任务
    for i := 0; i < 100; i++ {
        taskID := i
        pool.Submit(func() {
            fmt.Printf("Task %d\n", taskID)
        })
    }
}
```

#### 2. tunny

```go
import "github.com/Jeffail/tunny"

func useTunny() {
    pool := tunny.NewFunc(10, func(payload interface{}) interface{} {
        // 处理任务
        return nil
    })
    defer pool.Close()

    result := pool.Process("task data")
    fmt.Println(result)
}
```

### 性能优化技巧

```go
// 1. 合理设置 worker 数量
// CPU 密集型：workers = CPU 核心数
// I/O 密集型：workers = CPU 核心数 * 2~4

// 2. 动态调整池大小（高级）
type DynamicPool struct {
    minWorkers int
    maxWorkers int
    // 根据任务队列长度动态调整
}

// 3. 任务优先级队列
type PriorityTask struct {
    Priority int
    Task     Task
}

// 使用 heap 实现优先级队列

// 4. 批量提交减少锁竞争
func (p *Pool) SubmitBatch(tasks []Task) {
    for _, task := range tasks {
        p.taskQueue <- task
    }
}
```

### 测试与基准

```go
func BenchmarkPool(b *testing.B) {
    pool := NewWorkerPool(Config{
        Workers:   10,
        QueueSize: 100,
    })
    defer pool.Shutdown()

    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            pool.Submit(&MyTask{ID: 1})
        }
    })
}
```

### 总结

实现 Goroutine 池的关键点：

1. **核心组件**：
   - Worker goroutine 池
   - 任务队列（buffered channel）
   - 优雅关闭机制

2. **高级特性**：
   - 返回结果收集
   - 超时控制
   - Panic 恢复
   - 动态扩缩容

3. **最佳实践**：
   - 合理设置 worker 数量
   - 使用 context 控制生命周期
   - 提供非阻塞提交选项
   - 监控池的运行状态

4. **使用场景**：
   - 高并发 API 请求
   - 批量数据处理
   - 文件 I/O 操作
   - 爬虫任务调度

面试要点：
- 理解为什么需要 goroutine 池
- 掌握基础实现的核心逻辑
- 了解优雅关闭的重要性
- 能根据场景选择合适的配置
- 知道常见的第三方库
