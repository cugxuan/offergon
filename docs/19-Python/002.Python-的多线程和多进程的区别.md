---
title: Python 的多线程和多进程的区别
tags:
  - Python
status: robot
class: Python
slug: multithreading-vs-multiprocessing-python
ref:
---

## 核心要点

**内存隔离**:线程共享进程内存空间,进程完全隔离
**GIL影响**:多线程受GIL限制(CPU密集),多进程绕过GIL
**开销对比**:线程创建快/切换快,进程重量级/通信慢
**使用场景**:I/O密集用线程,CPU密集用进程

---

## 详细解答

### 一、本质区别

| 维度 | 多线程 (Threading) | 多进程 (Multiprocessing) |
|------|-------------------|-------------------------|
| **内存** | 共享进程的内存空间 | 每个进程独立内存空间 |
| **通信** | 直接访问共享变量(需加锁) | 需IPC机制(管道、队列、共享内存) |
| **GIL** | 受GIL限制,同一时刻仅一个线程执行 | 每个进程独立GIL,真正并行 |
| **创建开销** | 轻量级(几KB栈空间) | 重量级(复制整个进程) |
| **切换开销** | 快(纳秒级,同一进程内) | 慢(微秒级,涉及内核调度) |
| **稳定性** | 一个线程崩溃会导致整个进程崩溃 | 进程间隔离,一个崩溃不影响其他 |
| **调试难度** | 高(竞态条件、死锁) | 相对低(独立地址空间) |

### 二、GIL的关键影响

#### 多线程受GIL限制

```python
import threading
import time

def cpu_intensive():
    """CPU密集:计算1亿次累加"""
    total = 0
    for i in range(10**8):
        total += i
    return total

# 单线程基准测试
start = time.time()
cpu_intensive()
print(f"单线程耗时: {time.time()-start:.2f}s")  # 约5秒

# 多线程测试(4线程)
threads = [threading.Thread(target=cpu_intensive) for _ in range(4)]
start = time.time()
for t in threads: t.start()
for t in threads: t.join()
print(f"多线程耗时: {time.time()-start:.2f}s")  # 仍约20秒,甚至更慢!
```

**原因**:GIL导致4个线程串行执行,且引入线程切换开销

#### 多进程绕过GIL

```python
from multiprocessing import Process, Pool
import time

def cpu_intensive():
    total = 0
    for i in range(10**8):
        total += i
    return total

# 多进程测试(4进程)
if __name__ == '__main__':
    start = time.time()
    with Pool(4) as p:
        results = p.map(cpu_intensive, range(4))
    print(f"多进程耗时: {time.time()-start:.2f}s")  # 约5秒(4核并行)
```

**原因**:每个进程有独立的Python解释器和GIL,实现真正并行

### 三、典型使用场景

#### 场景1:I/O密集型任务 → 优先多线程

```python
import threading
import requests

urls = ['http://example.com'] * 100

# 多线程爬虫(I/O等待时自动释放GIL)
def fetch(url):
    response = requests.get(url)
    return len(response.content)

threads = [threading.Thread(target=fetch, args=(url,)) for url in urls]
for t in threads: t.start()
for t in threads: t.join()
```

**为什么用线程?**
- 网络I/O会自动释放GIL,允许其他线程运行
- 线程创建/销毁开销小,适合大量并发连接
- 共享内存便于管理结果数据

#### 场景2:CPU密集型任务 → 必须多进程

```python
from multiprocessing import Pool
import numpy as np

# 图像处理任务
def process_image(image_path):
    img = np.load(image_path)
    # 复杂的矩阵运算
    result = np.fft.fft2(img)
    return result

image_paths = ['img1.npy', 'img2.npy', 'img3.npy', 'img4.npy']

# 多进程处理
with Pool(4) as p:
    results = p.map(process_image, image_paths)
```

**为什么用进程?**
- 绕过GIL限制,充分利用多核CPU
- 即使NumPy等库内部释放GIL,复杂业务逻辑仍需多进程

#### 场景3:混合型任务 → 进程+线程

```python
from multiprocessing import Pool
import threading
import requests

def worker_process(task_batch):
    """每个进程处理一批任务"""
    threads = []
    for task in task_batch:
        # 进程内用多线程处理I/O
        t = threading.Thread(target=fetch_and_compute, args=(task,))
        threads.append(t)
        t.start()
    for t in threads:
        t.join()

def fetch_and_compute(url):
    data = requests.get(url).json()  # I/O密集
    result = heavy_compute(data)      # CPU密集
    return result

# 4进程,每进程10线程
batches = [urls[i:i+10] for i in range(0, len(urls), 10)]
with Pool(4) as p:
    p.map(worker_process, batches)
```

### 四、进程间通信(IPC)机制

#### 1. Queue(队列) - 最常用

```python
from multiprocessing import Process, Queue

def producer(q):
    for i in range(5):
        q.put(f"data-{i}")
    q.put(None)  # 结束信号

def consumer(q):
    while True:
        item = q.get()
        if item is None:
            break
        print(f"处理: {item}")

q = Queue()
p1 = Process(target=producer, args=(q,))
p2 = Process(target=consumer, args=(q,))
p1.start(); p2.start()
p1.join(); p2.join()
```

#### 2. Pipe(管道) - 双向通信

```python
from multiprocessing import Process, Pipe

def worker(conn):
    conn.send("Hello from child")
    msg = conn.recv()
    print(f"Child received: {msg}")
    conn.close()

parent_conn, child_conn = Pipe()
p = Process(target=worker, args=(child_conn,))
p.start()
print(f"Parent received: {parent_conn.recv()}")
parent_conn.send("Hello from parent")
p.join()
```

#### 3. Manager(共享对象) - 支持复杂数据结构

```python
from multiprocessing import Process, Manager

def worker(shared_dict, lock):
    with lock:
        shared_dict['count'] += 1

manager = Manager()
shared_dict = manager.dict({'count': 0})
lock = manager.Lock()

processes = [Process(target=worker, args=(shared_dict, lock)) for _ in range(10)]
for p in processes: p.start()
for p in processes: p.join()

print(shared_dict['count'])  # 输出10
```

### 五、线程/进程安全问题

#### 线程安全 - 需要锁

```python
import threading

# 不安全的计数器
counter = 0

def increment():
    global counter
    for _ in range(100000):
        counter += 1  # 非原子操作,会出现竞态条件

threads = [threading.Thread(target=increment) for _ in range(10)]
for t in threads: t.start()
for t in threads: t.join()
print(counter)  # 结果小于1000000!

# 安全的计数器
counter = 0
lock = threading.Lock()

def safe_increment():
    global counter
    for _ in range(100000):
        with lock:
            counter += 1

threads = [threading.Thread(target=safe_increment) for _ in range(10)]
for t in threads: t.start()
for t in threads: t.join()
print(counter)  # 正确输出1000000
```

#### 进程安全 - 天然隔离

```python
from multiprocessing import Process, Value

# 共享内存需要显式声明
counter = Value('i', 0)  # 'i'表示int类型

def increment(shared_counter):
    for _ in range(100000):
        with shared_counter.get_lock():
            shared_counter.value += 1

processes = [Process(target=increment, args=(counter,)) for _ in range(10)]
for p in processes: p.start()
for p in processes: p.join()
print(counter.value)  # 正确输出1000000
```

### 六、性能对比实测

```python
import time
import threading
from multiprocessing import Pool

def benchmark(func, *args):
    start = time.time()
    func(*args)
    return time.time() - start

# CPU密集任务
def cpu_task():
    return sum(i*i for i in range(10**7))

# I/O密集任务
def io_task():
    time.sleep(0.1)

# 测试CPU密集
print("=== CPU密集任务 ===")
print(f"单线程: {benchmark(lambda: [cpu_task() for _ in range(4)]):.2f}s")

threads = [threading.Thread(target=cpu_task) for _ in range(4)]
print(f"多线程: {benchmark(lambda: [t.start() or t for t in threads] and [t.join() for t in threads]):.2f}s")

with Pool(4) as p:
    print(f"多进程: {benchmark(lambda: p.map(lambda x: cpu_task(), range(4))):.2f}s")

# 测试I/O密集
print("\n=== I/O密集任务 ===")
print(f"串行: {benchmark(lambda: [io_task() for _ in range(40)]):.2f}s")

threads = [threading.Thread(target=io_task) for _ in range(40)]
print(f"多线程: {benchmark(lambda: [t.start() or t for t in threads] and [t.join() for t in threads]):.2f}s")
```

**典型结果**:
```
=== CPU密集任务 ===
单线程: 5.2s
多线程: 5.8s  (甚至更慢,因为GIL+切换开销)
多进程: 1.4s  (4核并行,接近线性加速)

=== I/O密集任务 ===
串行: 4.0s
多线程: 0.1s  (40倍加速)
```

### 七、最佳实践建议

#### 选择决策树

```
是否CPU密集?
├─ 是 → 使用multiprocessing
│   ├─ 任务数量多? → Pool.map()
│   └─ 需要共享状态? → Manager + Lock
│
└─ 否(I/O密集)
    ├─ 需要高并发(>1000)? → asyncio
    ├─ 需要简单? → threading.Thread
    └─ 需要灵活调度? → concurrent.futures.ThreadPoolExecutor
```

#### 常见陷阱

1. **多进程序列化开销**:传递大对象会很慢,考虑共享内存
2. **进程池的if __name__ == '__main__'**:Windows下必须加,否则无限递归
3. **线程不会真正"并行"计算**:CPU密集任务别用线程
4. **daemon线程**:主进程退出会强制杀死daemon线程,注意资源清理

### 八、面试官可能的追问

**Q1: 为什么不直接用多进程替代多线程?**
A: 进程开销大(启动慢、内存占用高),通信复杂(需序列化),不适合需要频繁创建/销毁或大量共享状态的场景。

**Q2: Python 3.13的无GIL模式解决了什么?**
A: 允许多线程真正并行执行Python代码,但需要C扩展适配,且单线程性能可能下降10%-20%。

**Q3: 协程(asyncio)和多线程的区别?**
A: 协程是单线程内的协作式调度,通过`await`显式让出控制权;多线程是操作系统抢占式调度,由内核决定切换时机。
