---
title: 零拷贝技术（sendfile、mmap）
tags:
  - 操作系统
  - 数据结构
status: robot
class: 操作系统
slug: zero-copy-sendfile-mmap
ref:
---

## 核心要点

**零拷贝 (Zero-Copy) 是一种减少数据拷贝次数、提升 IO 性能的技术:**
- **传统 IO**: 数据需要在内核态和用户态之间拷贝 4 次、发生 4 次上下文切换
- **mmap**: 内存映射,将文件映射到用户空间,减少一次拷贝 (3 次拷贝)
- **sendfile**: 直接在内核空间传输数据,完全避免用户态拷贝 (2-3 次拷贝)
- **splice/tee**: 基于管道的零拷贝,适合流式数据传输

**典型应用**: Kafka、Nginx、静态文件服务器 (文件下载、视频流)

---

## 详细回答

### 一、为什么需要零拷贝?

#### 传统文件传输流程 (read + write)

**场景**: 从磁盘读取文件并发送到网络 (如 Web 服务器发送静态文件)

```c
int fd = open("file.txt", O_RDONLY);
char buf[4096];
read(fd, buf, sizeof(buf));      // 读取文件到用户缓冲区
write(sockfd, buf, sizeof(buf)); // 发送到 socket
```

**底层发生了什么?**

```
磁盘 → 内核缓冲区 → 用户缓冲区 → Socket 缓冲区 → 网卡

详细步骤:
1. DMA 拷贝: 磁盘 → 内核页缓存 (Page Cache)
2. CPU 拷贝: 内核缓存 → 用户空间 buf (read 系统调用)
3. CPU 拷贝: 用户空间 buf → Socket 缓冲区 (write 系统调用)
4. DMA 拷贝: Socket 缓冲区 → 网卡

总计: 4 次拷贝 (2 次 DMA + 2 次 CPU)
      4 次上下文切换 (用户态 ↔ 内核态)
```

**问题:**
- 数据从内核拷贝到用户空间,又从用户空间拷贝回内核,**完全多余**
- CPU 浪费在数据搬运上,无法处理其他任务
- 频繁的上下文切换开销大

---

### 二、零拷贝技术 1: mmap (内存映射)

#### 原理

将文件直接映射到用户进程的虚拟地址空间,读写内存即读写文件。

```c
int fd = open("file.txt", O_RDONLY);
void *addr = mmap(NULL, size, PROT_READ, MAP_PRIVATE, fd, 0);
write(sockfd, addr, size);  // 直接从映射区域发送
munmap(addr, size);
```

#### 数据流

```
磁盘 → 内核页缓存 (mmap 映射到用户空间) → Socket 缓冲区 → 网卡

详细步骤:
1. DMA 拷贝: 磁盘 → 内核页缓存
2. [无 CPU 拷贝!] 用户空间和内核共享页缓存
3. CPU 拷贝: 内核页缓存 → Socket 缓冲区
4. DMA 拷贝: Socket 缓冲区 → 网卡

总计: 3 次拷贝 (2 次 DMA + 1 次 CPU)
      4 次上下文切换
```

#### 优势与劣势

**优势:**
- 减少一次 CPU 拷贝 (不需要拷贝到用户缓冲区)
- 多个进程可以共享同一文件的映射 (节省内存)
- 适合大文件随机读写 (如数据库索引)

**劣势:**
- **仍有 1 次 CPU 拷贝** (内核页缓存 → Socket 缓冲区)
- **仍有 4 次上下文切换** (mmap/write 系统调用)
- 映射/解除映射有开销,小文件可能不划算
- 如果映射文件被其他进程修改,可能触发 SIGBUS 信号

#### 实际应用

```c
// RocksDB 使用 mmap 读取 SST 文件
void *data = mmap(NULL, file_size, PROT_READ, MAP_SHARED, fd, 0);
// 直接访问数据,如同访问内存
memcpy(buf, data + offset, len);
```

---

### 三、零拷贝技术 2: sendfile (最常用)

#### 原理

**直接在内核空间传输数据,完全不经过用户空间。**

```c
#include <sys/sendfile.h>

int fd = open("file.txt", O_RDONLY);
sendfile(sockfd, fd, NULL, size);  // 一个系统调用搞定!
```

#### 数据流 (经典 sendfile)

```
磁盘 → 内核页缓存 → Socket 缓冲区 → 网卡

详细步骤:
1. DMA 拷贝: 磁盘 → 内核页缓存
2. CPU 拷贝: 内核页缓存 → Socket 缓冲区
3. DMA 拷贝: Socket 缓冲区 → 网卡

总计: 3 次拷贝 (2 次 DMA + 1 次 CPU)
      2 次上下文切换 (只有 sendfile 一个系统调用)
```

#### 数据流 (DMA Scatter-Gather 优化版)

**如果网卡支持 SG-DMA (Scatter-Gather DMA):**

```
磁盘 → 内核页缓存 → [文件描述符 + 偏移量] → 网卡

详细步骤:
1. DMA 拷贝: 磁盘 → 内核页缓存
2. [无 CPU 拷贝!] 将页缓存地址和长度信息传给 Socket 缓冲区
3. DMA 拷贝: 直接从内核页缓存 → 网卡 (SG-DMA)

总计: 2 次拷贝 (全部 DMA,0 次 CPU 拷贝!)
      2 次上下文切换
```

**真正的零拷贝!** (从 CPU 角度来看)

#### 优势与劣势

**优势:**
- **性能最高**: 只有 2 次上下文切换,CPU 拷贝最少
- **简单**: 一个系统调用替代 read+write
- **适合大文件顺序传输**: 静态文件服务、视频流

**劣势:**
- **只支持文件描述符 → Socket**: 不能用于普通文件间拷贝
- **不能修改数据**: 数据直接传输,无法在用户空间处理 (如压缩、加密)
- **Linux 特定**: 跨平台需要 fallback

#### 实际应用

```c
// Nginx 发送静态文件
off_t offset = 0;
size_t size = file_size;
sendfile(client_fd, file_fd, &offset, size);
```

```java
// Kafka 使用 Java NIO 的 FileChannel.transferTo (底层是 sendfile)
FileChannel fileChannel = new FileInputStream(file).getChannel();
fileChannel.transferTo(0, file.length(), socketChannel);
```

---

### 四、零拷贝技术 3: splice (管道零拷贝)

#### 原理

在两个文件描述符之间移动数据,至少有一个必须是管道。

```c
int pipefd[2];
pipe(pipefd);

// 文件 → 管道
splice(file_fd, NULL, pipefd[1], NULL, size, SPLICE_F_MOVE);

// 管道 → Socket
splice(pipefd[0], NULL, socket_fd, NULL, size, SPLICE_F_MOVE);
```

#### 数据流

```
文件 → 内核页缓存 → 管道缓冲区 → Socket 缓冲区 → 网卡

关键: 管道缓冲区和页缓存之间不拷贝数据,只移动指针!
```

#### 应用场景

- **代理服务器**: 转发数据 (如 HAProxy)
- **流式处理**: stdin → stdout
- **tee 命令**: 复制数据流到多个目标

```c
// tee: 同时写入文件和 stdout
tee(pipe_in, pipe_out, len, SPLICE_F_NONBLOCK);
```

---

### 五、四种方式对比

| 方式 | CPU 拷贝 | DMA 拷贝 | 上下文切换 | 适用场景 |
|------|----------|----------|------------|----------|
| **read + write** | 2 次 | 2 次 | 4 次 | 需要在用户空间处理数据 |
| **mmap + write** | 1 次 | 2 次 | 4 次 | 大文件随机读写 |
| **sendfile** | 1 次 | 2 次 | 2 次 | 文件 → 网络,不需要修改数据 |
| **sendfile (SG-DMA)** | 0 次 | 2 次 | 2 次 | 文件 → 网络 (硬件支持) |
| **splice** | 0 次 | 2 次 | 2 次 | 管道相关操作 |

---

### 六、实战案例:Kafka 的零拷贝

#### Kafka 如何高效传输消息?

```
消费者请求 → Kafka 从磁盘读取日志 → 发送给消费者

传统方式 (4 次拷贝):
磁盘 → 内核 → 用户空间 (Kafka 进程) → Socket → 网卡

Kafka 优化 (sendfile,2 次拷贝):
磁盘 → 内核页缓存 → 网卡 (SG-DMA)
```

**核心代码:**
```java
// Kafka 使用 FileChannel.transferTo (底层 sendfile)
public long writeTo(GatheringByteChannel channel, long position, int length) {
    return fileChannel.transferTo(position, length, channel);
}
```

**性能提升:**
- 吞吐量提升 **2-3 倍**
- CPU 使用率降低 **50%+**

---

### 七、Nginx 的零拷贝配置

```nginx
http {
    # 开启 sendfile
    sendfile on;

    # 开启 TCP_NOPUSH (sendfile 时一次发送所有头部)
    tcp_nopush on;

    # 大文件优化
    sendfile_max_chunk 1m;
}
```

**底层实现:**
```c
// Nginx 源码简化
if (sendfile(c->fd, r->file->fd, &offset, size) == -1) {
    // fallback to read + write
}
```

---

### 八、常见误区

#### 误区 1: "零拷贝"就是没有拷贝

**错误!** 零拷贝是指**减少不必要的 CPU 拷贝**,DMA 拷贝不可避免 (磁盘和网卡总要传输数据)。

**更准确的名字**: "零 CPU 拷贝" (Zero CPU Copy)

#### 误区 2: 零拷贝总是更快

**不一定!**
- **小文件**: 系统调用开销可能超过拷贝开销,传统 read+write 更快
- **需要修改数据**: 如压缩、加密,必须在用户空间处理,无法用 sendfile
- **硬件不支持**: 没有 SG-DMA 的网卡,sendfile 性能提升有限

#### 误区 3: mmap 总比 read 快

**不一定!**
- **小文件**: mmap 的映射开销 > read 的拷贝开销
- **顺序读取**: read 有预读优化,mmap 可能触发缺页中断
- **内存压力**: mmap 占用虚拟内存,可能导致其他进程被换出

---

### 九、选择建议

| 场景 | 推荐方案 | 理由 |
|------|----------|------|
| **静态文件服务 (Nginx)** | sendfile | 文件 → 网络,不需要修改数据 |
| **消息队列 (Kafka)** | sendfile | 顺序读取日志,直接发送 |
| **数据库索引 (RocksDB)** | mmap | 随机读写,多进程共享 |
| **代理服务器 (HAProxy)** | splice | Socket → Socket 转发 |
| **需要处理数据 (压缩)** | read + write | 必须在用户空间修改数据 |
| **小文件 (< 64KB)** | read + write | 系统调用开销占主导 |

---

### 十、实现示例:对比三种方式

#### 方式 1: 传统 read + write
```c
char buf[8192];
while ((n = read(file_fd, buf, sizeof(buf))) > 0) {
    write(socket_fd, buf, n);
}
// 4 次拷贝、多次系统调用
```

#### 方式 2: mmap + write
```c
struct stat st;
fstat(file_fd, &st);
void *addr = mmap(NULL, st.st_size, PROT_READ, MAP_PRIVATE, file_fd, 0);
write(socket_fd, addr, st.st_size);
munmap(addr, st.st_size);
// 3 次拷贝、3 次系统调用
```

#### 方式 3: sendfile (最优)
```c
struct stat st;
fstat(file_fd, &st);
sendfile(socket_fd, file_fd, NULL, st.st_size);
// 2-3 次拷贝、1 次系统调用
```

---

### 十一、内核优化:页缓存的作用

**为什么第一次拷贝到页缓存?**
- **缓存热数据**: 再次读取无需访问磁盘
- **预读优化**: 顺序读取时,内核预读后续数据
- **延迟写入**: 写操作先写页缓存,批量刷盘

**sendfile 利用页缓存:**
```
第一次请求: 磁盘 → 页缓存 → 网卡 (较慢)
后续请求: 页缓存 → 网卡 (极快!)
```

---

### 十二、总结

**核心思想**: 数据在哪里处理,就在哪里传输,避免无意义的搬运。

**技术选择:**
1. **默认方案**: sendfile (静态文件、日志传输)
2. **随机访问**: mmap (数据库、大文件索引)
3. **流式转发**: splice (代理、管道)
4. **需要处理数据**: read + write (无法避免)

**性能提升:**
- **吞吐量**: 提升 2-4 倍
- **CPU 使用**: 降低 50%+
- **延迟**: 降低 20-30%

**面试加分项:**
- 能画出传统 IO 的 4 次拷贝流程
- 理解 sendfile 的 SG-DMA 优化 (真正的零 CPU 拷贝)
- 知道 Kafka 和 Nginx 使用 sendfile 提升性能
- 能解释为什么小文件不适合零拷贝
