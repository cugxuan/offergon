---
title: 设计一个分布式追踪系统(类似 Jaeger)
tags:
  - 分布式
  - 复杂系统设计
status: robot
class: 复杂系统设计
slug: design-distributed-tracing-system
ref:
---

## 核心要点

**关键功能**: 全链路追踪 + 性能分析 + 依赖分析 + 根因定位

**技术难点**: 海量数据采集、低侵入性、高性能存储、实时分析、采样策略

**核心价值**: 微服务可观测性、性能瓶颈识别、故障快速定位、服务依赖可视化

---

## 详细回答

### 一、系统整体架构

分布式追踪系统通过在分布式系统中注入追踪标识,记录请求在各个服务间的调用路径和耗时,实现全链路可观测性。

```
┌───────────────────────────────────────────────────────────┐
│                    用户应用层                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐               │
│  │ Service A│  │ Service B│  │ Service C│ ...           │
│  │ (SDK)    │  │ (SDK)    │  │ (SDK)    │               │
│  └─────┬────┘  └─────┬────┘  └─────┬────┘               │
└────────┼─────────────┼─────────────┼─────────────────────┘
         │             │             │
         │ Span Data   │ Span Data   │ Span Data
         │             │             │
         └─────────────┼─────────────┘
                       │
         ┌─────────────▼────────────────┐
         │     数据采集层 (Collector)    │
         │  ┌────────┐  ┌────────┐     │
         │  │gRPC    │  │HTTP    │     │
         │  │Receiver│  │Receiver│     │
         │  └────┬───┘  └───┬────┘     │
         │       │          │          │
         │  ┌────▼──────────▼────┐     │
         │  │  Processor Pipeline │     │
         │  │ ·Batch·Sample·Enrich│     │
         │  └────────┬────────────┘     │
         └───────────┼──────────────────┘
                     │
         ┌───────────▼──────────────────┐
         │      存储层 (Storage)         │
         │  ┌──────────┐  ┌──────────┐ │
         │  │Cassandra │  │ElasticSearch│ │
         │  │(Span数据)│  │(索引/查询)│ │
         │  └──────────┘  └──────────┘ │
         │  ┌──────────┐                │
         │  │ Redis    │ (缓存)         │
         │  └──────────┘                │
         └───────────┬──────────────────┘
                     │
         ┌───────────▼──────────────────┐
         │       查询与分析层             │
         │  ┌──────────┐  ┌──────────┐ │
         │  │Query API │  │Analytics │ │
         │  └──────────┘  └──────────┘ │
         └───────────┬──────────────────┘
                     │
         ┌───────────▼──────────────────┐
         │         展示层 (UI)           │
         │  ·链路图  ·火焰图  ·依赖图   │
         └──────────────────────────────┘
```

### 二、核心数据模型

#### 1. Trace与Span

**OpenTelemetry标准数据模型**

```go
// Trace:一次完整的请求调用链路
type Trace struct {
    TraceID  TraceID      // 全局唯一追踪ID
    Spans    []*Span      // 包含的所有Span
    Duration time.Duration // 总耗时
}

// TraceID: 128位唯一标识
type TraceID [16]byte

// Span:单个服务内的一次操作
type Span struct {
    TraceID     TraceID            // 所属Trace
    SpanID      SpanID             // Span唯一ID
    ParentSpanID *SpanID           // 父Span ID(根Span为nil)
    OperationName string           // 操作名: "HTTP GET /api/users"
    ServiceName   string           // 服务名: "user-service"
    StartTime     time.Time        // 开始时间
    Duration      time.Duration    // 耗时
    Tags          map[string]string // 标签: http.method, db.type等
    Logs          []Log            // 日志事件
    SpanKind      SpanKind         // Span类型
    Status        Status           // 状态
    References    []Reference      // 关联关系
}

type SpanID [8]byte

type SpanKind int

const (
    SpanKindInternal SpanKind = iota  // 内部调用
    SpanKindServer                     // 服务端处理
    SpanKindClient                     // 客户端调用
    SpanKindProducer                   // 消息生产者
    SpanKindConsumer                   // 消息消费者
)

type Status struct {
    Code    StatusCode  // OK/Error
    Message string
}

type Log struct {
    Timestamp time.Time
    Fields    map[string]interface{}
}

type Reference struct {
    Type        ReferenceType  // ChildOf/FollowsFrom
    TraceID     TraceID
    SpanID      SpanID
}

// 标准标签
const (
    TagHTTPMethod     = "http.method"
    TagHTTPURL        = "http.url"
    TagHTTPStatusCode = "http.status_code"
    TagDBType         = "db.type"
    TagDBStatement    = "db.statement"
    TagError          = "error"
    TagErrorMessage   = "error.message"
)
```

#### 2. 上下文传播

**W3C Trace Context标准**

```go
// HTTP Header传播
const (
    TraceParentHeader = "traceparent"  // 00-{trace-id}-{span-id}-{flags}
    TraceStateHeader  = "tracestate"   // 厂商特定数据
)

// TraceContext: W3C标准格式
type TraceContext struct {
    Version    byte      // 版本号: 00
    TraceID    TraceID   // 128位Trace ID
    ParentSpanID SpanID  // 64位Parent Span ID
    TraceFlags byte      // 标志位: 采样标志等
}

// 序列化为HTTP Header
func (tc *TraceContext) ToHeader() string {
    return fmt.Sprintf("%02x-%032x-%016x-%02x",
        tc.Version,
        tc.TraceID,
        tc.ParentSpanID,
        tc.TraceFlags,
    )
}

// 示例: "00-0af7651916cd43dd8448eb211c80319c-b7ad6b7169203331-01"

// 从HTTP Header解析
func ParseTraceContext(header string) (*TraceContext, error) {
    parts := strings.Split(header, "-")
    if len(parts) != 4 {
        return nil, fmt.Errorf("invalid format")
    }

    // 解析各部分...
    return &TraceContext{}, nil
}
```

### 三、核心组件实现

#### 1. SDK与数据采集

**Go SDK实现**

```go
// Tracer: SDK入口
type Tracer struct {
    serviceName string
    exporter    SpanExporter      // 数据导出器
    sampler     Sampler           // 采样器
    propagator  Propagator        // 上下文传播器
    idGenerator IDGenerator       // ID生成器
}

// 开始一个新Span
func (t *Tracer) StartSpan(ctx context.Context, operationName string, opts ...SpanOption) (context.Context, *Span) {
    // 1. 从context中提取父Span
    parentSpan := SpanFromContext(ctx)

    var traceID TraceID
    var parentSpanID *SpanID

    if parentSpan != nil {
        traceID = parentSpan.TraceID
        parentSpanID = &parentSpan.SpanID
    } else {
        // 根Span,生成新的TraceID
        traceID = t.idGenerator.NewTraceID()
    }

    // 2. 创建新Span
    span := &Span{
        TraceID:       traceID,
        SpanID:        t.idGenerator.NewSpanID(),
        ParentSpanID:  parentSpanID,
        OperationName: operationName,
        ServiceName:   t.serviceName,
        StartTime:     time.Now(),
        Tags:          make(map[string]string),
        Logs:          []Log{},
    }

    // 3. 应用配置选项
    for _, opt := range opts {
        opt(span)
    }

    // 4. 采样决策
    if !t.sampler.ShouldSample(span) {
        span.Sampled = false
    }

    // 5. 将Span存入context
    ctx = context.WithValue(ctx, spanContextKey, span)

    return ctx, span
}

// 结束Span
func (t *Tracer) FinishSpan(span *Span) {
    span.Duration = time.Since(span.StartTime)

    // 只导出被采样的Span
    if span.Sampled {
        t.exporter.Export(span)
    }
}

// HTTP中间件自动追踪
func TracingMiddleware(tracer *Tracer) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            // 1. 从请求头提取TraceContext
            traceCtx, err := tracer.propagator.Extract(r.Header)
            if err != nil {
                // 无上游追踪,创建新Trace
                traceCtx = nil
            }

            // 2. 创建Span
            ctx := r.Context()
            if traceCtx != nil {
                ctx = context.WithValue(ctx, traceContextKey, traceCtx)
            }

            ctx, span := tracer.StartSpan(ctx, fmt.Sprintf("%s %s", r.Method, r.URL.Path),
                WithSpanKind(SpanKindServer),
                WithTag(TagHTTPMethod, r.Method),
                WithTag(TagHTTPURL, r.URL.String()),
            )
            defer tracer.FinishSpan(span)

            // 3. 包装ResponseWriter记录状态码
            wrappedWriter := &statusRecorder{ResponseWriter: w, statusCode: 200}

            // 4. 执行下游handler
            next.ServeHTTP(wrappedWriter, r.WithContext(ctx))

            // 5. 记录响应状态
            span.SetTag(TagHTTPStatusCode, strconv.Itoa(wrappedWriter.statusCode))
            if wrappedWriter.statusCode >= 400 {
                span.SetTag(TagError, "true")
                span.Status = Status{Code: StatusCodeError}
            }
        })
    }
}

// gRPC拦截器自动追踪
func UnaryClientInterceptor(tracer *Tracer) grpc.UnaryClientInterceptor {
    return func(ctx context.Context, method string, req, reply interface{},
        cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error {

        // 1. 创建客户端Span
        ctx, span := tracer.StartSpan(ctx, method,
            WithSpanKind(SpanKindClient),
            WithTag("rpc.system", "grpc"),
            WithTag("rpc.service", cc.Target()),
        )
        defer tracer.FinishSpan(span)

        // 2. 注入TraceContext到metadata
        md, ok := metadata.FromOutgoingContext(ctx)
        if !ok {
            md = metadata.New(nil)
        }
        tracer.propagator.Inject(span, &md)
        ctx = metadata.NewOutgoingContext(ctx, md)

        // 3. 执行RPC调用
        err := invoker(ctx, method, req, reply, cc, opts...)

        // 4. 记录错误
        if err != nil {
            span.SetTag(TagError, "true")
            span.SetTag(TagErrorMessage, err.Error())
            span.Status = Status{Code: StatusCodeError, Message: err.Error()}
        }

        return err
    }
}
```

#### 2. 采样策略

**多种采样算法**

```go
type Sampler interface {
    ShouldSample(span *Span) bool
}

// 1. 固定比例采样
type ProbabilisticSampler struct {
    samplingRate float64  // 0.01表示采样1%
}

func (ps *ProbabilisticSampler) ShouldSample(span *Span) bool {
    // 基于TraceID的哈希值决定采样,保证同一Trace的所有Span采样决策一致
    hash := murmur3Hash(span.TraceID[:])
    threshold := uint64(ps.samplingRate * float64(math.MaxUint64))
    return hash < threshold
}

// 2. 限速采样(每秒最多N条)
type RateLimitingSampler struct {
    maxTracesPerSecond int
    limiter            *rate.Limiter
}

func (rls *RateLimitingSampler) ShouldSample(span *Span) bool {
    return rls.limiter.Allow()
}

// 3. 自适应采样(根据流量动态调整)
type AdaptiveSampler struct {
    targetQPS     int       // 目标采样QPS
    currentQPS    int       // 当前实际QPS
    samplingRate  float64   // 当前采样率
    updateTicker  *time.Ticker
}

func (as *AdaptiveSampler) Start() {
    as.updateTicker = time.NewTicker(10 * time.Second)
    go func() {
        for range as.updateTicker.C {
            as.adjustSamplingRate()
        }
    }()
}

func (as *AdaptiveSampler) adjustSamplingRate() {
    if as.currentQPS > as.targetQPS {
        // 流量过高,降低采样率
        as.samplingRate *= 0.9
    } else if as.currentQPS < as.targetQPS*0.8 {
        // 流量较低,提高采样率
        as.samplingRate *= 1.1
    }

    // 限制范围 [0.001, 1.0]
    as.samplingRate = math.Max(0.001, math.Min(1.0, as.samplingRate))
}

// 4. 尾部采样(Tail-based Sampling)
// 收集完整Trace后,根据特征决定是否保留
type TailSampler struct {
    traceBuffer map[TraceID]*TraceBuffer
    mu          sync.RWMutex
}

func (ts *TailSampler) OnSpanFinished(span *Span) {
    ts.mu.Lock()
    defer ts.mu.Unlock()

    buffer, exists := ts.traceBuffer[span.TraceID]
    if !exists {
        buffer = &TraceBuffer{
            spans:     []*Span{},
            startTime: time.Now(),
        }
        ts.traceBuffer[span.TraceID] = buffer
    }

    buffer.spans = append(buffer.spans, span)

    // 判断Trace是否完整(收到根Span)
    if span.ParentSpanID == nil {
        ts.evaluateAndFlush(span.TraceID)
    }
}

func (ts *TailSampler) evaluateAndFlush(traceID TraceID) {
    buffer := ts.traceBuffer[traceID]

    // 决策规则:
    // 1. 包含错误的Trace必须采样
    // 2. 耗时>5s的慢请求必须采样
    // 3. 特定标签(如VIP用户)的请求必须采样
    shouldSample := false

    for _, span := range buffer.spans {
        if span.Status.Code == StatusCodeError {
            shouldSample = true
            break
        }
        if span.Duration > 5*time.Second {
            shouldSample = true
            break
        }
        if span.Tags["user_type"] == "vip" {
            shouldSample = true
            break
        }
    }

    // 如果采样,导出所有Span
    if shouldSample {
        for _, span := range buffer.spans {
            exporter.Export(span)
        }
    }

    // 清理buffer
    delete(ts.traceBuffer, traceID)
}
```

#### 3. Collector服务

**数据接收与处理**

```go
type Collector struct {
    receivers  []Receiver       // gRPC/HTTP接收器
    processors []Processor      // 处理器管道
    exporters  []Exporter       // 导出器
}

// gRPC Receiver
type GRPCReceiver struct {
    port int
}

func (gr *GRPCReceiver) Start(ctx context.Context, consumer SpanConsumer) error {
    lis, err := net.Listen("tcp", fmt.Sprintf(":%d", gr.port))
    if err != nil {
        return err
    }

    server := grpc.NewServer()
    tracepb.RegisterTraceServiceServer(server, &traceServiceServer{
        consumer: consumer,
    })

    return server.Serve(lis)
}

type traceServiceServer struct {
    consumer SpanConsumer
    tracepb.UnimplementedTraceServiceServer
}

func (s *traceServiceServer) Export(ctx context.Context, req *tracepb.ExportTraceServiceRequest) (*tracepb.ExportTraceServiceResponse, error) {
    // 解析Span数据
    spans := make([]*Span, 0, len(req.ResourceSpans))
    for _, rs := range req.ResourceSpans {
        for _, ss := range rs.ScopeSpans {
            for _, span := range ss.Spans {
                spans = append(spans, convertFromProto(span))
            }
        }
    }

    // 传递给消费者处理
    if err := s.consumer.ConsumeSpans(ctx, spans); err != nil {
        return nil, err
    }

    return &tracepb.ExportTraceServiceResponse{}, nil
}

// Processor Pipeline
type ProcessorPipeline struct {
    processors []Processor
}

type Processor interface {
    Process(ctx context.Context, spans []*Span) ([]*Span, error)
}

// 批处理Processor(减少IO次数)
type BatchProcessor struct {
    batchSize    int
    timeout      time.Duration
    buffer       []*Span
    bufferMu     sync.Mutex
    flushTicker  *time.Ticker
    exporter     Exporter
}

func (bp *BatchProcessor) Start() {
    bp.flushTicker = time.NewTicker(bp.timeout)
    go func() {
        for range bp.flushTicker.C {
            bp.flush()
        }
    }()
}

func (bp *BatchProcessor) Process(ctx context.Context, spans []*Span) ([]*Span, error) {
    bp.bufferMu.Lock()
    defer bp.bufferMu.Unlock()

    bp.buffer = append(bp.buffer, spans...)

    // 批量大小达到阈值,立即flush
    if len(bp.buffer) >= bp.batchSize {
        bp.flush()
    }

    return spans, nil
}

func (bp *BatchProcessor) flush() {
    if len(bp.buffer) == 0 {
        return
    }

    // 导出批量数据
    if err := bp.exporter.ExportBatch(context.Background(), bp.buffer); err != nil {
        log.Errorf("export failed: %v", err)
    }

    // 清空buffer
    bp.buffer = bp.buffer[:0]
}

// 属性增强Processor
type AttributeEnrichmentProcessor struct {
    enrichers []Enricher
}

type Enricher interface {
    Enrich(span *Span) error
}

// 示例:添加K8s元数据
type K8sEnricher struct {
    k8sClient kubernetes.Interface
}

func (ke *K8sEnricher) Enrich(span *Span) error {
    // 从Span的资源属性中获取Pod信息
    podName := span.Tags["k8s.pod.name"]
    namespace := span.Tags["k8s.namespace.name"]

    if podName == "" || namespace == "" {
        return nil
    }

    // 查询K8s API获取Pod详细信息
    pod, err := ke.k8sClient.CoreV1().Pods(namespace).Get(context.Background(), podName, metav1.GetOptions{})
    if err != nil {
        return err
    }

    // 添加额外标签
    span.Tags["k8s.node.name"] = pod.Spec.NodeName
    span.Tags["k8s.deployment.name"] = pod.Labels["app"]

    return nil
}
```

#### 4. 存储层

**Cassandra存储实现**

```go
type CassandraStore struct {
    session *gocql.Session
}

func NewCassandraStore(hosts []string, keyspace string) (*CassandraStore, error) {
    cluster := gocql.NewCluster(hosts...)
    cluster.Keyspace = keyspace
    cluster.Consistency = gocql.Quorum

    session, err := cluster.CreateSession()
    if err != nil {
        return nil, err
    }

    return &CassandraStore{session: session}, nil
}

// Schema设计
const schemaSQL = `
-- Span表(按TraceID分区)
CREATE TABLE IF NOT EXISTS spans (
    trace_id blob,
    span_id blob,
    parent_span_id blob,
    operation_name text,
    service_name text,
    start_time timestamp,
    duration bigint,
    tags map<text, text>,
    logs list<frozen<log_entry>>,
    span_kind int,
    status_code int,
    PRIMARY KEY (trace_id, start_time, span_id)
) WITH CLUSTERING ORDER BY (start_time DESC);

-- 索引表:按服务名查询
CREATE TABLE IF NOT EXISTS traces_by_service (
    service_name text,
    start_time timestamp,
    trace_id blob,
    operation_name text,
    duration bigint,
    PRIMARY KEY (service_name, start_time, trace_id)
) WITH CLUSTERING ORDER BY (start_time DESC);

-- 索引表:按操作名查询
CREATE TABLE IF NOT EXISTS traces_by_operation (
    service_name text,
    operation_name text,
    start_time timestamp,
    trace_id blob,
    duration bigint,
    PRIMARY KEY ((service_name, operation_name), start_time, trace_id)
) WITH CLUSTERING ORDER BY (start_time DESC);

-- 索引表:按标签查询(倒排索引)
CREATE TABLE IF NOT EXISTS traces_by_tag (
    tag_key text,
    tag_value text,
    start_time timestamp,
    trace_id blob,
    PRIMARY KEY ((tag_key, tag_value), start_time, trace_id)
) WITH CLUSTERING ORDER BY (start_time DESC);
`

// 写入Span
func (cs *CassandraStore) WriteSpan(ctx context.Context, span *Span) error {
    // 1. 写入主表
    query := `INSERT INTO spans (trace_id, span_id, parent_span_id, operation_name,
              service_name, start_time, duration, tags, span_kind, status_code)
              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`

    err := cs.session.Query(query,
        span.TraceID[:],
        span.SpanID[:],
        span.ParentSpanID,
        span.OperationName,
        span.ServiceName,
        span.StartTime,
        span.Duration.Nanoseconds(),
        span.Tags,
        span.SpanKind,
        span.Status.Code,
    ).WithContext(ctx).Exec()

    if err != nil {
        return err
    }

    // 2. 写入索引表(异步批量写入)
    go cs.updateIndexes(span)

    return nil
}

// 批量写入
func (cs *CassandraStore) WriteBatch(ctx context.Context, spans []*Span) error {
    batch := cs.session.NewBatch(gocql.UnloggedBatch)

    for _, span := range spans {
        batch.Query(`INSERT INTO spans (...) VALUES (...)`, /* 参数 */)
    }

    return cs.session.ExecuteBatch(batch.WithContext(ctx))
}

// 查询Trace
func (cs *CassandraStore) GetTrace(ctx context.Context, traceID TraceID) ([]*Span, error) {
    query := `SELECT span_id, parent_span_id, operation_name, service_name,
              start_time, duration, tags, span_kind, status_code
              FROM spans WHERE trace_id = ?`

    iter := cs.session.Query(query, traceID[:]).WithContext(ctx).Iter()
    defer iter.Close()

    spans := []*Span{}
    var span Span
    span.TraceID = traceID

    for iter.Scan(&span.SpanID, &span.ParentSpanID, &span.OperationName,
        &span.ServiceName, &span.StartTime, &span.Duration,
        &span.Tags, &span.SpanKind, &span.Status.Code) {

        spans = append(spans, &span)
        span = Span{TraceID: traceID}  // 重置
    }

    return spans, iter.Close()
}

// 查询:按服务名和时间范围
func (cs *CassandraStore) FindTraces(ctx context.Context, req *TraceQueryRequest) ([]*TraceMetadata, error) {
    query := `SELECT trace_id, operation_name, start_time, duration
              FROM traces_by_service
              WHERE service_name = ? AND start_time >= ? AND start_time <= ?
              LIMIT ?`

    iter := cs.session.Query(query,
        req.ServiceName,
        req.StartTime,
        req.EndTime,
        req.Limit,
    ).WithContext(ctx).Iter()
    defer iter.Close()

    traces := []*TraceMetadata{}
    var trace TraceMetadata

    for iter.Scan(&trace.TraceID, &trace.OperationName, &trace.StartTime, &trace.Duration) {
        traces = append(traces, &trace)
        trace = TraceMetadata{}
    }

    return traces, iter.Close()
}
```

**ElasticSearch索引(加速复杂查询)**

```go
type ESStore struct {
    client *elasticsearch.Client
    index  string
}

// Span文档映射
const spanMapping = `{
  "mappings": {
    "properties": {
      "traceID": { "type": "keyword" },
      "spanID": { "type": "keyword" },
      "operationName": { "type": "keyword" },
      "serviceName": { "type": "keyword" },
      "startTime": { "type": "date" },
      "duration": { "type": "long" },
      "tags": {
        "type": "object",
        "dynamic": true
      },
      "spanKind": { "type": "keyword" },
      "statusCode": { "type": "keyword" }
    }
  }
}`

// 写入ES
func (es *ESStore) IndexSpan(ctx context.Context, span *Span) error {
    doc := map[string]interface{}{
        "traceID":       span.TraceID.String(),
        "spanID":        span.SpanID.String(),
        "operationName": span.OperationName,
        "serviceName":   span.ServiceName,
        "startTime":     span.StartTime,
        "duration":      span.Duration.Nanoseconds(),
        "tags":          span.Tags,
        "spanKind":      span.SpanKind,
        "statusCode":    span.Status.Code,
    }

    body, _ := json.Marshal(doc)

    req := esapi.IndexRequest{
        Index:      es.index,
        DocumentID: span.SpanID.String(),
        Body:       bytes.NewReader(body),
        Refresh:    "false",
    }

    _, err := req.Do(ctx, es.client)
    return err
}

// 复杂查询:多条件过滤
func (es *ESStore) SearchTraces(ctx context.Context, req *SearchRequest) ([]*Span, error) {
    // 构建ES查询DSL
    query := map[string]interface{}{
        "query": map[string]interface{}{
            "bool": map[string]interface{}{
                "must": []interface{}{
                    map[string]interface{}{
                        "term": map[string]interface{}{
                            "serviceName": req.ServiceName,
                        },
                    },
                    map[string]interface{}{
                        "range": map[string]interface{}{
                            "startTime": map[string]interface{}{
                                "gte": req.StartTime,
                                "lte": req.EndTime,
                            },
                        },
                    },
                },
                "filter": []interface{}{
                    map[string]interface{}{
                        "range": map[string]interface{}{
                            "duration": map[string]interface{}{
                                "gte": req.MinDuration,
                            },
                        },
                    },
                },
            },
        },
        "size": req.Limit,
        "sort": []interface{}{
            map[string]interface{}{
                "startTime": "desc",
            },
        },
    }

    // 添加标签过滤
    if len(req.Tags) > 0 {
        for k, v := range req.Tags {
            query["query"].(map[string]interface{})["bool"].(map[string]interface{})["must"] = append(
                query["query"].(map[string]interface{})["bool"].(map[string]interface{})["must"].([]interface{}),
                map[string]interface{}{
                    "term": map[string]interface{}{
                        fmt.Sprintf("tags.%s", k): v,
                    },
                },
            )
        }
    }

    body, _ := json.Marshal(query)

    res, err := es.client.Search(
        es.client.Search.WithContext(ctx),
        es.client.Search.WithIndex(es.index),
        es.client.Search.WithBody(bytes.NewReader(body)),
    )
    if err != nil {
        return nil, err
    }
    defer res.Body.Close()

    // 解析结果
    var result map[string]interface{}
    json.NewDecoder(res.Body).Decode(&result)

    spans := []*Span{}
    hits := result["hits"].(map[string]interface{})["hits"].([]interface{})

    for _, hit := range hits {
        source := hit.(map[string]interface{})["_source"].(map[string]interface{})
        span := parseSpanFromES(source)
        spans = append(spans, span)
    }

    return spans, nil
}
```

#### 5. 查询与分析API

**Query Service**

```go
type QueryService struct {
    storage    TraceStorage
    cache      *cache.Cache
    aggregator *Aggregator
}

// 查询单个Trace
func (qs *QueryService) GetTrace(ctx context.Context, traceID TraceID) (*Trace, error) {
    // 1. 查询缓存
    cacheKey := fmt.Sprintf("trace:%s", traceID)
    if cached, found := qs.cache.Get(cacheKey); found {
        return cached.(*Trace), nil
    }

    // 2. 从存储加载
    spans, err := qs.storage.GetTrace(ctx, traceID)
    if err != nil {
        return nil, err
    }

    // 3. 构建Trace树
    trace := qs.buildTraceTree(traceID, spans)

    // 4. 缓存
    qs.cache.Set(cacheKey, trace, 5*time.Minute)

    return trace, nil
}

// 构建Trace树结构
func (qs *QueryService) buildTraceTree(traceID TraceID, spans []*Span) *Trace {
    // 1. 找到根Span
    var rootSpan *Span
    spanMap := make(map[string]*Span)

    for _, span := range spans {
        spanMap[span.SpanID.String()] = span
        if span.ParentSpanID == nil {
            rootSpan = span
        }
    }

    // 2. 构建父子关系
    for _, span := range spans {
        if span.ParentSpanID != nil {
            parent := spanMap[span.ParentSpanID.String()]
            if parent != nil {
                parent.Children = append(parent.Children, span)
            }
        }
    }

    // 3. 计算关键路径
    criticalPath := qs.calculateCriticalPath(rootSpan)

    return &Trace{
        TraceID:      traceID,
        RootSpan:     rootSpan,
        Spans:        spans,
        Duration:     rootSpan.Duration,
        CriticalPath: criticalPath,
    }
}

// 服务依赖分析
func (qs *QueryService) AnalyzeDependencies(ctx context.Context, req *DependencyRequest) (*DependencyGraph, error) {
    // 1. 查询时间范围内的Span
    spans, err := qs.storage.FindSpans(ctx, &FindSpansRequest{
        StartTime: req.StartTime,
        EndTime:   req.EndTime,
        Limit:     100000,  // 大批量查询
    })
    if err != nil {
        return nil, err
    }

    // 2. 统计服务间调用关系
    graph := &DependencyGraph{
        Nodes: make(map[string]*ServiceNode),
        Edges: make(map[string]*DependencyEdge),
    }

    for _, span := range spans {
        // 跳过非RPC类型的Span
        if span.SpanKind != SpanKindClient {
            continue
        }

        source := span.ServiceName
        target := span.Tags["peer.service"]

        if target == "" {
            continue
        }

        // 添加节点
        if _, exists := graph.Nodes[source]; !exists {
            graph.Nodes[source] = &ServiceNode{Name: source}
        }
        if _, exists := graph.Nodes[target]; !exists {
            graph.Nodes[target] = &ServiceNode{Name: target}
        }

        // 添加边
        edgeKey := fmt.Sprintf("%s->%s", source, target)
        edge, exists := graph.Edges[edgeKey]
        if !exists {
            edge = &DependencyEdge{
                Source: source,
                Target: target,
            }
            graph.Edges[edgeKey] = edge
        }

        // 统计调用次数和平均延迟
        edge.CallCount++
        edge.TotalDuration += span.Duration
        if span.Status.Code == StatusCodeError {
            edge.ErrorCount++
        }
    }

    // 3. 计算指标
    for _, edge := range graph.Edges {
        edge.AvgDuration = edge.TotalDuration / time.Duration(edge.CallCount)
        edge.ErrorRate = float64(edge.ErrorCount) / float64(edge.CallCount)
    }

    return graph, nil
}

// 性能热点分析
func (qs *QueryService) AnalyzeHotspots(ctx context.Context, req *HotspotRequest) (*HotspotReport, error) {
    // 1. 查询慢请求
    slowTraces, err := qs.storage.FindTraces(ctx, &TraceQueryRequest{
        ServiceName: req.ServiceName,
        StartTime:   req.StartTime,
        EndTime:     req.EndTime,
        MinDuration: 1 * time.Second,  // 慢请求阈值
        Limit:       1000,
    })
    if err != nil {
        return nil, err
    }

    // 2. 统计慢操作
    opStats := make(map[string]*OperationStats)

    for _, traceMeta := range slowTraces {
        trace, _ := qs.GetTrace(ctx, traceMeta.TraceID)

        for _, span := range trace.Spans {
            key := fmt.Sprintf("%s::%s", span.ServiceName, span.OperationName)

            stats, exists := opStats[key]
            if !exists {
                stats = &OperationStats{
                    ServiceName:   span.ServiceName,
                    OperationName: span.OperationName,
                }
                opStats[key] = stats
            }

            stats.Count++
            stats.TotalDuration += span.Duration
            if span.Duration > stats.MaxDuration {
                stats.MaxDuration = span.Duration
            }
        }
    }

    // 3. 排序并返回Top N
    hotspots := make([]*OperationStats, 0, len(opStats))
    for _, stats := range opStats {
        stats.AvgDuration = stats.TotalDuration / time.Duration(stats.Count)
        hotspots = append(hotspots, stats)
    }

    sort.Slice(hotspots, func(i, j int) bool {
        return hotspots[i].TotalDuration > hotspots[j].TotalDuration
    })

    if len(hotspots) > req.TopN {
        hotspots = hotspots[:req.TopN]
    }

    return &HotspotReport{
        Hotspots: hotspots,
    }, nil
}
```

### 四、高级特性

#### 1. 实时告警

```go
type AlertEngine struct {
    rules      []*AlertRule
    evaluator  *RuleEvaluator
    notifier   *Notifier
}

type AlertRule struct {
    ID          string
    Name        string
    Condition   string          // P95(duration) > 1s
    ServiceName string
    Window      time.Duration   // 5m
    Threshold   float64
    Actions     []AlertAction
}

func (ae *AlertEngine) EvaluateOnSpan(span *Span) {
    for _, rule := range ae.rules {
        if rule.ServiceName != span.ServiceName {
            continue
        }

        // 检查条件
        if ae.evaluator.Evaluate(rule, span) {
            ae.triggerAlert(rule, span)
        }
    }
}

func (ae *AlertEngine) triggerAlert(rule *AlertRule, span *Span) {
    alert := &Alert{
        RuleID:    rule.ID,
        RuleName:  rule.Name,
        TraceID:   span.TraceID,
        SpanID:    span.SpanID,
        Timestamp: time.Now(),
        Message:   fmt.Sprintf("Alert: %s triggered for %s", rule.Name, span.ServiceName),
    }

    for _, action := range rule.Actions {
        ae.notifier.Send(action, alert)
    }
}
```

#### 2. 根因分析

```go
type RootCauseAnalyzer struct {
    queryService *QueryService
}

// 自动定位慢请求的根因
func (rca *RootCauseAnalyzer) Analyze(ctx context.Context, traceID TraceID) (*RootCauseReport, error) {
    // 1. 获取完整Trace
    trace, err := rca.queryService.GetTrace(ctx, traceID)
    if err != nil {
        return nil, err
    }

    // 2. 找到关键路径(耗时最长的路径)
    criticalPath := rca.findCriticalPath(trace.RootSpan)

    // 3. 分析关键路径上的瓶颈
    bottlenecks := []*Bottleneck{}

    for _, span := range criticalPath {
        // 计算Self Time(自身耗时,不含子Span)
        selfTime := rca.calculateSelfTime(span)

        // Self Time占总时间的比例
        ratio := float64(selfTime) / float64(trace.Duration)

        // 如果Self Time占比>30%,认为是瓶颈
        if ratio > 0.3 {
            bottlenecks = append(bottlenecks, &Bottleneck{
                Span:     span,
                SelfTime: selfTime,
                Ratio:    ratio,
                Reason:   rca.inferReason(span),
            })
        }
    }

    return &RootCauseReport{
        TraceID:      traceID,
        TotalDuration: trace.Duration,
        CriticalPath: criticalPath,
        Bottlenecks:  bottlenecks,
    }, nil
}

func (rca *RootCauseAnalyzer) inferReason(span *Span) string {
    // 根据标签推断原因
    if span.Tags[TagDBType] != "" {
        return "Database query slow"
    }
    if span.Tags["cache.miss"] == "true" {
        return "Cache miss"
    }
    if span.Tags[TagHTTPStatusCode] == "429" {
        return "Rate limited"
    }
    if len(span.Children) == 0 {
        return "Business logic slow"
    }

    return "Unknown"
}
```

### 五、性能优化

#### 1. 数据压缩

```go
// Span数据压缩
func CompressSpan(span *Span) ([]byte, error) {
    // 1. 序列化为Protobuf(比JSON小70%)
    pb := span.ToProto()
    data, err := proto.Marshal(pb)
    if err != nil {
        return nil, err
    }

    // 2. Gzip压缩(再压缩50%)
    var buf bytes.Buffer
    writer := gzip.NewWriter(&buf)
    writer.Write(data)
    writer.Close()

    return buf.Bytes(), nil
}
```

#### 2. 查询优化

```go
// 使用Bloom Filter加速存在性查询
type BloomFilterIndex struct {
    filters map[string]*bloom.BloomFilter  // 按天分片
}

func (bfi *BloomFilterIndex) MightContain(traceID TraceID, date time.Time) bool {
    key := date.Format("2006-01-02")
    filter := bfi.filters[key]
    return filter.Test(traceID[:])
}
```

---

## 总结

分布式追踪系统的核心价值在于**可观测性**,通过全链路追踪实现:

1. **性能分析** - 识别慢请求和瓶颈
2. **故障定位** - 快速找到错误根因
3. **依赖分析** - 可视化服务间调用关系
4. **容量规划** - 基于真实调用数据评估资源需求

关键设计点:
- **低侵入性** - SDK轻量,中间件自动化
- **高性能** - 采样策略,批量写入,压缩传输
- **可扩展** - 水平扩展Collector和Storage
- **易用性** - 丰富的查询UI和分析能力

技术挑战主要在于海量数据处理、实时性、存储成本控制等方面。
