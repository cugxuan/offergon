---
title: 设计一个实时日志分析和告警系统
tags:
  - 复杂系统设计
status: robot
class: 复杂系统设计
slug: real-time-log-analysis-alert-system
ref:
---

## 核心要点提炼

**实时日志分析系统核心：** 流式采集 + 实时计算 + 复杂事件处理 + 智能告警 + 可视化展示

**关键技术点：** 高吞吐采集(Kafka+Filebeat)、流处理(Flink)、规则引擎(CEP)、告警管理(多渠道+去重)、存储优化(ES+ClickHouse)

---

## 详细设计方案

### 1. 系统架构设计

#### 1.1 整体架构
```
┌─────────────────────────────────────────────────────────────┐
│                    Data Source Layer                       │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Application  │ │   System    │ │  Network    │          │
│  │    Logs     │ │    Logs     │ │    Logs     │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│                  Collection Layer                          │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │  Filebeat   │ │  Fluentd    │ │   Logstash  │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│                   Message Queue                            │
│  ┌─────────────────────────────────────────────────────┐  │
│  │                   Kafka Cluster                    │  │
│  │  Topic: app-logs | system-logs | network-logs     │  │
│  └─────────────────────────────────────────────────────┘  │
├─────────────────────────────────────────────────────────────┤
│                 Stream Processing                          │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Flink Cluster│ │ Storm/Spark │ │ Custom CEP  │          │
│  │   (Parser)  │ │(Aggregator) │ │   Engine    │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│                Storage & Query Layer                       │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Elasticsearch│ │ ClickHouse  │ │    Redis    │          │
│  │(Hot Storage)│ │(Cold Storage│ │   (Cache)   │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│                Alert & Visualization                       │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Alert Manager│ │   Grafana   │ │   Kibana    │          │
│  │(Rules+Send) │ │(Dashboard)  │ │ (Analysis)  │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
```

#### 1.2 数据流架构
```
Logs → Collection → Kafka → Stream Processing → Storage → Alert/Query
  ↓        ↓          ↓           ↓              ↓         ↓
File    Filebeat   Topic      Flink           ES/CH    Grafana
Syslog  Fluentd   Partition  Storm            Redis    Kibana
API     Logstash  Consumer   Spark            MySQL    Alert
```

### 2. 数据采集层设计

#### 2.1 多源数据采集
```yaml
# Filebeat 配置示例
filebeat.inputs:
- type: log
  paths:
    - /var/log/app/*.log
    - /var/log/nginx/*.log
  fields:
    logtype: application
    service: webapp
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

- type: docker
  containers.ids:
    - "*"
  processors:
    - add_docker_metadata: ~

- type: syslog
  protocol.tcp:
    host: "0.0.0.0:514"

output.kafka:
  hosts: ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
  topic: 'logs-%{[fields.logtype]}'
  partition.round_robin:
    reachable_only: false
  compression: gzip
  max_message_bytes: 1000000
```

#### 2.2 实时采集监控
```go
// 采集器状态监控
type CollectorMetrics struct {
    BytesRead      prometheus.Counter    // 读取字节数
    LinesProcessed prometheus.Counter    // 处理行数
    ErrorCount     prometheus.Counter    // 错误计数
    Latency        prometheus.Histogram  // 处理延迟
    BackpressureGauge prometheus.Gauge   // 背压指标
}

type LogCollector struct {
    config  *Config
    metrics *CollectorMetrics
    buffer  chan LogEntry
    kafka   *KafkaProducer
}

func (lc *LogCollector) Start() error {
    // 启动文件监听
    go lc.watchFiles()

    // 启动批量发送
    go lc.batchSender()

    // 启动健康检查
    go lc.healthCheck()

    return nil
}

func (lc *LogCollector) batchSender() {
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()

    batch := make([]LogEntry, 0, 1000)

    for {
        select {
        case entry := <-lc.buffer:
            batch = append(batch, entry)
            if len(batch) >= 1000 {
                lc.sendBatch(batch)
                batch = batch[:0]
            }

        case <-ticker.C:
            if len(batch) > 0 {
                lc.sendBatch(batch)
                batch = batch[:0]
            }
        }
    }
}
```

### 3. 消息队列层设计

#### 3.1 Kafka 集群配置
```yaml
# Kafka 主题配置
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: app-logs
spec:
  partitions: 12
  replicas: 3
  config:
    retention.ms: 259200000        # 3天保留
    segment.ms: 3600000           # 1小时分段
    compression.type: "gzip"       # 压缩类型
    cleanup.policy: "delete"       # 清理策略
    min.insync.replicas: 2        # 最小同步副本
    unclean.leader.election.enable: false

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: alert-events
spec:
  partitions: 6
  replicas: 3
  config:
    retention.ms: 86400000        # 1天保留
    segment.ms: 1800000          # 30分钟分段
```

#### 3.2 消息分区策略
```go
// 智能分区器
type LogPartitioner struct {
    hasher hash.Hash32
}

func (lp *LogPartitioner) Partition(message *kafka.Message,
    numPartitions int32) (int32, error) {

    var partitionKey string

    logEntry := parseLogEntry(message.Value)

    // 根据日志类型选择分区策略
    switch logEntry.Type {
    case "error", "fatal":
        // 错误日志集中到少数分区，便于快速处理
        partitionKey = fmt.Sprintf("error_%s", logEntry.Service)
    case "access":
        // 访问日志按用户ID分区，保证用户行为连续性
        partitionKey = fmt.Sprintf("user_%s", logEntry.UserID)
    default:
        // 普通日志按服务分区
        partitionKey = logEntry.Service
    }

    lp.hasher.Reset()
    lp.hasher.Write([]byte(partitionKey))
    return int32(lp.hasher.Sum32()) % numPartitions, nil
}
```

### 4. 流处理引擎设计

#### 4.1 Flink 流处理作业
```java
// Flink 日志处理作业
public class LogProcessingJob {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env =
            StreamExecutionEnvironment.getExecutionEnvironment();

        // 设置Checkpoint
        env.enableCheckpointing(60000);
        env.getCheckpointConfig().setCheckpointingMode(
            CheckpointingMode.EXACTLY_ONCE);

        // Kafka Source
        FlinkKafkaConsumer<String> kafkaSource = new FlinkKafkaConsumer<>(
            "app-logs",
            new SimpleStringSchema(),
            getKafkaProperties());

        DataStream<LogEntry> logStream = env
            .addSource(kafkaSource)
            .map(new LogParseFunction())
            .filter(new LogFilterFunction());

        // 异常检测流
        logStream
            .filter(log -> "ERROR".equals(log.getLevel()))
            .keyBy(LogEntry::getService)
            .window(TumblingEventTimeWindows.of(Time.minutes(1)))
            .aggregate(new ErrorCountAggregator())
            .addSink(new AlertSinkFunction());

        // 实时统计流
        logStream
            .keyBy(LogEntry::getService)
            .window(SlidingEventTimeWindows.of(
                Time.minutes(5), Time.minutes(1)))
            .aggregate(new LogStatsAggregator())
            .addSink(new MetricsSinkFunction());

        // 异常行为检测
        logStream
            .filter(log -> "access".equals(log.getType()))
            .keyBy(LogEntry::getUserId)
            .process(new AnomalyDetectionFunction())
            .addSink(new SecurityAlertSink());

        env.execute("Log Processing Job");
    }
}

// 异常检测函数
public class AnomalyDetectionFunction
    extends KeyedProcessFunction<String, LogEntry, Alert> {

    private ValueState<UserBehaviorState> behaviorState;
    private ValueState<Long> lastAlertTime;

    @Override
    public void processElement(LogEntry log, Context ctx,
        Collector<Alert> out) throws Exception {

        UserBehaviorState behavior = behaviorState.value();
        if (behavior == null) {
            behavior = new UserBehaviorState();
        }

        // 更新用户行为状态
        behavior.update(log);

        // 异常检测逻辑
        if (isAnomalous(behavior)) {
            Long lastAlert = lastAlertTime.value();
            long currentTime = System.currentTimeMillis();

            // 避免重复告警（5分钟内）
            if (lastAlert == null ||
                currentTime - lastAlert > 300000) {

                Alert alert = new Alert();
                alert.setType("ANOMALY");
                alert.setUserId(log.getUserId());
                alert.setDescription("异常用户行为检测");
                alert.setSeverity(AlertSeverity.WARNING);

                out.collect(alert);
                lastAlertTime.update(currentTime);
            }
        }

        behaviorState.update(behavior);
    }
}
```

#### 4.2 复杂事件处理 (CEP)
```java
// CEP 规则定义
public class SecurityCEPRules {

    public static void createSecurityPatterns(CEP cep) {

        // 模式1：连续失败登录检测
        Pattern<LogEntry, ?> failedLoginPattern = Pattern
            .<LogEntry>begin("first")
            .where(new SimpleCondition<LogEntry>() {
                @Override
                public boolean filter(LogEntry log) {
                    return "LOGIN_FAILED".equals(log.getAction());
                }
            })
            .followedBy("second")
            .where(new SimpleCondition<LogEntry>() {
                @Override
                public boolean filter(LogEntry log) {
                    return "LOGIN_FAILED".equals(log.getAction());
                }
            })
            .followedBy("third")
            .where(new SimpleCondition<LogEntry>() {
                @Override
                public boolean filter(LogEntry log) {
                    return "LOGIN_FAILED".equals(log.getAction());
                }
            })
            .within(Time.minutes(5));

        // 模式2：SQL注入检测
        Pattern<LogEntry, ?> sqlInjectionPattern = Pattern
            .<LogEntry>begin("injection")
            .where(new SimpleCondition<LogEntry>() {
                @Override
                public boolean filter(LogEntry log) {
                    String query = log.getHttpRequest();
                    return query != null && (
                        query.contains("' OR '1'='1") ||
                        query.contains("UNION SELECT") ||
                        query.contains("DROP TABLE")
                    );
                }
            });

        // 注册模式处理
        cep.pattern(failedLoginPattern)
           .select(new SecurityAlertSelector());

        cep.pattern(sqlInjectionPattern)
           .select(new InjectionAlertSelector());
    }
}

// 安全告警选择器
public class SecurityAlertSelector
    implements PatternSelectFunction<LogEntry, Alert> {

    @Override
    public Alert select(Map<String, List<LogEntry>> pattern) {
        List<LogEntry> failures = pattern.get("third");
        LogEntry lastFailure = failures.get(failures.size() - 1);

        Alert alert = new Alert();
        alert.setType("SECURITY_BREACH");
        alert.setUserId(lastFailure.getUserId());
        alert.setSourceIP(lastFailure.getSourceIP());
        alert.setDescription("检测到连续登录失败，可能存在暴力破解攻击");
        alert.setSeverity(AlertSeverity.HIGH);
        alert.setTimestamp(System.currentTimeMillis());

        return alert;
    }
}
```

### 5. 存储层设计

#### 5.1 分层存储策略
```yaml
# Elasticsearch 热数据存储配置
PUT _template/logs-hot-template
{
  "index_patterns": ["logs-*"],
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index.routing.allocation.require.data": "hot",
    "index.lifecycle.name": "logs-lifecycle",
    "index.lifecycle.rollover_alias": "logs-write"
  },
  "mappings": {
    "properties": {
      "@timestamp": {"type": "date"},
      "level": {"type": "keyword"},
      "service": {"type": "keyword"},
      "message": {"type": "text", "analyzer": "standard"},
      "user_id": {"type": "keyword"},
      "source_ip": {"type": "ip"},
      "response_time": {"type": "long"},
      "status_code": {"type": "integer"}
    }
  }
}

# ILM 生命周期策略
PUT _ilm/policy/logs-lifecycle
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "10gb",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "require": {"data": "warm"}
          },
          "forcemerge": {
            "max_num_segments": 1
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "require": {"data": "cold"}
          }
        }
      },
      "delete": {
        "min_age": "90d"
      }
    }
  }
}
```

#### 5.2 ClickHouse 冷数据存储
```sql
-- ClickHouse 日志表设计
CREATE TABLE logs_distributed
(
    timestamp DateTime64(3),
    level LowCardinality(String),
    service LowCardinality(String),
    host LowCardinality(String),
    user_id String,
    source_ip IPv4,
    message String,
    response_time UInt32,
    status_code UInt16,
    day Date MATERIALIZED toDate(timestamp)
)
ENGINE = Distributed(cluster, default, logs_local, cityHash64(service));

-- 本地表
CREATE TABLE logs_local
(
    timestamp DateTime64(3),
    level LowCardinality(String),
    service LowCardinality(String),
    host LowCardinality(String),
    user_id String,
    source_ip IPv4,
    message String,
    response_time UInt32,
    status_code UInt16,
    day Date MATERIALIZED toDate(timestamp)
)
ENGINE = MergeTree()
PARTITION BY day
ORDER BY (service, level, timestamp)
SETTINGS index_granularity = 8192;

-- 物化视图：实时统计
CREATE MATERIALIZED VIEW error_stats_mv
ENGINE = SummingMergeTree()
PARTITION BY day
ORDER BY (service, host, level, hour)
AS SELECT
    service,
    host,
    level,
    toHour(timestamp) as hour,
    toDate(timestamp) as day,
    count() as error_count,
    avg(response_time) as avg_response_time
FROM logs_local
WHERE level IN ('ERROR', 'FATAL')
GROUP BY service, host, level, hour, day;
```

### 6. 告警引擎设计

#### 6.1 规则引擎架构
```go
// 告警规则定义
type AlertRule struct {
    ID          string              `json:"id"`
    Name        string              `json:"name"`
    Description string              `json:"description"`
    Query       string              `json:"query"`
    Conditions  []AlertCondition    `json:"conditions"`
    Severity    AlertSeverity       `json:"severity"`
    Frequency   time.Duration       `json:"frequency"`
    Enabled     bool               `json:"enabled"`
    NotifyChannels []string         `json:"notify_channels"`
}

type AlertCondition struct {
    Field     string      `json:"field"`
    Operator  string      `json:"operator"`  // >, <, >=, <=, ==, !=
    Value     interface{} `json:"value"`
    Aggregation string    `json:"aggregation"` // count, sum, avg, max, min
    TimeWindow time.Duration `json:"time_window"`
}

// 告警规则引擎
type AlertEngine struct {
    rules       map[string]*AlertRule
    evaluator   *RuleEvaluator
    notifier    *AlertNotifier
    storage     AlertStorage
    mu          sync.RWMutex
}

func (ae *AlertEngine) EvaluateRules() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        ae.mu.RLock()
        rules := make([]*AlertRule, 0, len(ae.rules))
        for _, rule := range ae.rules {
            if rule.Enabled {
                rules = append(rules, rule)
            }
        }
        ae.mu.RUnlock()

        // 并行评估规则
        var wg sync.WaitGroup
        for _, rule := range rules {
            wg.Add(1)
            go func(r *AlertRule) {
                defer wg.Done()
                ae.evaluateRule(r)
            }(rule)
        }
        wg.Wait()
    }
}

func (ae *AlertEngine) evaluateRule(rule *AlertRule) {
    // 执行查询
    result, err := ae.evaluator.Query(rule.Query, rule.Conditions)
    if err != nil {
        log.Errorf("Failed to evaluate rule %s: %v", rule.ID, err)
        return
    }

    // 检查条件
    triggered := ae.checkConditions(result, rule.Conditions)

    if triggered {
        alert := &Alert{
            RuleID:      rule.ID,
            RuleName:    rule.Name,
            Severity:    rule.Severity,
            Message:     ae.generateAlertMessage(rule, result),
            Timestamp:   time.Now(),
            Labels:      result.Labels,
            Annotations: result.Annotations,
        }

        // 发送告警
        ae.notifier.Send(alert, rule.NotifyChannels)
    }
}
```

#### 6.2 告警去重与抑制
```go
// 告警去重器
type AlertDeduplicator struct {
    activeAlerts map[string]*Alert
    mu          sync.RWMutex
    groupWait   time.Duration
    groupInterval time.Duration
    repeatInterval time.Duration
}

func (ad *AlertDeduplicator) Process(alert *Alert) bool {
    ad.mu.Lock()
    defer ad.mu.Unlock()

    // 生成去重键
    dedupKey := ad.generateDedupKey(alert)

    existingAlert, exists := ad.activeAlerts[dedupKey]

    if !exists {
        // 新告警
        ad.activeAlerts[dedupKey] = alert
        return true
    }

    // 检查是否需要重复发送
    if time.Since(existingAlert.LastSent) > ad.repeatInterval {
        existingAlert.LastSent = time.Now()
        existingAlert.Count++
        return true
    }

    // 更新现有告警计数
    existingAlert.Count++
    return false
}

func (ad *AlertDeduplicator) generateDedupKey(alert *Alert) string {
    var buf bytes.Buffer
    buf.WriteString(alert.RuleID)
    buf.WriteString("|")

    // 添加关键标签到去重键
    labels := []string{"service", "host", "environment"}
    for _, label := range labels {
        if value, ok := alert.Labels[label]; ok {
            buf.WriteString(label)
            buf.WriteString("=")
            buf.WriteString(value)
            buf.WriteString("|")
        }
    }

    return buf.String()
}

// 告警抑制器
type AlertSuppressor struct {
    suppressionRules []SuppressionRule
}

type SuppressionRule struct {
    SourceMatchers []LabelMatcher  `json:"source_matchers"`
    TargetMatchers []LabelMatcher  `json:"target_matchers"`
    Equal         []string        `json:"equal"`
}

func (as *AlertSuppressor) ShouldSuppress(alert *Alert,
    activeAlerts []*Alert) bool {

    for _, rule := range as.suppressionRules {
        // 查找抑制源
        var suppressorAlert *Alert
        for _, active := range activeAlerts {
            if as.matchesMatchers(active, rule.SourceMatchers) {
                suppressorAlert = active
                break
            }
        }

        if suppressorAlert == nil {
            continue
        }

        // 检查目标匹配
        if as.matchesMatchers(alert, rule.TargetMatchers) {
            // 检查相等标签
            suppressed := true
            for _, label := range rule.Equal {
                if suppressorAlert.Labels[label] != alert.Labels[label] {
                    suppressed = false
                    break
                }
            }

            if suppressed {
                return true
            }
        }
    }

    return false
}
```

### 7. 告警通知系统

#### 7.1 多渠道通知
```go
// 通知渠道接口
type NotificationChannel interface {
    Send(alert *Alert) error
    GetType() string
    GetConfig() map[string]interface{}
}

// 邮件通知
type EmailNotifier struct {
    SMTPHost     string
    SMTPPort     int
    Username     string
    Password     string
    From         string
    TemplatePath string
}

func (en *EmailNotifier) Send(alert *Alert) error {
    // 构建邮件内容
    subject := fmt.Sprintf("[%s] %s", alert.Severity, alert.RuleName)

    body, err := en.renderTemplate(alert)
    if err != nil {
        return err
    }

    // 发送邮件
    auth := smtp.PlainAuth("", en.Username, en.Password, en.SMTPHost)

    msg := fmt.Sprintf("To: %s\r\nSubject: %s\r\nContent-Type: text/html; charset=UTF-8\r\n\r\n%s",
        strings.Join(alert.Recipients, ","), subject, body)

    addr := fmt.Sprintf("%s:%d", en.SMTPHost, en.SMTPPort)
    return smtp.SendMail(addr, auth, en.From, alert.Recipients, []byte(msg))
}

// 钉钉通知
type DingTalkNotifier struct {
    WebhookURL string
    Secret     string
}

func (dt *DingTalkNotifier) Send(alert *Alert) error {
    // 构建钉钉消息
    message := map[string]interface{}{
        "msgtype": "markdown",
        "markdown": map[string]string{
            "title": fmt.Sprintf("告警: %s", alert.RuleName),
            "text": dt.formatMarkdown(alert),
        },
        "at": map[string]interface{}{
            "isAtAll": alert.Severity == "CRITICAL",
        },
    }

    // 计算签名
    timestamp := time.Now().UnixNano() / int64(time.Millisecond)
    signature := dt.calculateSignature(timestamp)

    url := fmt.Sprintf("%s&timestamp=%d&sign=%s",
        dt.WebhookURL, timestamp, signature)

    // 发送HTTP请求
    jsonData, _ := json.Marshal(message)
    resp, err := http.Post(url, "application/json", bytes.NewBuffer(jsonData))
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    return nil
}

// 企业微信通知
type WeChatWorkNotifier struct {
    WebhookURL string
}

func (ww *WeChatWorkNotifier) Send(alert *Alert) error {
    message := map[string]interface{}{
        "msgtype": "text",
        "text": map[string]string{
            "content": ww.formatText(alert),
        },
    }

    jsonData, _ := json.Marshal(message)
    resp, err := http.Post(ww.WebhookURL, "application/json",
        bytes.NewBuffer(jsonData))
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    return nil
}

// 通知管理器
type NotificationManager struct {
    channels map[string]NotificationChannel
    router   *NotificationRouter
    queue    chan *AlertNotification
}

func (nm *NotificationManager) Send(alert *Alert, channelNames []string) {
    for _, channelName := range channelNames {
        if channel, exists := nm.channels[channelName]; exists {
            notification := &AlertNotification{
                Alert:   alert,
                Channel: channel,
                Retries: 0,
                MaxRetries: 3,
            }

            select {
            case nm.queue <- notification:
            default:
                log.Warnf("Notification queue is full, dropping alert: %s",
                    alert.RuleID)
            }
        }
    }
}

func (nm *NotificationManager) processNotifications() {
    for notification := range nm.queue {
        go func(n *AlertNotification) {
            err := n.Channel.Send(n.Alert)
            if err != nil && n.Retries < n.MaxRetries {
                n.Retries++
                time.Sleep(time.Duration(n.Retries) * time.Minute)
                nm.queue <- n
            }
        }(notification)
    }
}
```

### 8. 可视化与监控

#### 8.1 Grafana Dashboard
```json
{
  "dashboard": {
    "title": "日志分析监控大盘",
    "panels": [
      {
        "title": "日志流量趋势",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(logs_total[5m])",
            "legendFormat": "{{service}} - {{level}}"
          }
        ]
      },
      {
        "title": "错误率分布",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(logs_total{level=\"ERROR\"}[5m])) / sum(rate(logs_total[5m])) * 100",
            "legendFormat": "错误率 %"
          }
        ]
      },
      {
        "title": "TOP 错误服务",
        "type": "table",
        "targets": [
          {
            "expr": "topk(10, sum by (service) (rate(logs_total{level=\"ERROR\"}[1h])))",
            "format": "table"
          }
        ]
      },
      {
        "title": "告警统计",
        "type": "pie",
        "targets": [
          {
            "expr": "sum by (severity) (alerts_total)",
            "legendFormat": "{{severity}}"
          }
        ]
      }
    ]
  }
}
```

#### 8.2 Kibana 日志分析
```yaml
# Kibana 索引模式配置
GET /_template/kibana-logs
{
  "index_patterns": ["logs-*"],
  "mappings": {
    "properties": {
      "@timestamp": {"type": "date"},
      "level": {"type": "keyword"},
      "service": {"type": "keyword"},
      "message": {
        "type": "text",
        "fields": {
          "keyword": {"type": "keyword", "ignore_above": 256}
        }
      },
      "user_id": {"type": "keyword"},
      "source_ip": {"type": "ip"},
      "geo_location": {"type": "geo_point"},
      "response_time": {"type": "long"},
      "status_code": {"type": "integer"}
    }
  }
}

# Kibana 数据视图
PUT /.kibana/_doc/index-pattern:logs-*
{
  "index-pattern": {
    "title": "logs-*",
    "timeFieldName": "@timestamp",
    "fields": "[{\"name\":\"@timestamp\",\"type\":\"date\",\"searchable\":true,\"aggregatable\":true}]"
  }
}
```

### 9. 性能优化与扩展

#### 9.1 性能监控指标
```go
type SystemMetrics struct {
    // 吞吐量指标
    LogsPerSecond    prometheus.Gauge    // 日志处理速度
    BytesPerSecond   prometheus.Gauge    // 字节处理速度
    BacklogSize      prometheus.Gauge    // 积压队列大小

    // 延迟指标
    IngestionLatency prometheus.Histogram // 摄入延迟
    ProcessLatency   prometheus.Histogram // 处理延迟
    QueryLatency     prometheus.Histogram // 查询延迟

    // 错误指标
    DropRate         prometheus.Gauge    // 丢弃率
    ErrorRate        prometheus.Gauge    // 错误率
    RetryCount       prometheus.Counter  // 重试次数

    // 资源指标
    CPUUsage         prometheus.Gauge    // CPU使用率
    MemoryUsage      prometheus.Gauge    // 内存使用率
    DiskIOPS         prometheus.Gauge    // 磁盘IOPS
    NetworkBandwidth prometheus.Gauge    // 网络带宽
}

// 自动扩缩容
type AutoScaler struct {
    metrics    *SystemMetrics
    thresholds *ScalingThresholds
    scaler     *ContainerScaler
}

type ScalingThresholds struct {
    CPUHigh       float64  // CPU高阈值 (80%)
    CPULow        float64  // CPU低阈值 (20%)
    MemoryHigh    float64  // 内存高阈值 (85%)
    BacklogHigh   int64    // 积压高阈值
    LatencyHigh   time.Duration // 延迟高阈值
}

func (as *AutoScaler) Monitor() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        metrics := as.getCurrentMetrics()

        // 扩容决策
        if as.shouldScaleUp(metrics) {
            as.scaleUp()
        } else if as.shouldScaleDown(metrics) {
            as.scaleDown()
        }
    }
}

func (as *AutoScaler) shouldScaleUp(metrics *MetricsSnapshot) bool {
    return metrics.CPUUsage > as.thresholds.CPUHigh ||
           metrics.MemoryUsage > as.thresholds.MemoryHigh ||
           metrics.BacklogSize > as.thresholds.BacklogHigh ||
           metrics.AvgLatency > as.thresholds.LatencyHigh
}
```

#### 9.2 水平扩展策略
```yaml
# Kubernetes HPA 配置
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: log-processor-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: log-processor
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: kafka_consumer_lag
      target:
        type: AverageValue
        averageValue: "1000"
```

### 10. 灾难恢复与高可用

#### 10.1 多区域部署
```yaml
# 多区域 Kafka 集群配置
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: log-kafka-cluster
spec:
  kafka:
    replicas: 9
    config:
      default.replication.factor: 3
      min.insync.replicas: 2
      offsets.topic.replication.factor: 3
    rack:
      topologyKey: topology.kubernetes.io/zone
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app: kafka
            topologyKey: topology.kubernetes.io/zone
```

#### 10.2 数据备份与恢复
```bash
#!/bin/bash
# 数据备份脚本

# Elasticsearch 快照备份
curl -X PUT "elasticsearch:9200/_snapshot/backup_repository" -H 'Content-Type: application/json' -d'
{
  "type": "s3",
  "settings": {
    "bucket": "log-backups",
    "region": "us-west-2",
    "base_path": "elasticsearch"
  }
}'

# 创建快照
curl -X PUT "elasticsearch:9200/_snapshot/backup_repository/snapshot_$(date +%Y%m%d_%H%M%S)" -H 'Content-Type: application/json' -d'
{
  "indices": "logs-*",
  "ignore_unavailable": true,
  "include_global_state": false
}'

# ClickHouse 备份
clickhouse-backup create backup_$(date +%Y%m%d_%H%M%S)
clickhouse-backup upload backup_$(date +%Y%m%d_%H%M%S)

# Kafka 数据备份 (使用 MirrorMaker 2.0)
kafka-mirror-maker-2.sh --config-file mirror-maker.properties
```

## 总结

这个实时日志分析和告警系统设计方案提供了：

1. **高吞吐量采集**: 支持百万级日志/秒的实时采集
2. **实时流处理**: 毫秒级的事件检测和处理
3. **智能告警**: 复杂事件处理和多级告警机制
4. **存储优化**: 热温冷分层存储，成本优化
5. **高可用性**: 多副本、多区域部署
6. **扩展性**: 水平扩展支持，自动扩缩容
7. **可观测性**: 全方位监控和可视化

系统能够处理：
- **数据量**: PB级日志存储
- **实时性**: 秒级告警响应
- **可用性**: 99.99% SLA
- **扩展性**: 支持数百个服务接入
