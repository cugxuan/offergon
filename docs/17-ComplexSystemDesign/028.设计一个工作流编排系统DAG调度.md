---
title: 设计一个工作流编排系统（DAG调度）
tags:
  - 复杂系统设计
status: robot
class: 复杂系统设计
slug: workflow-orchestration-system-dag-scheduling
ref:
---

## 核心要点

**工作流编排系统设计精髓：** 通过DAG（有向无环图）拓扑排序、任务状态机、分布式调度器、资源管理器，实现复杂业务流程的自动化编排，支持条件分支、并行执行、故障重试、动态伸缩的企业级工作流引擎。

## 详细解答

### 1. 系统概述

工作流编排系统是企业数字化转型的核心基础设施，负责管理和执行复杂的业务流程。系统需要支持DAG（有向无环图）的构建、调度、执行和监控，确保任务之间的依赖关系得到正确执行。

### 2. 整体架构设计

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Web Portal    │    │    API Gateway  │    │  Task Explorer  │
│                 │    │                 │    │                 │
│  ┌───────────┐  │    │  ┌───────────┐  │    │  ┌───────────┐  │
│  │Workflow   │  │    │  │Auth &     │  │    │  │Log Viewer │  │
│  │Designer   │  │    │  │Rate Limit │  │    │  │Metrics    │  │
│  └───────────┘  │    │  └───────────┘  │    │  └───────────┘  │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
         ┌───────────────────────┼───────────────────────┐
         │                       │                       │
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│ Workflow Engine │    │   Scheduler     │    │ Resource Manager│
│                 │    │                 │    │                 │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │DAG Parser   │ │    │ │Task Queue   │ │    │ │Node Pool    │ │
│ │State Machine│ │    │ │Priority     │ │    │ │Auto Scaling │ │
│ │Event Bus    │ │    │ │Load Balance │ │    │ │Health Check │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
         ┌───────────────────────┼───────────────────────┐
         │                       │                       │
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Data Layer    │    │   Execution     │    │   Monitoring    │
│                 │    │   Runtime       │    │                 │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │Metadata DB  │ │    │ │Worker Nodes │ │    │ │Metrics      │ │
│ │Task Queue   │ │    │ │Containers   │ │    │ │Alerting     │ │
│ │Log Storage  │ │    │ │Isolation    │ │    │ │Tracing      │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 3. 核心组件设计

#### 3.1 DAG定义和解析

```go
type DAG struct {
    ID           string            `json:"id"`
    Name         string            `json:"name"`
    Description  string            `json:"description"`
    Version      string            `json:"version"`
    Tasks        map[string]*Task  `json:"tasks"`
    Dependencies map[string][]string `json:"dependencies"`
    Schedule     Schedule          `json:"schedule"`
    Config       DAGConfig         `json:"config"`
    CreatedAt    time.Time         `json:"created_at"`
    UpdatedAt    time.Time         `json:"updated_at"`
}

type Task struct {
    ID          string            `json:"id"`
    Name        string            `json:"name"`
    Type        TaskType          `json:"type"`
    Command     string            `json:"command,omitempty"`
    Image       string            `json:"image,omitempty"`
    Script      string            `json:"script,omitempty"`
    Parameters  map[string]interface{} `json:"parameters"`
    Resources   ResourceRequirements   `json:"resources"`
    Retry       RetryPolicy       `json:"retry"`
    Timeout     time.Duration     `json:"timeout"`
    Condition   string            `json:"condition,omitempty"`
}

type TaskType string
const (
    SHELL_TASK      TaskType = "shell"
    DOCKER_TASK     TaskType = "docker"
    PYTHON_TASK     TaskType = "python"
    SQL_TASK        TaskType = "sql"
    HTTP_TASK       TaskType = "http"
    CONDITIONAL_TASK TaskType = "conditional"
    SUBDAG_TASK     TaskType = "subdag"
)

type TaskState string
const (
    PENDING    TaskState = "pending"
    QUEUED     TaskState = "queued"
    RUNNING    TaskState = "running"
    SUCCESS    TaskState = "success"
    FAILED     TaskState = "failed"
    RETRYING   TaskState = "retrying"
    SKIPPED    TaskState = "skipped"
    CANCELLED  TaskState = "cancelled"
)
```

#### 3.2 DAG拓扑排序和依赖解析

```go
type DAGParser struct {
    validateCycles bool
    maxDepth      int
}

func (dp *DAGParser) ParseDAG(dag *DAG) (*ExecutionPlan, error) {
    // 1. 验证DAG结构
    if err := dp.validateDAG(dag); err != nil {
        return nil, err
    }

    // 2. 构建邻接表
    graph := dp.buildGraph(dag)

    // 3. 拓扑排序
    sortedTasks, err := dp.topologicalSort(graph)
    if err != nil {
        return nil, err
    }

    // 4. 构建执行计划
    plan := &ExecutionPlan{
        DAGID:        dag.ID,
        Tasks:        sortedTasks,
        ExecutionLevels: dp.buildExecutionLevels(graph, sortedTasks),
        Dependencies: graph,
    }

    return plan, nil
}

func (dp *DAGParser) topologicalSort(graph map[string][]string) ([]string, error) {
    // 1. 计算入度
    inDegree := make(map[string]int)
    for node := range graph {
        inDegree[node] = 0
    }
    for _, neighbors := range graph {
        for _, neighbor := range neighbors {
            inDegree[neighbor]++
        }
    }

    // 2. 初始化队列
    queue := make([]string, 0)
    for node, degree := range inDegree {
        if degree == 0 {
            queue = append(queue, node)
        }
    }

    // 3. 拓扑排序
    result := make([]string, 0)
    for len(queue) > 0 {
        node := queue[0]
        queue = queue[1:]
        result = append(result, node)

        for _, neighbor := range graph[node] {
            inDegree[neighbor]--
            if inDegree[neighbor] == 0 {
                queue = append(queue, neighbor)
            }
        }
    }

    // 4. 检查环路
    if len(result) != len(graph) {
        return nil, errors.New("cycle detected in DAG")
    }

    return result, nil
}
```

### 4. 调度器设计

#### 4.1 任务调度器

```go
type Scheduler struct {
    taskQueue     PriorityQueue
    resourceMgr   ResourceManager
    executor      TaskExecutor
    stateStore    StateStore
    eventBus      EventBus
    workers       []*Worker
    maxConcurrency int
}

type ScheduleRequest struct {
    DAGID       string
    TaskID      string
    Priority    int
    ScheduledAt time.Time
    Resources   ResourceRequirements
    Context     map[string]interface{}
}

func (s *Scheduler) ScheduleDAG(dagRun *DAGRun) error {
    // 1. 加载执行计划
    plan, err := s.loadExecutionPlan(dagRun.DAGID)
    if err != nil {
        return err
    }

    // 2. 初始化DAG运行状态
    dagRun.State = RUNNING
    dagRun.StartTime = time.Now()
    s.stateStore.SaveDAGRun(dagRun)

    // 3. 调度首批可执行任务
    readyTasks := s.getReadyTasks(plan, dagRun)
    for _, taskID := range readyTasks {
        s.scheduleTask(dagRun, taskID)
    }

    return nil
}

func (s *Scheduler) scheduleTask(dagRun *DAGRun, taskID string) error {
    task := dagRun.Tasks[taskID]

    // 1. 检查资源可用性
    if !s.resourceMgr.CanAllocate(task.Resources) {
        // 资源不足，加入等待队列
        s.taskQueue.Push(&ScheduleRequest{
            DAGID:    dagRun.ID,
            TaskID:   taskID,
            Priority: s.calculatePriority(task),
        })
        return nil
    }

    // 2. 分配资源
    allocation, err := s.resourceMgr.Allocate(task.Resources)
    if err != nil {
        return err
    }

    // 3. 提交执行
    execution := &TaskExecution{
        DAGRunID:   dagRun.ID,
        TaskID:     taskID,
        Allocation: allocation,
        StartTime:  time.Now(),
        State:      RUNNING,
    }

    return s.executor.Execute(execution)
}
```

#### 4.2 工作器实现

```go
type Worker struct {
    id           string
    executor     TaskExecutor
    resourceMgr  ResourceManager
    stateStore   StateStore
    currentTasks map[string]*TaskExecution
    maxTasks     int
    mu           sync.RWMutex
}

func (w *Worker) Execute(execution *TaskExecution) error {
    w.mu.Lock()
    defer w.mu.Unlock()

    // 1. 检查容量
    if len(w.currentTasks) >= w.maxTasks {
        return errors.New("worker at capacity")
    }

    // 2. 加载任务定义
    task, err := w.loadTask(execution.DAGRunID, execution.TaskID)
    if err != nil {
        return err
    }

    // 3. 准备执行环境
    env, err := w.prepareEnvironment(task, execution)
    if err != nil {
        return err
    }

    // 4. 异步执行任务
    go w.executeTask(task, execution, env)

    w.currentTasks[execution.TaskID] = execution
    return nil
}

func (w *Worker) executeTask(task *Task, execution *TaskExecution, env *ExecutionEnvironment) {
    defer func() {
        w.mu.Lock()
        delete(w.currentTasks, execution.TaskID)
        w.mu.Unlock()
    }()

    // 1. 更新任务状态
    execution.State = RUNNING
    execution.StartTime = time.Now()
    w.stateStore.SaveTaskExecution(execution)

    // 2. 根据任务类型执行
    var result *TaskResult
    var err error

    switch task.Type {
    case SHELL_TASK:
        result, err = w.executeShellTask(task, env)
    case DOCKER_TASK:
        result, err = w.executeDockerTask(task, env)
    case PYTHON_TASK:
        result, err = w.executePythonTask(task, env)
    case SQL_TASK:
        result, err = w.executeSQLTask(task, env)
    case HTTP_TASK:
        result, err = w.executeHTTPTask(task, env)
    default:
        err = fmt.Errorf("unsupported task type: %s", task.Type)
    }

    // 3. 处理执行结果
    execution.EndTime = time.Now()
    execution.Duration = execution.EndTime.Sub(execution.StartTime)
    execution.Result = result

    if err != nil {
        execution.State = FAILED
        execution.Error = err.Error()
        w.handleTaskFailure(execution, task)
    } else {
        execution.State = SUCCESS
        w.handleTaskSuccess(execution)
    }

    w.stateStore.SaveTaskExecution(execution)
}
```

### 5. 状态管理

#### 5.1 DAG运行状态

```go
type DAGRun struct {
    ID          string                    `json:"id"`
    DAGID       string                    `json:"dag_id"`
    State       DAGState                  `json:"state"`
    StartTime   time.Time                 `json:"start_time"`
    EndTime     *time.Time                `json:"end_time,omitempty"`
    Duration    time.Duration             `json:"duration"`
    Tasks       map[string]*TaskExecution `json:"tasks"`
    Config      map[string]interface{}    `json:"config"`
    Context     map[string]interface{}    `json:"context"`
    TriggerType TriggerType               `json:"trigger_type"`
    ExternalID  string                    `json:"external_id,omitempty"`
}

type DAGState string
const (
    DAG_PENDING    DAGState = "pending"
    DAG_RUNNING    DAGState = "running"
    DAG_SUCCESS    DAGState = "success"
    DAG_FAILED     DAGState = "failed"
    DAG_CANCELLED  DAGState = "cancelled"
)

type StateStore interface {
    SaveDAGRun(run *DAGRun) error
    GetDAGRun(id string) (*DAGRun, error)
    SaveTaskExecution(execution *TaskExecution) error
    GetTaskExecution(dagRunID, taskID string) (*TaskExecution, error)
    ListDAGRuns(dagID string, limit int) ([]*DAGRun, error)
}
```

#### 5.2 状态机管理

```go
type StateMachine struct {
    stateStore StateStore
    eventBus   EventBus
    scheduler  Scheduler
}

func (sm *StateMachine) HandleTaskCompletion(execution *TaskExecution) error {
    // 1. 获取DAG运行状态
    dagRun, err := sm.stateStore.GetDAGRun(execution.DAGRunID)
    if err != nil {
        return err
    }

    // 2. 更新任务状态
    dagRun.Tasks[execution.TaskID] = execution

    // 3. 检查下游任务
    if execution.State == SUCCESS {
        readyTasks := sm.getNextReadyTasks(dagRun, execution.TaskID)
        for _, taskID := range readyTasks {
            sm.scheduler.scheduleTask(dagRun, taskID)
        }
    }

    // 4. 检查DAG完成状态
    if sm.isDAGCompleted(dagRun) {
        sm.finalizeDAGRun(dagRun)
    }

    // 5. 发送状态变更事件
    sm.eventBus.Publish(&TaskCompletionEvent{
        DAGRunID: execution.DAGRunID,
        TaskID:   execution.TaskID,
        State:    execution.State,
        Time:     time.Now(),
    })

    return nil
}

func (sm *StateMachine) getNextReadyTasks(dagRun *DAGRun, completedTaskID string) []string {
    plan, _ := sm.loadExecutionPlan(dagRun.DAGID)
    readyTasks := make([]string, 0)

    // 遍历所有任务，检查依赖是否满足
    for taskID, dependencies := range plan.Dependencies {
        if dagRun.Tasks[taskID] != nil && dagRun.Tasks[taskID].State != PENDING {
            continue // 任务已经被调度或完成
        }

        allDepsCompleted := true
        for _, depTaskID := range dependencies {
            if dagRun.Tasks[depTaskID] == nil || dagRun.Tasks[depTaskID].State != SUCCESS {
                allDepsCompleted = false
                break
            }
        }

        if allDepsCompleted {
            readyTasks = append(readyTasks, taskID)
        }
    }

    return readyTasks
}
```

### 6. 资源管理

#### 6.1 资源池管理

```go
type ResourceManager struct {
    nodePools    map[string]*NodePool
    allocations  map[string]*ResourceAllocation
    scheduler    *ResourceScheduler
    scaler       *AutoScaler
    mu           sync.RWMutex
}

type NodePool struct {
    Name         string
    Nodes        []*Node
    TotalCPU     int64
    TotalMemory  int64
    UsedCPU      int64
    UsedMemory   int64
    Labels       map[string]string
    Taints       []Taint
}

type Node struct {
    ID           string
    Name         string
    CPU          int64
    Memory       int64
    GPU          int64
    Storage      int64
    UsedCPU      int64
    UsedMemory   int64
    UsedGPU      int64
    UsedStorage  int64
    State        NodeState
    Labels       map[string]string
    LastHeartbeat time.Time
}

func (rm *ResourceManager) Allocate(req ResourceRequirements) (*ResourceAllocation, error) {
    rm.mu.Lock()
    defer rm.mu.Unlock()

    // 1. 选择合适的节点池
    pool := rm.selectNodePool(req)
    if pool == nil {
        return nil, errors.New("no suitable node pool found")
    }

    // 2. 在节点池中选择节点
    node := rm.selectNode(pool, req)
    if node == nil {
        // 尝试自动扩容
        if rm.scaler.CanScale(pool) {
            rm.scaler.ScaleOut(pool, 1)
            return nil, errors.New("scaling out, retry later")
        }
        return nil, errors.New("insufficient resources")
    }

    // 3. 分配资源
    allocation := &ResourceAllocation{
        ID:       generateID(),
        NodeID:   node.ID,
        CPU:      req.CPU,
        Memory:   req.Memory,
        GPU:      req.GPU,
        Storage:  req.Storage,
        AllocatedAt: time.Now(),
    }

    // 4. 更新资源使用情况
    node.UsedCPU += req.CPU
    node.UsedMemory += req.Memory
    node.UsedGPU += req.GPU
    node.UsedStorage += req.Storage

    rm.allocations[allocation.ID] = allocation

    return allocation, nil
}
```

#### 6.2 自动伸缩

```go
type AutoScaler struct {
    resourceMgr   *ResourceManager
    metrics       MetricsCollector
    config        ScalingConfig
    cooldownPeriod time.Duration
    lastScaleTime  map[string]time.Time
    mu             sync.RWMutex
}

type ScalingConfig struct {
    MinNodes         int
    MaxNodes         int
    TargetCPUPercent float64
    TargetMemPercent float64
    ScaleUpThreshold float64
    ScaleDownThreshold float64
}

func (as *AutoScaler) EvaluateScaling() {
    for poolName, pool := range as.resourceMgr.nodePools {
        // 1. 收集资源使用率指标
        cpuUsage := float64(pool.UsedCPU) / float64(pool.TotalCPU) * 100
        memUsage := float64(pool.UsedMemory) / float64(pool.TotalMemory) * 100

        // 2. 检查是否需要扩容
        if cpuUsage > as.config.ScaleUpThreshold || memUsage > as.config.ScaleUpThreshold {
            if as.shouldScaleUp(poolName) {
                as.scaleUp(pool)
            }
        }

        // 3. 检查是否需要缩容
        if cpuUsage < as.config.ScaleDownThreshold && memUsage < as.config.ScaleDownThreshold {
            if as.shouldScaleDown(poolName) {
                as.scaleDown(pool)
            }
        }
    }
}

func (as *AutoScaler) scaleUp(pool *NodePool) {
    if len(pool.Nodes) >= as.config.MaxNodes {
        return
    }

    // 1. 计算需要添加的节点数
    targetNodes := min(len(pool.Nodes)*2, as.config.MaxNodes)
    nodesToAdd := targetNodes - len(pool.Nodes)

    // 2. 创建新节点
    for i := 0; i < nodesToAdd; i++ {
        node := as.createNode(pool)
        if node != nil {
            pool.Nodes = append(pool.Nodes, node)
            pool.TotalCPU += node.CPU
            pool.TotalMemory += node.Memory
        }
    }

    as.lastScaleTime[pool.Name] = time.Now()
    log.Printf("Scaled up pool %s to %d nodes", pool.Name, len(pool.Nodes))
}
```

### 7. 监控和可观测性

#### 7.1 指标收集

```go
type MetricsCollector struct {
    registry    prometheus.Registry
    dagMetrics  *DAGMetrics
    taskMetrics *TaskMetrics
    sysMetrics  *SystemMetrics
}

type DAGMetrics struct {
    DAGRunsTotal     prometheus.Counter
    DAGRunDuration   prometheus.Histogram
    DAGRunsActive    prometheus.Gauge
    DAGSuccessRate   prometheus.Gauge
}

type TaskMetrics struct {
    TasksTotal       prometheus.Counter
    TaskDuration     prometheus.Histogram
    TasksActive      prometheus.Gauge
    TaskRetries      prometheus.Counter
    TaskSuccessRate  prometheus.Gauge
}

func (mc *MetricsCollector) RecordDAGCompletion(dagRun *DAGRun) {
    mc.dagMetrics.DAGRunsTotal.Inc()
    mc.dagMetrics.DAGRunDuration.Observe(dagRun.Duration.Seconds())
    mc.dagMetrics.DAGRunsActive.Dec()

    if dagRun.State == DAG_SUCCESS {
        mc.dagMetrics.DAGSuccessRate.Inc()
    }
}

func (mc *MetricsCollector) RecordTaskExecution(execution *TaskExecution) {
    labels := prometheus.Labels{
        "dag_id":   execution.DAGRunID,
        "task_id":  execution.TaskID,
        "state":    string(execution.State),
    }

    mc.taskMetrics.TasksTotal.With(labels).Inc()
    if execution.Duration > 0 {
        mc.taskMetrics.TaskDuration.With(labels).Observe(execution.Duration.Seconds())
    }
}
```

#### 7.2 分布式追踪

```go
type TracingManager struct {
    tracer opentracing.Tracer
}

func (tm *TracingManager) TraceDAGExecution(dagRun *DAGRun) opentracing.Span {
    span := tm.tracer.StartSpan("dag_execution")
    span.SetTag("dag_id", dagRun.DAGID)
    span.SetTag("dag_run_id", dagRun.ID)
    return span
}

func (tm *TracingManager) TraceTaskExecution(execution *TaskExecution, parentSpan opentracing.Span) opentracing.Span {
    span := tm.tracer.StartSpan("task_execution", opentracing.ChildOf(parentSpan.Context()))
    span.SetTag("task_id", execution.TaskID)
    span.SetTag("worker_id", execution.WorkerID)
    return span
}
```

### 8. 高级特性

#### 8.1 条件分支

```go
type ConditionalTask struct {
    Task
    Condition   string                `json:"condition"`
    TrueTask    string                `json:"true_task"`
    FalseTask   string                `json:"false_task"`
    Context     map[string]interface{} `json:"context"`
}

func (ct *ConditionalTask) Evaluate(context map[string]interface{}) (string, error) {
    // 1. 解析条件表达式
    expr, err := govaluate.NewEvaluableExpression(ct.Condition)
    if err != nil {
        return "", err
    }

    // 2. 计算条件结果
    result, err := expr.Evaluate(context)
    if err != nil {
        return "", err
    }

    // 3. 根据结果选择下一个任务
    if result.(bool) {
        return ct.TrueTask, nil
    } else {
        return ct.FalseTask, nil
    }
}
```

#### 8.2 动态DAG生成

```go
type DynamicDAGGenerator struct {
    templates map[string]*DAGTemplate
    renderer  TemplateRenderer
}

type DAGTemplate struct {
    Name        string                 `json:"name"`
    Template    string                 `json:"template"`
    Parameters  []Parameter            `json:"parameters"`
    Defaults    map[string]interface{} `json:"defaults"`
}

func (ddg *DynamicDAGGenerator) GenerateDAG(templateName string, params map[string]interface{}) (*DAG, error) {
    // 1. 获取模板
    template := ddg.templates[templateName]
    if template == nil {
        return nil, fmt.Errorf("template %s not found", templateName)
    }

    // 2. 合并参数和默认值
    context := make(map[string]interface{})
    for k, v := range template.Defaults {
        context[k] = v
    }
    for k, v := range params {
        context[k] = v
    }

    // 3. 渲染模板
    dagDef, err := ddg.renderer.Render(template.Template, context)
    if err != nil {
        return nil, err
    }

    // 4. 解析DAG定义
    var dag DAG
    err = json.Unmarshal([]byte(dagDef), &dag)
    if err != nil {
        return nil, err
    }

    return &dag, nil
}
```

### 9. 容错和恢复

#### 9.1 故障恢复

```go
type RecoveryManager struct {
    stateStore StateStore
    scheduler  Scheduler
    executor   TaskExecutor
}

func (rm *RecoveryManager) RecoverRunningDAGs() error {
    // 1. 查找所有运行中的DAG
    runningDAGs, err := rm.stateStore.ListRunningDAGs()
    if err != nil {
        return err
    }

    // 2. 恢复每个DAG的状态
    for _, dagRun := range runningDAGs {
        err := rm.recoverDAGRun(dagRun)
        if err != nil {
            log.Printf("Failed to recover DAG run %s: %v", dagRun.ID, err)
        }
    }

    return nil
}

func (rm *RecoveryManager) recoverDAGRun(dagRun *DAGRun) error {
    // 1. 检查运行中的任务
    for taskID, execution := range dagRun.Tasks {
        if execution.State == RUNNING {
            // 检查任务是否还在运行
            if !rm.executor.IsTaskRunning(execution) {
                // 任务已失败，标记为失败并重试
                execution.State = FAILED
                rm.handleTaskFailure(dagRun, taskID, execution)
            }
        }
    }

    // 2. 重新调度可执行的任务
    readyTasks := rm.getReadyTasks(dagRun)
    for _, taskID := range readyTasks {
        rm.scheduler.scheduleTask(dagRun, taskID)
    }

    return nil
}
```

### 10. 部署和运维

#### 10.1 Kubernetes部署配置

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: workflow-scheduler
spec:
  replicas: 3
  selector:
    matchLabels:
      app: workflow-scheduler
  template:
    metadata:
      labels:
        app: workflow-scheduler
    spec:
      containers:
      - name: scheduler
        image: workflow-engine:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          value: "postgresql"
        - name: REDIS_HOST
          value: "redis"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: workflow-scheduler-service
spec:
  selector:
    app: workflow-scheduler
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
```

#### 10.2 监控告警配置

```yaml
groups:
- name: workflow.rules
  rules:
  - alert: DAGFailureRate
    expr: rate(dag_runs_failed_total[5m]) / rate(dag_runs_total[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High DAG failure rate"
      description: "DAG failure rate is {{ $value }} in the last 5 minutes"

  - alert: TaskExecutionDelay
    expr: histogram_quantile(0.95, rate(task_duration_seconds_bucket[5m])) > 3600
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Task execution taking too long"
      description: "95th percentile task duration is {{ $value }} seconds"

  - alert: WorkerNodeDown
    expr: up{job="worker-nodes"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Worker node is down"
      description: "Worker node {{ $labels.instance }} has been down for more than 1 minute"
```

这个工作流编排系统设计通过DAG结构和拓扑排序确保了任务依赖的正确执行，通过分布式调度和资源管理保证了系统的高可用性和可扩展性，通过完善的监控和容错机制确保了企业级的稳定性要求。
