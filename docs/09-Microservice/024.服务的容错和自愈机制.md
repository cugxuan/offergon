---
title: 服务的容错和自愈机制
tags:
  - 微服务
status: robot
class: 微服务
slug: service-fault-tolerance-and-self-healing
ref:
---

## 核心要点

**容错和自愈是微服务高可用的核心保障**,通过**熔断器(Circuit Breaker)、限流(Rate Limiting)、重试(Retry)、超时(Timeout)、舱壁隔离(Bulkhead)**等机制防止故障扩散。自愈则依赖**健康检查(Health Check)、自动重启、服务降级、流量迁移**实现系统自动恢复。核心原则是**快速失败(Fail Fast)、优雅降级(Graceful Degradation)、最终一致性**。

---

## 详细回答

### 一、为什么需要容错机制

微服务架构下,一个请求可能经过多个服务,任何一个环节出错都会影响整体:

**故障传播链:**
```
用户请求 → API网关 → 订单服务 → 库存服务(故障) → 支付服务
                                    ↓
                              响应超时(30s)
                                    ↓
                        订单服务线程池耗尽
                                    ↓
                          API网关请求堆积
                                    ↓
                            整个系统雪崩
```

**常见故障类型:**
1. **服务宕机** - 实例崩溃、网络分区
2. **响应缓慢** - 数据库慢查询、下游服务超时
3. **资源耗尽** - CPU/内存/线程池满载
4. **间歇性故障** - 网络抖动、短暂不可用

### 二、熔断器(Circuit Breaker)

#### 1. 熔断器原理

熔断器模仿电路保险丝,当故障率达到阈值时**自动断开**,避免持续调用失败的服务。

**三种状态:**
```
┌─────────┐   失败率 > 阈值   ┌──────┐   超时    ┌──────────┐
│ Closed  ├──────────────────>│ Open ├─────────>│ Half-Open│
│ (正常)  │                   │(熔断)│          │(半开)    │
└────┬────┘                   └──┬───┘          └────┬─────┘
     │                           │                   │
     │                           │     成功 N 次     │
     │                           │<──────────────────┤
     │                           │                   │
     └───────────────────────────┴───────────────────┘
              失败率 < 阈值,恢复正常
```

**状态说明:**
- **Closed(关闭)** - 正常状态,请求正常通过,统计失败率
- **Open(打开)** - 熔断状态,直接返回错误,不调用下游服务
- **Half-Open(半开)** - 尝试恢复,允许部分请求通过测试

#### 2. Go实现熔断器

使用`sony/gobreaker`库:

```go
package circuitbreaker

import (
    "errors"
    "time"
    "github.com/sony/gobreaker"
)

var (
    inventoryServiceCB *gobreaker.CircuitBreaker
)

func init() {
    settings := gobreaker.Settings{
        Name:        "inventory-service",
        MaxRequests: 3,  // Half-Open状态下允许3个请求测试
        Interval:    10 * time.Second,  // 统计窗口10秒
        Timeout:     30 * time.Second,  // Open状态持续30秒后进入Half-Open

        // 熔断条件:连续失败5次 或 10秒内失败率>50%
        ReadyToTrip: func(counts gobreaker.Counts) bool {
            failureRatio := float64(counts.TotalFailures) / float64(counts.Requests)
            return counts.ConsecutiveFailures > 5 || failureRatio >= 0.5
        },

        // 状态变化回调
        OnStateChange: func(name string, from gobreaker.State, to gobreaker.State) {
            log.Printf("Circuit breaker '%s' changed from %s to %s", name, from, to)
        },
    }

    inventoryServiceCB = gobreaker.NewCircuitBreaker(settings)
}

// 使用熔断器包装调用
func DeductInventory(productID string, quantity int) error {
    result, err := inventoryServiceCB.Execute(func() (interface{}, error) {
        // 实际调用库存服务
        return nil, callInventoryService(productID, quantity)
    })

    if err != nil {
        // 熔断器打开时返回特定错误
        if err == gobreaker.ErrOpenState {
            log.Warn("Inventory service circuit breaker is OPEN")
            return errors.New("inventory service temporarily unavailable")
        }
        return err
    }

    return nil
}

func callInventoryService(productID string, quantity int) error {
    // gRPC调用库存服务
    ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
    defer cancel()

    conn, err := grpc.Dial("inventory-service:9090", grpc.WithInsecure())
    if err != nil {
        return err
    }
    defer conn.Close()

    client := inventorypb.NewInventoryServiceClient(conn)
    _, err = client.DeductStock(ctx, &inventorypb.DeductStockRequest{
        ProductId: productID,
        Quantity:  int32(quantity),
    })

    return err
}
```

#### 3. 熔断后的降级策略

```go
func GetProductInventory(productID string) (int, error) {
    inventory, err := inventoryServiceCB.Execute(func() (interface{}, error) {
        return queryInventoryService(productID)
    })

    if err != nil {
        if err == gobreaker.ErrOpenState {
            // 熔断后降级策略:
            // 1. 返回缓存数据
            cached, found := cache.Get("inventory:" + productID)
            if found {
                log.Info("Using cached inventory data (circuit breaker open)")
                return cached.(int), nil
            }

            // 2. 返回默认值
            log.Warn("Returning default inventory (circuit breaker open)")
            return 0, nil  // 显示库存为0,防止超卖

            // 3. 返回错误给上游
            // return 0, errors.New("inventory service unavailable")
        }
        return 0, err
    }

    return inventory.(int), nil
}
```

### 三、限流(Rate Limiting)

限流防止系统过载,常用算法:

#### 1. 令牌桶算法(Token Bucket)

```go
package ratelimit

import (
    "golang.org/x/time/rate"
    "net/http"
)

// 全局限流器:每秒100个请求,桶容量200
var globalLimiter = rate.NewLimiter(rate.Limit(100), 200)

// 限流中间件
func RateLimitMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // 尝试获取令牌
        if !globalLimiter.Allow() {
            http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
            return
        }

        next.ServeHTTP(w, r)
    })
}

// 基于用户的限流
var userLimiters = make(map[string]*rate.Limiter)
var mu sync.Mutex

func getUserLimiter(userID string) *rate.Limiter {
    mu.Lock()
    defer mu.Unlock()

    limiter, exists := userLimiters[userID]
    if !exists {
        // 每个用户每秒10个请求
        limiter = rate.NewLimiter(rate.Limit(10), 20)
        userLimiters[userID] = limiter
    }

    return limiter
}

func UserRateLimitMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        userID := r.Context().Value("user_id").(string)
        limiter := getUserLimiter(userID)

        if !limiter.Allow() {
            http.Error(w, "User rate limit exceeded", http.StatusTooManyRequests)
            return
        }

        next.ServeHTTP(w, r)
    })
}
```

#### 2. 滑动窗口限流(Redis实现)

```go
package ratelimit

import (
    "context"
    "errors"
    "time"
    "github.com/go-redis/redis/v8"
)

type SlidingWindowLimiter struct {
    redis  *redis.Client
    limit  int64         // 限流阈值
    window time.Duration // 时间窗口
}

func NewSlidingWindowLimiter(redis *redis.Client, limit int64, window time.Duration) *SlidingWindowLimiter {
    return &SlidingWindowLimiter{
        redis:  redis,
        limit:  limit,
        window: window,
    }
}

func (l *SlidingWindowLimiter) Allow(ctx context.Context, key string) (bool, error) {
    now := time.Now().UnixMilli()
    windowStart := now - l.window.Milliseconds()

    pipe := l.redis.Pipeline()

    // 1. 删除窗口外的记录
    pipe.ZRemRangeByScore(ctx, key, "0", fmt.Sprintf("%d", windowStart))

    // 2. 统计当前窗口内的请求数
    pipe.ZCard(ctx, key)

    // 3. 添加当前请求
    pipe.ZAdd(ctx, key, &redis.Z{
        Score:  float64(now),
        Member: now, // 使用时间戳作为唯一标识
    })

    // 4. 设置过期时间
    pipe.Expire(ctx, key, l.window)

    results, err := pipe.Exec(ctx)
    if err != nil {
        return false, err
    }

    // 获取当前窗口内的请求数
    count := results[1].(*redis.IntCmd).Val()

    // 判断是否超过限流阈值
    return count < l.limit, nil
}

// 使用示例
func OrderRateLimitMiddleware(limiter *SlidingWindowLimiter) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            userID := r.Context().Value("user_id").(string)
            key := "rate_limit:order:" + userID

            // 限流:每分钟最多10个订单
            allowed, err := limiter.Allow(r.Context(), key)
            if err != nil || !allowed {
                http.Error(w, "Too many orders, please try again later", http.StatusTooManyRequests)
                return
            }

            next.ServeHTTP(w, r)
        })
    }
}
```

### 四、重试和超时

#### 1. 智能重试策略

```go
package retry

import (
    "context"
    "errors"
    "time"
    "math/rand"
)

type RetryConfig struct {
    MaxAttempts int
    InitialDelay time.Duration
    MaxDelay     time.Duration
    Multiplier   float64
}

// 指数退避重试
func ExponentialBackoffRetry(ctx context.Context, config RetryConfig, fn func() error) error {
    var lastErr error
    delay := config.InitialDelay

    for attempt := 1; attempt <= config.MaxAttempts; attempt++ {
        // 执行函数
        err := fn()
        if err == nil {
            return nil  // 成功,直接返回
        }

        lastErr = err

        // 判断是否是可重试错误
        if !isRetriable(err) {
            return err  // 不可重试的错误,立即返回
        }

        // 最后一次尝试失败
        if attempt == config.MaxAttempts {
            break
        }

        // 计算下次重试延迟(指数退避 + 随机抖动)
        jitter := time.Duration(rand.Float64() * float64(delay) * 0.1)  // 10%随机抖动
        sleepTime := delay + jitter

        log.Warnf("Attempt %d failed: %v, retrying in %v", attempt, err, sleepTime)

        // 等待后重试
        select {
        case <-time.After(sleepTime):
            // 指数增长延迟
            delay = time.Duration(float64(delay) * config.Multiplier)
            if delay > config.MaxDelay {
                delay = config.MaxDelay
            }
        case <-ctx.Done():
            return ctx.Err()  // 上下文取消
        }
    }

    return fmt.Errorf("max retry attempts reached: %w", lastErr)
}

// 判断错误是否可重试
func isRetriable(err error) bool {
    // 网络超时、临时错误可重试
    if errors.Is(err, context.DeadlineExceeded) {
        return true
    }

    // gRPC错误码判断
    if st, ok := status.FromError(err); ok {
        code := st.Code()
        return code == codes.Unavailable ||
               code == codes.DeadlineExceeded ||
               code == codes.ResourceExhausted
    }

    // HTTP状态码判断
    if httpErr, ok := err.(HTTPError); ok {
        return httpErr.StatusCode == 429 ||  // Too Many Requests
               httpErr.StatusCode == 503 ||  // Service Unavailable
               httpErr.StatusCode == 504     // Gateway Timeout
    }

    return false
}

// 使用示例
func PlaceOrder(ctx context.Context, order *Order) error {
    config := RetryConfig{
        MaxAttempts:  3,
        InitialDelay: 100 * time.Millisecond,
        MaxDelay:     2 * time.Second,
        Multiplier:   2.0,
    }

    return ExponentialBackoffRetry(ctx, config, func() error {
        return orderService.Create(ctx, order)
    })
}
```

#### 2. 超时控制

```go
package timeout

import (
    "context"
    "time"
)

// HTTP客户端超时配置
func NewHTTPClient() *http.Client {
    return &http.Client{
        Timeout: 10 * time.Second,  // 总超时时间
        Transport: &http.Transport{
            DialContext: (&net.Dialer{
                Timeout:   3 * time.Second,  // 连接超时
                KeepAlive: 30 * time.Second,
            }).DialContext,
            TLSHandshakeTimeout:   5 * time.Second,  // TLS握手超时
            ResponseHeaderTimeout: 5 * time.Second,  // 响应头超时
            IdleConnTimeout:       90 * time.Second,
            MaxIdleConnsPerHost:   10,
        },
    }
}

// gRPC调用超时
func CallInventoryService(ctx context.Context, req *Request) (*Response, error) {
    // 设置3秒超时
    ctx, cancel := context.WithTimeout(ctx, 3*time.Second)
    defer cancel()

    conn, err := grpc.DialContext(ctx, "inventory-service:9090",
        grpc.WithInsecure(),
        grpc.WithBlock(),  // 阻塞直到连接建立
    )
    if err != nil {
        return nil, fmt.Errorf("failed to connect: %w", err)
    }
    defer conn.Close()

    client := inventorypb.NewInventoryServiceClient(conn)
    resp, err := client.CheckStock(ctx, req)

    return resp, err
}

// 超时后的降级处理
func GetUserProfile(ctx context.Context, userID string) (*UserProfile, error) {
    ctx, cancel := context.WithTimeout(ctx, 2*time.Second)
    defer cancel()

    profileChan := make(chan *UserProfile, 1)
    errChan := make(chan error, 1)

    go func() {
        profile, err := userService.GetProfile(ctx, userID)
        if err != nil {
            errChan <- err
            return
        }
        profileChan <- profile
    }()

    select {
    case profile := <-profileChan:
        return profile, nil
    case err := <-errChan:
        return nil, err
    case <-ctx.Done():
        // 超时后返回缓存数据
        cached, found := cache.Get("user_profile:" + userID)
        if found {
            log.Warn("User service timeout, returning cached data")
            return cached.(*UserProfile), nil
        }
        return nil, errors.New("user service timeout")
    }
}
```

### 五、舱壁隔离(Bulkhead)

隔离不同资源池,防止一个服务的故障影响其他服务。

#### 1. 线程池隔离

```go
package bulkhead

import (
    "context"
    "errors"
)

type BulkheadExecutor struct {
    name     string
    maxConcurrent int
    semaphore chan struct{}
    metrics   *Metrics
}

func NewBulkheadExecutor(name string, maxConcurrent int) *BulkheadExecutor {
    return &BulkheadExecutor{
        name:          name,
        maxConcurrent: maxConcurrent,
        semaphore:     make(chan struct{}, maxConcurrent),
        metrics:       &Metrics{},
    }
}

func (b *BulkheadExecutor) Execute(ctx context.Context, fn func() error) error {
    // 尝试获取信号量
    select {
    case b.semaphore <- struct{}{}:
        // 获取成功,执行任务
        defer func() { <-b.semaphore }()

        b.metrics.ActiveRequests.Inc()
        defer b.metrics.ActiveRequests.Dec()

        err := fn()
        if err != nil {
            b.metrics.Failures.Inc()
        } else {
            b.metrics.Successes.Inc()
        }
        return err

    case <-ctx.Done():
        return ctx.Err()

    default:
        // 信号量已满,拒绝请求
        b.metrics.Rejections.Inc()
        return errors.New("bulkhead full: too many concurrent requests")
    }
}

// 为不同服务创建独立的舱壁
var (
    inventoryBulkhead = NewBulkheadExecutor("inventory", 10)  // 库存服务最多10并发
    paymentBulkhead   = NewBulkheadExecutor("payment", 5)     // 支付服务最多5并发
    emailBulkhead     = NewBulkheadExecutor("email", 20)      // 邮件服务最多20并发
)

// 使用示例
func ProcessOrder(ctx context.Context, order *Order) error {
    // 调用库存服务(独立线程池)
    err := inventoryBulkhead.Execute(ctx, func() error {
        return inventoryService.Deduct(order.Items)
    })
    if err != nil {
        return err
    }

    // 调用支付服务(独立线程池)
    err = paymentBulkhead.Execute(ctx, func() error {
        return paymentService.Charge(order.Amount)
    })
    if err != nil {
        return err
    }

    // 发送邮件(独立线程池,即使失败也不影响订单)
    emailBulkhead.Execute(ctx, func() error {
        return emailService.SendOrderConfirmation(order)
    })

    return nil
}
```

### 六、健康检查和自愈

#### 1. Kubernetes健康检查

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: order-service
        image: order-service:v1.0
        ports:
        - containerPort: 8080

        # 存活探针:失败后重启容器
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8080
          initialDelaySeconds: 30  # 启动后30秒开始检测
          periodSeconds: 10        # 每10秒检测一次
          timeoutSeconds: 5        # 超时时间5秒
          failureThreshold: 3      # 连续失败3次后重启

        # 就绪探针:失败后从负载均衡移除
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 2

        # 启动探针:容器启动时检查
        startupProbe:
          httpGet:
            path: /health/startup
            port: 8080
          periodSeconds: 5
          failureThreshold: 30  # 最多等待150秒(5*30)

        # 资源限制
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
```

#### 2. Go实现健康检查端点

```go
package health

import (
    "context"
    "encoding/json"
    "net/http"
    "sync"
    "time"
)

type HealthChecker struct {
    checks map[string]HealthCheck
    mu     sync.RWMutex
}

type HealthCheck func(ctx context.Context) error

type HealthStatus struct {
    Status string            `json:"status"`  // "healthy", "degraded", "unhealthy"
    Checks map[string]string `json:"checks"`
}

func NewHealthChecker() *HealthChecker {
    return &HealthChecker{
        checks: make(map[string]HealthCheck),
    }
}

func (h *HealthChecker) Register(name string, check HealthCheck) {
    h.mu.Lock()
    defer h.mu.Unlock()
    h.checks[name] = check
}

// 存活检查:基本进程是否运行
func (h *HealthChecker) LivenessHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}

// 就绪检查:依赖服务是否正常
func (h *HealthChecker) ReadinessHandler(w http.ResponseWriter, r *http.Request) {
    ctx, cancel := context.WithTimeout(r.Context(), 5*time.Second)
    defer cancel()

    h.mu.RLock()
    defer h.mu.RUnlock()

    status := HealthStatus{
        Status: "healthy",
        Checks: make(map[string]string),
    }

    hasFailure := false

    for name, check := range h.checks {
        if err := check(ctx); err != nil {
            status.Checks[name] = "unhealthy: " + err.Error()
            hasFailure = true
        } else {
            status.Checks[name] = "healthy"
        }
    }

    if hasFailure {
        status.Status = "unhealthy"
        w.WriteHeader(http.StatusServiceUnavailable)
    } else {
        w.WriteHeader(http.StatusOK)
    }

    json.NewEncoder(w).Encode(status)
}

// 注册各种健康检查
func SetupHealthChecks(checker *HealthChecker, db *sql.DB, redis *redis.Client) {
    // 数据库健康检查
    checker.Register("database", func(ctx context.Context) error {
        return db.PingContext(ctx)
    })

    // Redis健康检查
    checker.Register("redis", func(ctx context.Context) error {
        return redis.Ping(ctx).Err()
    })

    // 下游服务健康检查
    checker.Register("inventory-service", func(ctx context.Context) error {
        conn, err := grpc.DialContext(ctx, "inventory-service:9090",
            grpc.WithInsecure(),
            grpc.WithBlock(),
        )
        if err != nil {
            return err
        }
        defer conn.Close()

        client := grpchealth.NewHealthClient(conn)
        resp, err := client.Check(ctx, &grpchealth.HealthCheckRequest{})
        if err != nil || resp.Status != grpchealth.HealthCheckResponse_SERVING {
            return errors.New("inventory service unhealthy")
        }
        return nil
    })
}

// 主函数注册路由
func main() {
    checker := NewHealthChecker()
    SetupHealthChecks(checker, db, redis)

    http.HandleFunc("/health/live", checker.LivenessHandler)
    http.HandleFunc("/health/ready", checker.ReadinessHandler)
    http.HandleFunc("/health/startup", checker.LivenessHandler)

    http.ListenAndServe(":8080", nil)
}
```

### 七、服务降级策略

```go
package degradation

import (
    "context"
)

// 多级降级策略
func GetRecommendedProducts(ctx context.Context, userID string) ([]*Product, error) {
    // 第一级:调用推荐服务(AI推荐)
    products, err := recommendService.GetPersonalizedRecommendations(ctx, userID)
    if err == nil && len(products) > 0 {
        return products, nil
    }

    log.Warn("Recommendation service failed, falling back to user history")

    // 第二级:基于用户历史
    products, err = orderService.GetUserFavoriteProducts(ctx, userID)
    if err == nil && len(products) > 0 {
        return products, nil
    }

    log.Warn("User history unavailable, falling back to popular products")

    // 第三级:热门商品
    products, err = productService.GetPopularProducts(ctx, 10)
    if err == nil && len(products) > 0 {
        return products, nil
    }

    log.Error("All recommendation strategies failed, returning default")

    // 第四级:返回默认商品列表
    return getDefaultProducts(), nil
}

// 功能开关控制降级
type FeatureFlag struct {
    EnableAIRecommendation bool
    EnableUserHistory      bool
    EnableSearch           bool
}

var currentFeatureFlag = &FeatureFlag{
    EnableAIRecommendation: true,
    EnableUserHistory:      true,
    EnableSearch:           true,
}

func SearchProducts(ctx context.Context, query string) ([]*Product, error) {
    if !currentFeatureFlag.EnableSearch {
        // 搜索功能降级:返回热门商品
        log.Info("Search feature disabled, returning popular products")
        return productService.GetPopularProducts(ctx, 20)
    }

    return searchService.Search(ctx, query)
}

// 动态调整功能开关(通过配置中心)
func WatchFeatureFlags(configCenter ConfigCenter) {
    configCenter.Watch("feature_flags", func(newConfig *FeatureFlag) {
        currentFeatureFlag = newConfig
        log.Infof("Feature flags updated: %+v", newConfig)
    })
}
```

### 八、实战案例:电商大促容错方案

```go
package order

import (
    "context"
    "errors"
)

type OrderService struct {
    inventoryClient  InventoryClient
    paymentClient    PaymentClient
    circuitBreaker   *gobreaker.CircuitBreaker
    bulkhead         *BulkheadExecutor
    cache            Cache
}

func (s *OrderService) CreateOrder(ctx context.Context, order *Order) error {
    // 1. 舱壁隔离:限制并发
    return s.bulkhead.Execute(ctx, func() error {
        // 2. 超时控制
        ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
        defer cancel()

        // 3. 熔断器保护库存服务调用
        err := s.circuitBreaker.Execute(func() (interface{}, error) {
            // 4. 重试机制
            return nil, ExponentialBackoffRetry(ctx, RetryConfig{
                MaxAttempts:  2,
                InitialDelay: 50 * time.Millisecond,
                MaxDelay:     500 * time.Millisecond,
                Multiplier:   2.0,
            }, func() error {
                return s.inventoryClient.DeductStock(ctx, order.Items)
            })
        })

        if err != nil {
            // 5. 降级策略:库存服务失败后,异步扣减
            if err == gobreaker.ErrOpenState {
                log.Warn("Inventory service unavailable, using async deduction")
                return s.asyncInventoryDeduction(order)
            }
            return err
        }

        // 6. 调用支付服务(独立熔断器)
        err = s.paymentClient.Charge(ctx, order.Amount)
        if err != nil {
            // 补偿:恢复库存
            s.inventoryClient.RestoreStock(ctx, order.Items)
            return err
        }

        // 7. 订单创建成功,缓存订单信息
        s.cache.Set("order:"+order.ID, order, 10*time.Minute)

        return nil
    })
}

// 异步库存扣减(降级方案)
func (s *OrderService) asyncInventoryDeduction(order *Order) error {
    // 先创建订单(状态:待扣库存)
    order.Status = "PENDING_INVENTORY"
    if err := s.repo.Save(order); err != nil {
        return err
    }

    // 发送到消息队列异步处理
    return s.messageQueue.Publish("inventory.deduct", order)
}
```

### 总结

服务容错和自愈的核心要点:

1. **熔断器** - 快速失败,防止故障蔓延
2. **限流** - 保护系统资源,防止过载
3. **重试和超时** - 指数退避,智能重试
4. **舱壁隔离** - 资源隔离,故障隔离
5. **健康检查** - 自动发现故障,及时恢复
6. **服务降级** - 多级降级,保证核心功能

关键原则:
- **Fail Fast(快速失败)** - 不要让请求长时间阻塞
- **Graceful Degradation(优雅降级)** - 核心功能优先
- **Bulkhead Pattern(舱壁模式)** - 隔离故障影响范围
- **Self-Healing(自愈)** - 自动检测和恢复
