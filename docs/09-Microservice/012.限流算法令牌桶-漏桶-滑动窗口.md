---
title: 限流算法(令牌桶、漏桶、滑动窗口)
tags:
  - 微服务
status: robot
class: 微服务
slug: rate-limiting-algorithms
ref:
---

## 核心要点

- **限流目的**:保护系统资源,防止过载,保证服务可用性
- **令牌桶**:允许突发流量,适合应对流量波动场景
- **漏桶**:强制固定速率,适合需要平滑流量的场景
- **滑动窗口**:精确统计,解决固定窗口临界问题,实现复杂度较高

---

## 一、为什么需要限流

### 1.1 系统过载问题

系统的处理能力是有限的,超过承载能力会导致:

```
请求量 vs 系统承载
正常: 1000 QPS ≤ 系统容量 2000 QPS → 正常响应
过载: 5000 QPS > 系统容量 2000 QPS →
      - 响应变慢
      - 内存溢出
      - 数据库连接耗尽
      - 系统崩溃
```

**典型场景**:
- **流量突增**:促销活动、热点事件
- **恶意攻击**:DDoS、爬虫、刷单
- **资源保护**:保护数据库、第三方API配额
- **成本控制**:云服务按调用计费

### 1.2 限流的作用

- **过载保护**:保证系统稳定,避免雪崩
- **资源分配**:保证核心业务优先
- **成本控制**:避免超额费用
- **公平性**:防止单个用户占用过多资源

---

## 二、固定窗口计数器(最简单但有缺陷)

### 2.1 原理

将时间划分为固定窗口(如1分钟),统计窗口内的请求数:

```
窗口1: [00:00-01:00]  允许100次  → 已使用50次  ✅ 允许
窗口2: [01:00-02:00]  允许100次  → 已使用100次 ❌ 拒绝
窗口3: [02:00-03:00]  允许100次  → 已使用0次   ✅ 允许(重置)
```

### 2.2 实现代码

```go
type FixedWindowLimiter struct {
    limit      int           // 限流阈值
    window     time.Duration // 时间窗口
    counter    int           // 当前计数
    windowTime int64         // 窗口开始时间
    mu         sync.Mutex
}

func (l *FixedWindowLimiter) Allow() bool {
    l.mu.Lock()
    defer l.mu.Unlock()

    now := time.Now().Unix()
    windowKey := now / int64(l.window.Seconds()) // 计算当前窗口

    // 新窗口,重置计数
    if windowKey != l.windowTime {
        l.windowTime = windowKey
        l.counter = 0
    }

    // 检查是否超限
    if l.counter >= l.limit {
        return false
    }

    l.counter++
    return true
}
```

### 2.3 临界问题

**致命缺陷**:窗口边界可能承受2倍流量

```
时间线:  |--------窗口1--------|--------窗口2--------|
         00:00              01:00               02:00
请求分布:         [99次]  [99次]
                      ↑      ↑
                  00:59    01:01
问题: 在1分钟内(00:30-01:30)实际通过了198次请求,是限制的2倍!
```

**解决方案**:使用滑动窗口算法

---

## 三、漏桶算法(Leaky Bucket)

### 3.1 原理

水流入桶,以恒定速率流出,桶满则溢出(拒绝请求):

```
            请求流入(不定速)
                ↓
         ┌──────────────┐
         │   漏桶容量   │  ← 桶满则溢出(拒绝)
         │ ▓▓▓▓▓▓▓▓▓▓ │
         │ ▓▓▓▓▓▓▓▓▓▓ │
         └──────┴───────┘
                ↓
         恒定速率流出(处理)
```

**关键特性**:
- 请求以任意速率进入
- 以固定速率处理请求
- 桶有容量上限(缓冲区)
- **强制平滑输出流量**

### 3.2 实现代码

```go
type LeakyBucket struct {
    capacity   int           // 桶容量
    rate       time.Duration // 漏水速率(处理间隔)
    water      int           // 当前水量
    lastLeakMs int64         // 上次漏水时间
    mu         sync.Mutex
}

func (lb *LeakyBucket) Allow() bool {
    lb.mu.Lock()
    defer lb.mu.Unlock()

    now := time.Now().UnixMilli()

    // 计算距离上次漏水的时间,漏掉的水量
    elapsed := now - lb.lastLeakMs
    leaked := int(elapsed / lb.rate.Milliseconds())

    // 更新桶内水量
    lb.water = max(0, lb.water-leaked)
    lb.lastLeakMs = now

    // 检查是否溢出
    if lb.water >= lb.capacity {
        return false // 桶满,拒绝
    }

    lb.water++ // 加水
    return true
}

func max(a, b int) int {
    if a > b {
        return a
    }
    return b
}
```

### 3.3 优缺点

**优点**:
- ✅ 强制流量平滑,保护后端服务
- ✅ 实现简单,内存占用小
- ✅ 适合需要稳定输出的场景(如视频流)

**缺点**:
- ❌ 无法应对突发流量(即使系统有余力)
- ❌ 可能浪费系统资源(空闲时也限流)

**适用场景**:
- 对第三方API的调用(严格遵守速率限制)
- 消息队列消费(避免下游过载)
- 数据库写入(平滑写入压力)

---

## 四、令牌桶算法(Token Bucket)

### 4.1 原理

以恒定速率生成令牌放入桶,请求消耗令牌,桶满则令牌溢出:

```
       以固定速率生成令牌(如10个/秒)
                ↓
         ┌──────────────┐
         │  令牌桶容量  │  ← 桶满,新令牌丢弃
         │ 🪙🪙🪙🪙🪙 │
         │ 🪙🪙🪙       │
         └──────────────┘
                ↓
         请求获取令牌(不定速)
         有令牌:通过  无令牌:拒绝
```

**与漏桶的关键区别**:
- 漏桶:强制**输出速率**恒定
- 令牌桶:限制**平均速率**,允许突发

### 4.2 实现代码

```go
type TokenBucket struct {
    capacity    int           // 桶容量(最大令牌数)
    rate        time.Duration // 生成令牌间隔
    tokens      int           // 当前令牌数
    lastTokenMs int64         // 上次生成令牌时间
    mu          sync.Mutex
}

func (tb *TokenBucket) Allow() bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()

    now := time.Now().UnixMilli()

    // 计算需要生成的令牌数
    elapsed := now - tb.lastTokenMs
    tokensToAdd := int(elapsed / tb.rate.Milliseconds())

    // 更新令牌数(不超过容量)
    tb.tokens = min(tb.capacity, tb.tokens+tokensToAdd)
    tb.lastTokenMs = now

    // 检查是否有令牌
    if tb.tokens <= 0 {
        return false // 无令牌,拒绝
    }

    tb.tokens-- // 消耗令牌
    return true
}

func min(a, b int) int {
    if a < b {
        return a
    }
    return b
}
```

### 4.3 突发流量处理

**示例**:速率10个/秒,容量100

```
场景1: 系统空闲1小时
- 积累令牌:100个(已满)
- 突发请求:100个 → 全部通过 ✅
- 之后:恢复10个/秒速率

场景2: 持续高流量
- 令牌耗尽:0个
- 新请求:只能以10个/秒通过(生成速率)
```

**这就是为什么适合Web应用**:
- 允许短时突发(用户点击)
- 长期限制平均速率

### 4.4 Go 官方库使用

```go
import "golang.org/x/time/rate"

func main() {
    // 创建限流器: 每秒10个令牌,桶容量100
    limiter := rate.NewLimiter(rate.Limit(10), 100)

    // 方式1: 阻塞等待令牌
    err := limiter.Wait(context.Background())
    if err != nil {
        log.Fatal(err)
    }

    // 方式2: 非阻塞检查
    if limiter.Allow() {
        // 处理请求
    } else {
        // 拒绝请求
    }

    // 方式3: 预留令牌(用于批量操作)
    reservation := limiter.Reserve()
    if !reservation.OK() {
        // 无法满足
    }
    time.Sleep(reservation.Delay()) // 等待到可用时间
}
```

### 4.5 优缺点

**优点**:
- ✅ 允许突发流量,充分利用系统资源
- ✅ 限制长期平均速率
- ✅ 应用广泛,生态完善

**缺点**:
- ❌ 突发流量可能冲击后端
- ❌ 需要合理设置桶容量

**适用场景**:
- Web API限流(最常见)
- 用户级别限流
- 需要应对突发流量的场景

---

## 五、滑动窗口算法(Sliding Window)

### 5.1 固定窗口问题回顾

固定窗口在边界处可能承受2倍流量:

```
固定窗口:
|-----窗口1(100次)-----|-----窗口2(100次)-----|
          [99次][99次]
              ↑    ↑
           临界区域: 实际1分钟内198次
```

### 5.2 滑动窗口日志

**原理**:记录每个请求的时间戳,统计最近N秒的请求数

```
当前时间: 10:00:50
限制: 100次/分钟

请求日志: [10:00:01, 10:00:15, ..., 10:00:48, 10:00:50]
           ↑ 超过1分钟,清理
计算: 10:00:50 - 60秒 = 09:59:50
统计: 09:59:50 ~ 10:00:50 之间的请求数
```

**实现代码**:

```go
type SlidingWindowLog struct {
    limit      int
    window     time.Duration
    requests   []int64 // 请求时间戳队列
    mu         sync.Mutex
}

func (sw *SlidingWindowLog) Allow() bool {
    sw.mu.Lock()
    defer sw.mu.Unlock()

    now := time.Now().UnixMilli()
    windowStart := now - sw.window.Milliseconds()

    // 清理过期请求
    validIdx := 0
    for i, reqTime := range sw.requests {
        if reqTime > windowStart {
            validIdx = i
            break
        }
    }
    sw.requests = sw.requests[validIdx:]

    // 检查是否超限
    if len(sw.requests) >= sw.limit {
        return false
    }

    sw.requests = append(sw.requests, now)
    return true
}
```

**优缺点**:
- ✅ 非常精确,无临界问题
- ❌ 内存占用高(存储每个请求)
- ❌ 高并发性能差

### 5.3 滑动窗口计数(优化版)

**原理**:将时间分为多个小窗口,滑动时加权计算

```
大窗口: 1分钟,分为6个小窗口(每个10秒)

当前时间: 10:00:55
|--10s--|--10s--|--10s--|--10s--|--10s--|--10s--|
 [20]    [15]    [30]    [25]    [10]    [5次] ← 当前
  ↑                                        ↑
清理                                    10:00:50-10:00:59

计算:
- 当前窗口(10:00:50-10:00:59): 5次(权重100%)
- 上个窗口(10:00:40-10:00:49): 10次(权重50% → 5次)
- 总计: 5 + 5 = 10次
```

**实现代码**:

```go
type SlidingWindowCounter struct {
    limit       int
    window      time.Duration
    slotNum     int              // 切片数量
    slotWindow  time.Duration    // 每个切片的时间
    slots       []int            // 每个切片的计数
    slotTime    []int64          // 每个切片的开始时间
    mu          sync.Mutex
}

func NewSlidingWindowCounter(limit int, window time.Duration, slotNum int) *SlidingWindowCounter {
    return &SlidingWindowCounter{
        limit:      limit,
        window:     window,
        slotNum:    slotNum,
        slotWindow: window / time.Duration(slotNum),
        slots:      make([]int, slotNum),
        slotTime:   make([]int64, slotNum),
    }
}

func (sw *SlidingWindowCounter) Allow() bool {
    sw.mu.Lock()
    defer sw.mu.Unlock()

    now := time.Now().UnixMilli()
    windowStart := now - sw.window.Milliseconds()

    // 计算当前slot索引
    currentSlot := int((now / sw.slotWindow.Milliseconds()) % int64(sw.slotNum))

    // 清理过期slot
    for i := 0; i < sw.slotNum; i++ {
        if sw.slotTime[i] < windowStart {
            sw.slots[i] = 0
        }
    }

    // 统计窗口内总请求数
    var count int
    for i := 0; i < sw.slotNum; i++ {
        slotStart := sw.slotTime[i]
        if slotStart >= windowStart {
            // 当前窗口内的slot,全部计入
            count += sw.slots[i]
        } else if slotStart+sw.slotWindow.Milliseconds() > windowStart {
            // 跨窗口的slot,按比例计算
            ratio := float64(slotStart+sw.slotWindow.Milliseconds()-windowStart) /
                     float64(sw.slotWindow.Milliseconds())
            count += int(float64(sw.slots[i]) * ratio)
        }
    }

    // 检查是否超限
    if count >= sw.limit {
        return false
    }

    // 更新当前slot
    slotStartTime := (now / sw.slotWindow.Milliseconds()) * sw.slotWindow.Milliseconds()
    if sw.slotTime[currentSlot] != slotStartTime {
        sw.slotTime[currentSlot] = slotStartTime
        sw.slots[currentSlot] = 0
    }
    sw.slots[currentSlot]++

    return true
}
```

**优缺点**:
- ✅ 内存可控(固定slot数量)
- ✅ 较高精度(比固定窗口好)
- ❌ 实现复杂
- ❌ 窗口边界仍有小误差(取决于slot数量)

---

## 六、算法对比与选型

### 6.1 核心对比

| 算法 | 突发流量 | 流量平滑 | 精确度 | 内存 | 实现复杂度 |
|------|----------|----------|--------|------|-----------|
| **固定窗口** | ❌ 临界问题 | ✅ | ⚠️ 临界2倍 | ✅ 低 | ⭐ 简单 |
| **漏桶** | ❌ 不允许 | ✅✅ 强制平滑 | ✅ | ✅ 低 | ⭐⭐ 中等 |
| **令牌桶** | ✅✅ 允许 | ⚠️ 平均限制 | ✅ | ✅ 低 | ⭐⭐ 中等 |
| **滑动窗口日志** | ✅ | ✅ | ✅✅ 非常精确 | ❌ 高 | ⭐⭐⭐ 复杂 |
| **滑动窗口计数** | ✅ | ✅ | ✅ 较精确 | ✅ 可控 | ⭐⭐⭐ 复杂 |

### 6.2 选型建议

**场景1: Web API限流**
- **推荐**: 令牌桶
- 原因: 允许突发,用户体验好

**场景2: 调用第三方API**
- **推荐**: 漏桶
- 原因: 严格遵守速率限制,避免超额

**场景3: 高精度计费场景**
- **推荐**: 滑动窗口日志
- 原因: 精确统计,无临界问题

**场景4: 高并发网关**
- **推荐**: 令牌桶 或 滑动窗口计数
- 原因: 性能好,内存可控

**场景5: 资源受限设备**
- **推荐**: 固定窗口
- 原因: 实现简单,资源占用最小(可接受临界问题)

### 6.3 分布式限流

以上算法都是单机限流,分布式场景需要:

**方案1: Redis + Lua脚本**

```lua
-- 令牌桶 Lua 脚本
local key = KEYS[1]
local capacity = tonumber(ARGV[1])
local rate = tonumber(ARGV[2])
local requested = tonumber(ARGV[3])

local info = redis.call('HMGET', key, 'tokens', 'timestamp')
local tokens = tonumber(info[1]) or capacity
local last = tonumber(info[2]) or 0
local now = tonumber(ARGV[4])

-- 计算新增令牌
local delta = math.max(0, now - last)
local new_tokens = math.min(capacity, tokens + delta * rate)

-- 检查是否足够
if new_tokens >= requested then
    new_tokens = new_tokens - requested
    redis.call('HMSET', key, 'tokens', new_tokens, 'timestamp', now)
    redis.call('EXPIRE', key, 10)
    return 1
else
    return 0
end
```

**方案2: 网关集中限流**
- Kong、APISIX等网关统一限流
- 避免每个服务实例单独实现

**方案3: Sentinel 集群流控**
- Token Server模式
- 所有实例连接同一Token Server

---

## 七、生产环境最佳实践

### 7.1 多级限流

```go
// 组合多种策略
type MultiLevelLimiter struct {
    globalLimiter *rate.Limiter      // 全局令牌桶
    userLimiters  map[string]*rate.Limiter // 用户级别
    ipLimiters    map[string]*rate.Limiter // IP级别
    mu            sync.RWMutex
}

func (ml *MultiLevelLimiter) Allow(userID, ip string) bool {
    // 第一级: 全局限流
    if !ml.globalLimiter.Allow() {
        return false
    }

    // 第二级: 用户限流
    ml.mu.RLock()
    userLimiter, ok := ml.userLimiters[userID]
    ml.mu.RUnlock()

    if ok && !userLimiter.Allow() {
        return false
    }

    // 第三级: IP限流(防刷)
    ml.mu.RLock()
    ipLimiter, ok := ml.ipLimiters[ip]
    ml.mu.RUnlock()

    if ok && !ipLimiter.Allow() {
        return false
    }

    return true
}
```

### 7.2 动态调整限流阈值

```go
type AdaptiveLimiter struct {
    limiter   *rate.Limiter
    baseRate  float64
    maxRate   float64
    cpuWatch  *CPUWatcher
}

func (al *AdaptiveLimiter) adjust() {
    cpu := al.cpuWatch.GetUsage()

    switch {
    case cpu > 80:
        // CPU高负载,降低限流
        newRate := al.baseRate * 0.5
        al.limiter.SetLimit(rate.Limit(newRate))
    case cpu < 50:
        // CPU空闲,提高限流
        newRate := min(al.baseRate*1.5, al.maxRate)
        al.limiter.SetLimit(rate.Limit(newRate))
    }
}
```

### 7.3 优雅降级

```go
func handleRequest(w http.ResponseWriter, r *http.Request) {
    if !limiter.Allow() {
        // 被限流,返回友好提示
        w.Header().Set("X-RateLimit-Limit", "100")
        w.Header().Set("X-RateLimit-Remaining", "0")
        w.Header().Set("X-RateLimit-Reset", fmt.Sprintf("%d", time.Now().Add(time.Minute).Unix()))
        w.Header().Set("Retry-After", "60")

        http.Error(w, "Rate limit exceeded. Please retry after 60 seconds.",
                   http.StatusTooManyRequests)
        return
    }

    // 正常处理
    processRequest(w, r)
}
```

### 7.4 监控告警

```go
type LimiterMetrics struct {
    total    int64 // 总请求数
    allowed  int64 // 通过数
    rejected int64 // 拒绝数
}

func (lm *LimiterMetrics) Record(allowed bool) {
    atomic.AddInt64(&lm.total, 1)
    if allowed {
        atomic.AddInt64(&lm.allowed, 1)
    } else {
        atomic.AddInt64(&lm.rejected, 1)

        // 拒绝率超过30%告警
        rejectRate := float64(lm.rejected) / float64(lm.total)
        if rejectRate > 0.3 {
            alert.Send("限流拒绝率过高: " + fmt.Sprintf("%.2f%%", rejectRate*100))
        }
    }
}
```

---

## 八、总结

### 8.1 选择建议速查

```
需要平滑流量(保护后端) → 漏桶
需要应对突发流量 → 令牌桶
需要高精度统计 → 滑动窗口
资源受限/简单场景 → 固定窗口
```

### 8.2 关键要点

1. **限流是主动防护**,熔断是被动防护,两者配合使用
2. **令牌桶最常用**,适合绝大多数Web场景
3. **分布式限流**需要Redis等中心化组件
4. **多级限流**:全局 + 用户 + IP,层层保护
5. **优雅降级**:提供友好错误信息和重试建议

### 8.3 避免的坑

1. ❌ 限流阈值设置过低,影响正常业务
2. ❌ 没有区分不同用户/接口,一刀切限流
3. ❌ 限流后直接返回500,应返回429(Too Many Requests)
4. ❌ 没有监控限流指标,无法及时调整
5. ❌ 分布式场景用本地限流,导致总流量超限

---

**参考资料**:
- [Cloudflare - Rate Limiting](https://blog.cloudflare.com/counting-things-a-lot-of-different-things/)
- [Go rate package](https://pkg.go.dev/golang.org/x/time/rate)
- [Redis INCR patterns](https://redis.io/commands/incr#pattern-rate-limiter)
